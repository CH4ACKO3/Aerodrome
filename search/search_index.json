{"config":{"lang":["en","zh"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Aerodrome - \u6982\u8ff0","text":"<p>Aerodrome \u662f\u4e00\u4e2a\u57fa\u4e8e C++ \u548c Python \u8054\u5408\u7f16\u7a0b\u7684\u8f7b\u91cf\u7ea7\u5e93\uff0c\u4e13\u6ce8\u4e8e\u63d0\u4f9b\u9ad8\u6027\u80fd\u52a8\u529b\u5b66\u4eff\u771f\u3001Python \u4ea4\u4e92\u63a5\u53e3\u4ee5\u53ca\u5f3a\u5316\u5b66\u4e60\u548c\u4f20\u7edf\u63a7\u5236\u7684\u4ee3\u7801\u793a\u4f8b\u3002\u5b83\u4e3b\u8981\u9762\u5411\u4e24\u7c7b\u7528\u6237\uff1a\u521d\u5b66\u5f3a\u5316\u5b66\u4e60\u7684\u7814\u7a76\u8005\uff0c\u6216\u5e0c\u671b\u5c06\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u7279\u5b9a\u9886\u57df\uff08\u5982\u98de\u63a7\uff09\u5e76\u9700\u8981\u81ea\u5b9a\u4e49\u4eff\u771f\u73af\u5883\u7684\u7814\u7a76\u8005\u3002\u4e3a\u4e86\u786e\u4fdd\u826f\u597d\u7684\u53ef\u4fee\u6539\u6027\u548c\u53ef\u8bfb\u6027\uff0cAerodrome \u7684\u6bcf\u4e2a\u90e8\u5206\u90fd\u5c3d\u91cf\u907f\u514d\u4f7f\u7528\u590d\u6742\u7684\u6cdb\u578b\u7f16\u7a0b\u6216\u9ad8\u7ea7\u8bed\u8a00\u7279\u6027\uff0c\u5e76\u5728\u4ee3\u7801\u4e2d\u4f5c\u4e86\u8be6\u5c3d\u7684\u6ce8\u91ca\u3002</p> <p>Aerodrome \u7684\u4e3b\u8981\u5185\u5bb9\u548c\u7279\u70b9\u5305\u62ec\uff1a</p> <ul> <li> <p>\u4eff\u7167 Gym \u7684\u4ee3\u7801\u548c\u63a5\u53e3\u98ce\u683c</p> </li> <li> <p>\u4e00\u4e2a\u793a\u4f8b\u73af\u5883\u548c\u8fc1\u79fb\u7248\u7684 Gym-CartPole \uff0c\u7528\u4e8e\u6d4b\u8bd5\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u6b63\u786e\u6027</p> </li> <li> <p>\u9ad8\u5ea6\u53ef\u81ea\u5b9a\u4e49\u7684\u56fa\u5b9a\u7ffc\u98de\u884c\u5668\u4eff\u771f\u793a\u4f8b\u4ee3\u7801</p> </li> <li> <p>\u57fa\u4e8e\u516c\u5f00\u8d44\u6599\u7684 Winged-Cone \u975e\u7ebf\u6027\u6c14\u52a8\u6a21\u578b\uff0c\u4ee5\u53ca\u5176\u52a8\u529b\u5b66\u4eff\u771f\uff08C++ \u548c Python \u4e24\u79cd\u8bed\u8a00\u7248\u672c\uff0c\u5e76\u5305\u542b\u8fd0\u884c\u6027\u80fd\u5bf9\u6bd4\uff01\uff09</p> </li> <li> <p>Winged-Cone \u7eb5\u5411\u8fc7\u8f7d\u63a7\u5236\u7684\u4f20\u7edf\u4e09\u56de\u8def\u9a7e\u9a76\u4eea\u5b9e\u73b0\u548c \u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO \uff09\u5b9e\u73b0</p> </li> </ul> <p>Note Aerodrome \u4e0d\u662f \u4e00\u4e2a\u6a21\u5757\u5316\u5e93\uff0c\u56e0\u6b64\u5b83\u5e76\u4e0d\u9002\u5408\u88ab\u5bfc\u5165\u4f7f\u7528\u3002Aerodrome \u4ee5\u90e8\u5206\u4ee3\u7801\u91cd\u590d\u4e3a\u4ee3\u4ef7\uff0c\u5c3d\u91cf\u4f7f\u5f97\u6240\u6709\u4ee3\u7801\u7b80\u6d01\u3001\u6613\u4e8e\u7406\u89e3\u4e14\u65b9\u4fbf\u6269\u5c55\u3002Aerodrome \u4e5f\u6709\u5176\u5c40\u9650\u6027\uff0c\u4f8b\u5982\u7f3a\u5c11\u53ef\u89c6\u5316\u548c\u5b9e\u9a8c\u7ed3\u679c\u4fdd\u5b58\u529f\u80fd\uff1b\u5982\u679c\u4f60\u9700\u8981\u7279\u5b9a\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u793a\u4f8b\uff0c\u53ef\u4ee5\u53c2\u8003 CleanRL \u5e93\uff1b\u5982\u679c\u4f60\u9700\u8981\u5b9e\u73b0\u5176\u5b83\u98de\u884c\u5668\u6a21\u578b\uff08\u6216\u8005\u751a\u81f3\u5176\u5b83\u9886\u57df\u7684\u73af\u5883\uff09\uff0c\u53ef\u4ee5\u5728 Aerodrome \u4ee3\u7801\u57fa\u7840\u4e0a\u4fee\u6539\uff0c\u6216\u8005\u5b8c\u5168\u91cd\u5199\uff01</p>"},{"location":"basics/","title":"\u57fa\u7840\u8fd0\u884c\u903b\u8f91","text":"<p>\u5728 Aerodrome \u4e2d\uff0c\u4e00\u4e2a\u5178\u578b\u7684 C++/Python \u8054\u5408\u7f16\u7a0b\u73af\u5883\u7684\u7ed3\u6784\u5982\u56fe\uff1a</p> <p>\u901a\u5e38\u6765\u8bf4\uff0cC++ \u73af\u5883\u7c7b\u76f4\u63a5\u7ba1\u7406 C++ \u5b9e\u4f53\u7684\u521d\u59cb\u5316\u3001\u8fd0\u884c\uff0c\u5e76\u5728\u9700\u8981\u65f6\u8bfb\u53d6\u5176\u4fe1\u606f\u5e76\u8f93\u51fa\uff1b Python \u73af\u5883\u7c7b\u5219\u8d1f\u8d23\u5904\u7406\u7528\u6237\u8f93\u5165\u3001C++ \u73af\u5883\u7684\u8f93\u51fa\uff08\u4f8b\u5982\uff0c\u6570\u636e\u7c7b\u578b\u7684\u5fc5\u8981\u8f6c\u6362\uff09\u7b49\uff1b</p> <p>\u5f53\u7136\uff0c\u8fd9\u79cd\u8bbe\u8ba1\u5e76\u4e0d\u662f\u5f3a\u5236\u7684\uff0c\u7528\u6237\u5b8c\u5168\u53ef\u4ee5\u6839\u636e\u9700\u8981\u81ea\u884c\u8bbe\u8ba1\uff0c\u4f8b\u5982\u4e0b\u9762\u4e24\u79cd\u90fd\u662f\u53ef\u884c\u7684\uff1a</p> \u8df3\u8fc7 Python \u73af\u5883\u7c7b\uff0c\u76f4\u63a5\u4ece C++ \u73af\u5883\u7c7b\u83b7\u53d6\u8f93\u51fa \u5728 Python \u4e2d\u76f4\u63a5\u5b9e\u73b0\u6240\u6709\u529f\u80fd"},{"location":"basics/#c","title":"C++ \u57fa\u7840\u7c7b","text":"<p>\u5728 Aerodrome \u4e2d\uff0c\u6709\u4e24\u4e2a\u6700\u57fa\u672c\u7684\u7c7b\u578b\uff0c\u53ef\u4ee5\u5728 <code>src/simulator/Core</code> \u4e2d\u627e\u5230\uff1a</p> <ul> <li><code>BaseEnv</code>\uff1a\u6240\u6709\u73af\u5883\u7684\u57fa\u7c7b\uff0c\u5b9a\u4e49\u4e86\u6240\u6709\u73af\u5883\u5171\u6709\u7684\u63a5\u53e3\uff1b</li> <li><code>Object3D</code>\uff1a\u6240\u6709\u4e09\u7ef4\u5bf9\u8c61\u7684\u57fa\u7c7b\uff0c\u5b9a\u4e49\u4e86\u4e09\u7ef4\u5bf9\u8c61\u7684\u901a\u7528\u5c5e\u6027\uff0c\u4f8b\u5982\u901f\u5ea6\u3001\u4f4d\u7f6e\u3001\u59ff\u6001\u7b49\uff1b</li> </ul> <p>Note \u7531\u4e8e pybind11 \u5728\u7f16\u8bd1\u65b9\u9762\u7684\u9650\u5236\uff0c\u76ee\u524d C++ \u4ee3\u7801 pybind \u7ed1\u5b9a\u7684\u5b9e\u73b0\u65b9\u5f0f\u662f\u5c06\u51fd\u6570/\u7c7b\u7684\u5b9a\u4e49\u548c\u5b9e\u73b0\u90fd\u5199\u5728 <code>.h</code> \u6587\u4ef6\u4e2d\uff1bpybind\u7ed1\u5b9a\u5219\u5199\u5728\u540c\u540d\u7684 <code>.cpp</code> \u6587\u4ef6\u4e2d\u3002 \u5982\u679c\u6709\u66f4\u597d\u7684\u5b9e\u73b0\u65b9\u5f0f\uff0c\u975e\u5e38\u6b22\u8fce\u63d0\u51fa issue \u6216 PR\uff01</p>"},{"location":"basics/#baseenv","title":"BaseEnv","text":"<p>\u5728 BaseEnv \u4e2d\uff0c\u5b9a\u4e49\u4e86\u6240\u6709\u73af\u5883\u5171\u6709\u7684\u63a5\u53e3\uff0c\u5305\u62ec\uff1a</p> <ul> <li><code>reset()</code>\uff1a\u91cd\u7f6e\u73af\u5883\uff1b</li> <li><code>step(action)</code>\uff1a\u6267\u884c\u4e00\u6b65\u52a8\u4f5c\uff0c\u5e76\u8fd4\u56de\u4fe1\u606f\uff08\u4f8b\u5982\uff0c\u89c2\u6d4b\u3001\u5956\u52b1\u3001\u7ec8\u6b62\u7b49\uff09\uff1b</li> </ul> \u70b9\u51fb\u5c55\u5f00\u4ee3\u7801 <pre><code>class BaseEnv\n{\npublic:\n    BaseEnv() = default;\n    virtual ~BaseEnv() = default;\n\n    virtual py::object reset() = 0;\n    virtual py::object step(const py::object&amp; action) = 0;\n};\n</code></pre>"},{"location":"basics/#object3d","title":"Object3D","text":"<p>Object3D \u7684\u5185\u5bb9\u5219\u8f83\u591a\uff0c\u5305\u62ec\uff1a</p> <ul> <li>\u4f4d\u7f6e\u3001\u901f\u5ea6\u3001\u59ff\u6001\u7b49\u57fa\u672c\u5c5e\u6027\uff1b</li> <li>\u5c06\u81ea\u8eab\u5c5e\u6027\u8f93\u51fa\u4e3a\u5b57\u5178\u7684\u65b9\u6cd5\uff1b</li> <li>\u91cd\u7f6e\u81ea\u8eab\u5c5e\u6027\u7684\u65b9\u6cd5\uff1b</li> <li>\u8ba1\u7b97\u81ea\u8eab\u52a8\u529b\u5b66\u5bfc\u6570\u7684\u65b9\u6cd5\uff1b</li> <li>\u8fdb\u884c\u4e00\u6b65\u4eff\u771f\u7684\u65b9\u6cd5\uff1b</li> </ul> <p>\u4e3a\u4e86\u51c6\u786e\u65b9\u4fbf\u5730\u8ba1\u7b97\u81ea\u8eab\u7684\u52a8\u529b\u5b66\u5bfc\u6570\u5e76\u8fdb\u884c\u4eff\u771f\uff0c\u8fd8\u5bf9\u8fd0\u7b97\u7b26\u8fdb\u884c\u4e86\u91cd\u8f7d\u3002 \u5728\u540e\u9762\u4f1a\u770b\u5230\uff0c\u5bf9\u4e8e\u6d3e\u751f\u7c7b\uff0c\u4ee3\u7801\u5f88\u5927\u7a0b\u5ea6\u4e0a\u662f\u53ef\u4ee5\u590d\u7528\u7684\uff0c\u53ea\u9700\u8981\u91cd\u5199\u5c11\u91cf\u4ee3\u7801\u5c31\u53ef\u4ee5\u5b9e\u73b0\u4e00\u4e2a\u6b63\u786e\u4e14\u89c4\u8303\u7684\u7269\u7406\u5bf9\u8c61\u3002</p> \u70b9\u51fb\u5c55\u5f00\u4ee3\u7801 <pre><code>class Object3D {\npublic:\n    std::string name;\n    std::string integrator;\n\n    // \u4f4d\u7f6e\u5750\u6807\uff08\u5730\u9762\u7cfb\uff09\n    std::array&lt;double, 3&gt; pos;\n\n    // \u901f\u5ea6\u5411\u91cf\uff08\u5730\u9762\u7cfb\uff09\n    std::array&lt;double, 3&gt; vel;\n\n    // \u89d2\u901f\u5ea6\u5411\u91cf\uff08\u5f39\u4f53\u7cfb\uff09\n    std::array&lt;double, 3&gt; ang_vel;\n\n    // \u8f6c\u52a8\u60ef\u91cf\n    std::array&lt;double, 3&gt; J;\n\n    double V; // \u901f\u5ea6\n\n    // \u63cf\u8ff0\u521a\u4f53\u59ff\u6001\u7684\u516b\u4e2a\u89d2\u5ea6\n    double theta;    // \u4fef\u4ef0\u89d2\n    double phi;      // \u504f\u822a\u89d2\n    double gamma;    // \u503e\u659c\u89d2\n    double theta_v;  // \u901f\u5ea6\u503e\u89d2\n    double phi_v;    // \u901f\u5ea6\u504f\u89d2\n    double alpha;    // \u653b\u89d2\n    double beta;     // \u4fa7\u6ed1\u89d2\n    double gamma_v;  // \u901f\u5ea6\u503e\u659c\u89d2\n\n    py::dict initial_state;\n\n    Object3D() {}\n\n    Object3D(py::dict input_dict)\n    {\n        name = input_dict[\"name\"].cast&lt;std::string&gt;();\n        integrator = input_dict[\"integrator\"].cast&lt;std::string&gt;();\n        pos = input_dict[\"pos\"].cast&lt;std::array&lt;double, 3&gt;&gt;();\n        vel = input_dict[\"vel\"].cast&lt;std::array&lt;double, 3&gt;&gt;();\n        ang_vel = input_dict[\"ang_vel\"].cast&lt;std::array&lt;double, 3&gt;&gt;();\n        J = input_dict[\"J\"].cast&lt;std::array&lt;double, 3&gt;&gt;();\n        // V = input_dict[\"V\"].cast&lt;double&gt;();\n        V = sqrt(vel[0] * vel[0] + vel[1] * vel[1] + vel[2] * vel[2]);\n        theta = input_dict[\"theta\"].cast&lt;double&gt;();\n        phi = input_dict[\"phi\"].cast&lt;double&gt;();\n        gamma = input_dict[\"gamma\"].cast&lt;double&gt;();\n        theta_v = input_dict[\"theta_v\"].cast&lt;double&gt;();\n        phi_v = input_dict[\"phi_v\"].cast&lt;double&gt;();\n        gamma_v = input_dict[\"gamma_v\"].cast&lt;double&gt;();\n        alpha = input_dict[\"alpha\"].cast&lt;double&gt;();\n        beta = input_dict[\"beta\"].cast&lt;double&gt;();\n\n        initial_state = input_dict;\n    }\n\n    virtual void reset()\n    {\n        *this = Object3D(initial_state);\n    }\n\n    virtual py::dict to_dict()\n    {\n        py::dict output_dict;\n        output_dict[\"pos\"] = pos;\n        output_dict[\"vel\"] = vel;\n        output_dict[\"ang_vel\"] = ang_vel;\n        output_dict[\"J\"] = J;\n        output_dict[\"V\"] = V;\n        output_dict[\"theta\"] = theta;\n        output_dict[\"phi\"] = phi;\n        output_dict[\"gamma\"] = gamma;\n        output_dict[\"theta_v\"] = theta_v;\n        output_dict[\"phi_v\"] = phi_v;\n        output_dict[\"alpha\"] = alpha;\n        output_dict[\"beta\"] = beta;\n        output_dict[\"gamma_v\"] = gamma_v;\n        output_dict[\"name\"] = name;\n        return output_dict;\n    }\n\n    virtual py::object step(py::dict action)\n    {\n        double dt = action[\"dt\"].cast&lt;double&gt;();\n\n        pos = action[\"pos\"].cast&lt;std::array&lt;double, 3&gt;&gt;();\n        vel = action[\"vel\"].cast&lt;std::array&lt;double, 3&gt;&gt;();\n        ang_vel = action[\"ang_vel\"].cast&lt;std::array&lt;double, 3&gt;&gt;();\n        J = action[\"J\"].cast&lt;std::array&lt;double, 3&gt;&gt;();\n        // V = action[\"V\"].cast&lt;double&gt;();\n        V = sqrt(vel[0] * vel[0] + vel[1] * vel[1] + vel[2] * vel[2]);\n        theta = action[\"theta\"].cast&lt;double&gt;();\n        phi = action[\"phi\"].cast&lt;double&gt;();\n        gamma = action[\"gamma\"].cast&lt;double&gt;();\n        theta_v = action[\"theta_v\"].cast&lt;double&gt;();\n        phi_v = action[\"phi_v\"].cast&lt;double&gt;();\n        gamma_v = action[\"gamma_v\"].cast&lt;double&gt;();\n        alpha = action[\"alpha\"].cast&lt;double&gt;();\n        beta = action[\"beta\"].cast&lt;double&gt;();\n\n        if (integrator == \"euler\")\n        {\n            *this = *this + this-&gt;d() * dt;\n        }\n        else if (integrator == \"midpoint\")\n        {\n            auto temp1 = *this + this-&gt;d() * (0.5 * dt);\n            auto k1 = temp1.d();\n            *this = *this + k1 * dt;\n        }\n        else if (integrator == \"rk23\")\n        {\n            auto k1 = this-&gt;d();\n            auto temp1 = *this + k1 * (0.5 * dt);\n            auto k2 = temp1.d();\n            auto temp2 = *this + k2 * (0.5 * dt);\n            auto k3 = temp2.d();\n            *this = *this + (k1 + k2 * 2 + k3) * (dt / 4);\n        }\n        else if (integrator == \"rk45\")\n        {\n            auto k1 = this-&gt;d();\n            auto temp1 = *this + k1 * (0.5 * dt);\n            auto k2 = temp1.d();\n            auto temp2 = *this + k2 * (0.5 * dt);\n            auto k3 = temp2.d();\n            auto temp3 = *this + k3 * dt;\n            auto k4 = temp3.d();\n            *this = *this + (k1 + k2 * 2 + k3 * 2 + k4) * (dt / 6);\n        }\n\n        theta_v = atan2(vel[1], sqrt(vel[0] * vel[0] + vel[2] * vel[2]));\n        phi_v = atan2(-vel[2], vel[0]);\n\n        beta = cos(theta_v) * (cos(gamma) * sin(phi - phi_v) + sin(theta) * sin(gamma) * cos(phi - phi_v)) - sin(theta_v) * cos(theta) * sin(gamma);\n        alpha = (cos(theta_v) * (sin(theta) * cos(gamma) * cos(phi - phi_v) - sin(gamma) * sin(phi - phi_v)) - sin(theta_v) * cos(theta) * cos(gamma)) / cos(beta);\n        gamma_v = (cos(alpha) * sin(beta) * sin(theta) - sin(alpha) * sin(beta) * cos(gamma) * cos(theta) + cos(beta) * sin(gamma) * cos(theta)) / cos(theta_v);\n\n        V = sqrt(vel[0] * vel[0] + vel[1] * vel[1] + vel[2] * vel[2]);\n        return to_dict();\n    }\n\n    virtual Object3D d()\n    {\n        auto derivative = *this;\n\n        derivative.pos[0] = vel[0];\n        derivative.pos[1] = vel[1];\n        derivative.pos[2] = vel[2];\n\n        derivative.vel[0] = 0;\n        derivative.vel[1] = 0;\n        derivative.vel[2] = 0;\n\n        derivative.ang_vel[0] = 0;\n        derivative.ang_vel[1] = 0;\n        derivative.ang_vel[2] = 0;\n\n        derivative.theta = ang_vel[1] * sin(gamma) + ang_vel[2] * cos(gamma);\n        derivative.phi = (ang_vel[1] * cos(gamma) - ang_vel[2] * sin(gamma)) / cos(theta);\n        derivative.gamma = ang_vel[0] * - tan(theta) * (ang_vel[1] * cos(gamma) - ang_vel[2] * sin(gamma));\n\n        derivative.theta_v = 0;\n        derivative.phi_v = 0;\n        derivative.gamma_v = 0;\n\n        derivative.alpha = 0;\n        derivative.beta = 0;\n\n        return derivative;\n    }\n\n    template&lt;typename T, typename P&gt;\n    friend T operator+(const T&amp; lop, const P&amp; rop)\n    {\n        auto result = lop;\n\n        for (int i = 0; i &lt; 3; ++i)\n        {   \n            result.pos[i] = lop.pos[i] + rop.pos[i];\n            result.vel[i] = lop.vel[i] + rop.vel[i];\n            result.ang_vel[i] = lop.ang_vel[i] + rop.ang_vel[i];\n        }   \n\n        result.V = lop.V + rop.V;\n        result.theta = lop.theta + rop.theta;\n        result.phi = lop.phi + rop.phi;\n        result.gamma = lop.gamma + rop.gamma;\n        result.theta_v = lop.theta_v + rop.theta_v;\n        result.phi_v = lop.phi_v + rop.phi_v; \n        result.alpha = lop.alpha + rop.alpha;\n        result.beta = lop.beta + rop.beta;\n        result.gamma_v = lop.gamma_v + rop.gamma_v;\n\n        return result;\n    }\n\n    template&lt;typename T, typename P&gt;\n    friend T operator-(const T&amp; lop, const P&amp; rop)\n    {\n        auto result = lop;\n\n        for (int i = 0; i &lt; 3; ++i)\n        {\n            result.pos[i] = lop.pos[i] - rop.pos[i];\n            result.vel[i] = lop.vel[i] - rop.vel[i];\n            result.ang_vel[i] = lop.ang_vel[i] - rop.ang_vel[i];\n        }\n\n        result.V = lop.V - rop.V;\n        result.theta = lop.theta - rop.theta;\n        result.phi = lop.phi - rop.phi;\n        result.gamma = lop.gamma - rop.gamma;\n        result.theta_v = lop.theta_v - rop.theta_v;\n        result.phi_v = lop.phi_v - rop.phi_v;\n        result.alpha = lop.alpha - rop.alpha;\n        result.beta = lop.beta - rop.beta;\n        result.gamma_v = lop.gamma_v - rop.gamma_v;\n\n        return result;\n    }\n\n    template&lt;typename T&gt;\n    friend T operator*(const T&amp; lop, const double&amp; rop)\n    {\n        auto result = lop;\n\n        for (int i = 0; i &lt; 3; ++i)\n        {\n            result.pos[i] = lop.pos[i] * rop; \n            result.vel[i] = lop.vel[i] * rop;\n            result.ang_vel[i] = lop.ang_vel[i] * rop;\n        }   \n\n        result.V = lop.V * rop;\n        result.theta = lop.theta * rop;\n        result.phi = lop.phi * rop;\n        result.gamma = lop.gamma * rop;\n        result.theta_v = lop.theta_v * rop;\n        result.phi_v = lop.phi_v * rop;\n        result.alpha = lop.alpha * rop;\n        result.beta = lop.beta * rop;\n        result.gamma_v = lop.gamma_v * rop;\n\n        return result;\n    }\n\n    template&lt;typename T&gt;\n    friend T operator/(const T&amp; lop, const double&amp; rop)\n    {\n        auto result = lop;\n\n        for (int i = 0; i &lt; 3; ++i)\n        {\n            result.pos[i] = lop.pos[i] / rop; \n            result.vel[i] = lop.vel[i] / rop;\n            result.ang_vel[i] = lop.ang_vel[i] / rop;\n        }   \n\n        result.V = lop.V / rop;\n        result.theta = lop.theta / rop;\n        result.phi = lop.phi / rop;\n        result.gamma = lop.gamma / rop;\n        result.theta_v = lop.theta_v / rop;\n        result.phi_v = lop.phi_v / rop;   \n        result.alpha = lop.alpha / rop;\n        result.beta = lop.beta / rop;\n        result.gamma_v = lop.gamma_v / rop;\n\n        return result;\n    }\n};\n</code></pre>"},{"location":"cartpole_dqn/","title":"CartPole \u548c DQN","text":"<p>\u5728 Aerodrome \u4e2d\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ece <code>gymnasium</code> \u590d\u523b\u7684 CartPole \u73af\u5883\uff0c\u5e76\u4f7f\u7528\u6700\u57fa\u7840\u7684 DQN \u7b97\u6cd5\u8fdb\u884c\u8bad\u7ec3\u3002\u7528\u6237\u53ef\u4ee5\u5728\u8fd9\u4e2a\u7b80\u5355\u7684\u73af\u5883\u4e0a\u8bd5\u9a8c\u81ea\u5df1\u7684\u7b97\u6cd5\uff0c\u4ee5\u9a8c\u8bc1\u4ee3\u7801\u7684\u6b63\u786e\u6027\u3002</p> <p>\u4f7f\u7528\u5230\u7684\u4ee3\u7801\uff1a</p> <ul> <li>C++ \u73af\u5883\uff1a <code>src/simulator/CartPole/envs/CartPoleEnv.h</code></li> <li>Python \u73af\u5883\uff1a <code>python/aerodrome/envs/CartPole.py</code></li> <li>\u4ea4\u4e92\u4ee3\u7801\uff1a <code>examples/CartPole/CartPole_dqn.py</code></li> </ul>"},{"location":"cartpole_dqn/#c","title":"C++ \u73af\u5883","text":"<p>\u5012\u7acb\u6446\u4eff\u771f\uff0c\u8fc1\u79fb\u81ea <code>gymnasium</code> \u7684 CartPole\u3002\u5176\u5b9e gymnasium \u4e5f\u662f\u590d\u5236\u7684\u522b\u4eba\u7684\u4ee3\u7801</p> \u70b9\u51fb\u5c55\u5f00\u4ee3\u7801 <pre><code>class CartPoleEnv : public BaseEnv\n{\nprivate:\n    double gravity = 9.81;\n    double masscart = 1.0;\n    double masspole = 0.1;\n    double total_mass = masspole + masscart;\n    double length = 0.5; // half the pole's length\n    double polemass_length = masspole * length;\n    double force_mag = 10.0;\n    double tau = 0.02; // seconds between state updates\n    std::string kinematic_integrator = \"euler\";\n\n    double theta_threshold_radians = 12 * 2 * 3.1415926 / 360; // angle at which to fail the episode\n    double x_threshold = 2.4; // distance at which to fail the episode\n\n    double x = 0;\n    double theta = 0;\n    double x_dot = 0;\n    double theta_dot = 0;\n\n    int time_step = 0;\n    int max_steps = 200;\n    bool steps_beyond_done = false;\n\npublic:\n    CartPoleEnv() {}\n\n    ~CartPoleEnv() {}\n\n    py::object reset() override\n    {\n        py::dict result;\n        std::random_device rd;\n        std::mt19937 gen(rd());\n        std::uniform_real_distribution&lt;&gt; dis(-0.05, 0.05);\n\n        x = dis(gen);\n        x_dot = dis(gen);\n        theta = dis(gen);\n        theta_dot = dis(gen);\n        time_step = 0;\n        steps_beyond_done = false;\n\n        result[\"observation\"] = py::make_tuple(x, x_dot, theta, theta_dot);\n        result[\"info\"] = \"\";\n        return result;\n    }\n\n    py::object step(const py::object&amp; input_dict) override\n    {\n        py::dict result;\n        if (!input_dict.contains(\"action\"))\n        {\n            result[\"info\"] = \"input_dict does not contain 'action'\";\n            return result;\n        }\n\n        int action;\n        try\n        {\n            action = input_dict[\"action\"].cast&lt;int&gt;();\n        }\n        catch (const std::exception &amp;e)\n        {\n            result[\"info\"] = std::string(\"failed to convert action to int: \") + e.what();\n            return result;\n        }\n\n        if (action != 0 &amp;&amp; action != 1)\n        {\n            result[\"info\"] = \"action must be either 0 or 1\";\n            return result;\n        }\n\n        double force = action * force_mag;\n        double costheta = cos(theta);\n        double sintheta = sin(theta);\n\n        // For the interested reader:\n        // https://coneural.org/florian/papers/05_cart_pole.pdf\n        double temp = (force + polemass_length * theta_dot * theta_dot * sintheta) / total_mass;\n        double theta_acc = (gravity * sintheta - costheta * temp) / (length * (4.0 / 3.0 - masspole * costheta * costheta / total_mass));\n        double x_acc = temp - polemass_length * theta_acc * costheta / total_mass;\n\n        if (kinematic_integrator == \"euler\")\n        {\n            x = x + tau * x_dot;\n            x_dot = x_dot + tau * x_acc;\n            theta = theta + tau * theta_dot;\n            theta_dot = theta_dot + tau * theta_acc;\n        }\n        else if (kinematic_integrator == \"semi-implicit-euler\")\n        {\n            x_dot = x_dot + tau * x_acc;\n            x = x + tau * x_dot;\n            theta_dot = theta_dot + tau * theta_acc;\n            theta = theta + tau * theta_dot;\n        }\n        else\n        {\n            result[\"info\"] = \"unknown kinematic integrator\";\n            return result;\n        }\n\n        time_step ++;\n        bool terminated = ((x &lt; -x_threshold) || (x &gt; x_threshold) || (theta &lt; -theta_threshold_radians) || (theta &gt; theta_threshold_radians));\n        bool truncated = (time_step &gt;= max_steps);\n\n        double reward;\n        if (!terminated &amp;&amp; !truncated)\n        {\n            reward = 1.0;\n        }\n        else if (!steps_beyond_done)\n        {\n            if (terminated)\n            {\n                reward = 0.0;\n            }\n            else if (truncated)\n            {\n                reward = 1.0;\n            }\n            steps_beyond_done = true;\n        }\n        else\n        {\n            reward = 0.0;\n            result[\"info\"] = \"You are calling 'step()' even though this environment has already returned terminated = True. \"\n                              \"You should always call 'reset()' once you receive 'terminated = True' -- any further steps are undefined behavior.\";\n        }\n\n        result[\"observation\"] = py::make_tuple(x, x_dot, theta, theta_dot);\n        result[\"reward\"] = reward;\n        result[\"terminated\"] = terminated;\n        result[\"truncated\"] = truncated;\n\n        if (!result.contains(\"info\"))\n        {\n            result[\"info\"] = \"\";\n        }\n\n        return result;\n    }\n};\n</code></pre>"},{"location":"cartpole_dqn/#python","title":"Python \u73af\u5883","text":"<p>\u975e\u5e38\u7b80\u5355\u7684 Python \u73af\u5883\uff0c\u628a C++ \u73af\u5883\u5305\u88c5\u4e86\u4e00\u4e0b\uff0c\u628a\u8fd4\u56de\u503c\u5904\u7406\u6210 <code>gymnasium</code> \u7684\u683c\u5f0f\u3002</p> <pre><code>class CartPole(Env):\n    def __init__(self):\n        self.env = CartPoleEnv()\n\n    def reset(self):\n        output_dict = self.env.reset()\n        return output_dict[\"observation\"], output_dict[\"info\"]\n\n    def step(self, action: int):\n        input_dict = {\n            \"action\": action\n        }\n\n        output_dict = self.env.step(input_dict)\n        return output_dict[\"observation\"], output_dict[\"reward\"], output_dict[\"terminated\"], output_dict[\"truncated\"], output_dict[\"info\"]\n</code></pre>"},{"location":"cartpole_dqn/#dqn","title":"DQN","text":"<p>\u8fd9\u91cc\u5b9e\u73b0\u7684 DQN \u4ee3\u7801\u6765\u81ea <code>CleanRL</code> \u7684 DQN\uff0c\u8fdb\u884c\u4e86\u4e00\u5b9a\u7684\u7b80\u5316\uff0c\u53bb\u6389\u4e86\u7ed3\u679c\u50a8\u5b58\u7b49\u90e8\u5206\u3002</p> \u70b9\u51fb\u5c55\u5f00\u4ee3\u7801 <pre><code>import random\nimport numpy as np\nimport argparse\nfrom copy import deepcopy\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport aerodrome\n\nclass ReplayBuffer:\n    def __init__(self, buffer_size: int):\n        self.buffer_size = buffer_size\n        self.full = False\n        self.pointer = 0\n        self.obs = np.zeros((buffer_size, 4), dtype=np.float32)\n        self.act = np.zeros((buffer_size, 1), dtype=np.float32)\n        self.reward = np.zeros((buffer_size, 1), dtype=np.float32)\n        self.next_obs = np.zeros((buffer_size, 4), dtype=np.float32)\n        self.terminated = np.zeros((buffer_size, 1), dtype=np.float32)\n        self.truncated = np.zeros((buffer_size, 1), dtype=np.float32)\n\n    def push(self, obs, act, reward, next_obs, terminated, truncated):\n        self.obs[self.pointer] = obs\n        self.act[self.pointer] = act\n        self.reward[self.pointer] = reward\n        self.next_obs[self.pointer] = next_obs\n        self.terminated[self.pointer] = terminated\n        self.truncated[self.pointer] = truncated\n        self.pointer = (self.pointer + 1) % self.buffer_size\n        if not self.full and self.pointer == 0:\n            self.full = True\n\n    def sample(self, batch_size: int):\n        if self.full:\n            indices = np.random.randint(0, self.buffer_size, size=batch_size)\n        else:\n            indices = np.random.randint(0, self.pointer, size=batch_size)\n\n        data = {\n            \"obs\": self.obs[indices],\n            \"act\": self.act[indices],\n            \"reward\": self.reward[indices],\n            \"next_obs\": self.next_obs[indices],\n            \"terminated\": self.terminated[indices],\n            \"truncated\": self.truncated[indices]\n        }\n        return data\n\nclass QNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Linear(4, 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, 2),\n        )\n\n    def forward(self, x):\n        return self.network(x)\n\ndef linear_schedule(start_e, end_e, duration, t):\n    return start_e + (end_e - start_e) * min(t / duration, 1)\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--seed\", type=int, default=0,\n                        help=\"random seed of the experiment\")\n    parser.add_argument(\"--batch_size\", type=int, default=2048,\n                        help=\"the batch size of sample from the reply memory\")\n    parser.add_argument(\"--gamma\", type=float, default=0.99,\n                        help=\"discount factor\")\n    parser.add_argument(\"--tau\", type=float, default=0.1,\n                        help=\"the target network update rate\")\n    parser.add_argument(\"--target_network_frequency\", type=int, default=1_000,\n                        help=\"the frequency of target network update\")\n    parser.add_argument(\"--start_e\", type=float, default=1.0,\n                        help=\"starting epsilon\")\n    parser.add_argument(\"--end_e\", type=float, default=0.01,\n                        help=\"ending epsilon\")\n    parser.add_argument(\"--exploration_fraction\", type=float, default=0.5,\n                        help=\"the timesteps it takes to update the target network\")\n    parser.add_argument(\"--learning_rate\", type=float, default=1e-3,\n                        help=\"learning rate\")\n    parser.add_argument(\"--total_timesteps\", type=int, default=1_000_000,\n                        help=\"total number of timesteps\")\n    parser.add_argument(\"--buffer_size\", type=int, default=100_000,\n                        help=\"buffer size\")\n    parser.add_argument(\"--learning_starts\", type=int, default=10_000,\n                        help=\"timestep to start learning\")\n    parser.add_argument(\"--train_frequency\", type=int, default=10,\n                        help=\"the frequency of training\")\n    parser.add_argument(\"--device\", type=str, default=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n                        help=\"Device to run the experiment on\")\n    args = parser.parse_args()\n\n    random.seed(args.seed)\n    np.random.seed(args.seed)\n    torch.manual_seed(args.seed)\n    torch.backends.cudnn.deterministic = True\n\n    device = torch.device(args.device)\n    print(f\"Using device: {device}\")\n\n    q_network = QNetwork().to(device)\n    target_network = QNetwork().to(device)\n    target_network.load_state_dict(q_network.state_dict())\n    target_network.eval()\n\n    optimizer = optim.Adam(q_network.parameters(), lr=args.learning_rate)\n    cos_annealing_scheduler = CosineAnnealingLR(optimizer, T_max=args.total_timesteps, eta_min=args.learning_rate * 0.01)\n\n    replay_buffer = ReplayBuffer(args.buffer_size)\n\n    env = aerodrome.make(\"cartpole-v0\")\n    obs, info = env.reset()\n    obs = np.array(obs, dtype=np.float32)\n    print(obs, info)\n\n    episode_length = []\n    current_step = 0\n    for step in tqdm(range(args.total_timesteps)):\n        current_step += 1\n        epsilon = linear_schedule(args.start_e, args.end_e, args.exploration_fraction * args.total_timesteps, step)\n        if random.random() &lt; epsilon:\n            action = random.randint(0, 1)\n        else:\n            with torch.no_grad():\n                q_values = q_network(torch.from_numpy(obs).unsqueeze(0).to(device))\n                action = torch.argmax(q_values, dim=1).cpu().numpy().item()\n\n        next_obs, reward, terminated, truncated, info = env.step(action)\n        next_obs = np.array(next_obs, dtype=np.float32)\n\n        real_next_obs = deepcopy(next_obs)\n        replay_buffer.push(obs, action, reward, real_next_obs, terminated, truncated)\n\n        obs = next_obs\n\n        if step &gt; args.learning_starts:\n            if step % args.train_frequency == 0:\n                batch = replay_buffer.sample(args.batch_size)\n                batch[\"obs\"] = torch.from_numpy(batch[\"obs\"]).to(device)\n                batch[\"act\"] = torch.from_numpy(batch[\"act\"]).to(device)\n                batch[\"reward\"] = torch.from_numpy(batch[\"reward\"]).to(device)\n                batch[\"next_obs\"] = torch.from_numpy(batch[\"next_obs\"]).to(device)\n                batch[\"terminated\"] = torch.from_numpy(batch[\"terminated\"]).to(device)\n                batch[\"truncated\"] = torch.from_numpy(batch[\"truncated\"]).to(device)\n\n                with torch.no_grad():\n                    target_max, _ = target_network(batch[\"next_obs\"]).max(dim=1, keepdim=True)\n                    td_target = batch[\"reward\"] + args.gamma * (1 - batch[\"terminated\"]) * target_max - 10.0 * batch[\"terminated\"]\n\n                old_val = q_network(batch[\"obs\"])\n                old_val = old_val.gather(1, batch[\"act\"].long())\n\n                loss = F.mse_loss(td_target, old_val)\n\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n\n            if step % args.target_network_frequency == 0:\n                for target_param, param in zip(target_network.parameters(), q_network.parameters()):\n                    target_param.data.copy_(args.tau * param.data + (1 - args.tau) * target_param.data)\n\n        cos_annealing_scheduler.step()\n\n        if terminated or truncated:\n            obs, info = env.reset()\n            obs = np.array(obs, dtype=np.float32)\n            episode_length.append((step, current_step))\n            current_step = 0\n\n    episode_length = np.array(episode_length)\n    fig, ax = plt.subplots()\n    ax.plot(episode_length[:, 0], episode_length[:, 1], alpha=0.5, c=\"skyblue\")\n    moving_average = np.convolve(episode_length[:, 1], np.ones(100) / 100, mode='valid')\n    ax.plot(episode_length[99:, 0], moving_average, c=\"royalblue\")\n    ax.set_xlabel(\"steps\")\n    ax.set_ylabel(\"cumulative reward\")\n    plt.show()\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"cartpole_dqn/#_1","title":"\u8fd0\u884c\u7ed3\u679c","text":"<p>\u4ec5\u4f5c\u6f14\u793a\u7528\uff0c\u672a\u7ecf\u8fc7\u4ed4\u7ec6\u8c03\u53c2\uff0c\u53ef\u4ee5\u770b\u5230\u6709\u4e00\u5b9a\u7684\u8bad\u7ec3\u6548\u679c\u3002</p>"},{"location":"get_started/","title":"\u5b89\u88c5 Aerodrome","text":"<p>1.\u521b\u5efa\u5e76\u6fc0\u6d3b Conda \u73af\u5883</p> <pre><code>$ conda create -n aerodrome python==3.9\n$ conda activate aerodrome\n</code></pre> <p>Aerodrome \u5728 <code>python&gt;=3.9.0,&lt;3.12</code> \u4e0a\u6d4b\u8bd5\uff0c\u4f46\u6e90\u7801\u4e2d\u5305\u542b\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\uff08python/simulator \u4e0b\u7684 C++ \u7f16\u8bd1\u51fa\u7684\u6587\u4ef6\uff09\u662f\u5728 <code>python==3.9</code> \u73af\u5883\u4e0b\u751f\u6210\u7684\uff1b\u5982\u679c\u4f60\u8981\u4f7f\u7528\u5176\u5b83 python \u7248\u672c\u6216\u81ea\u5df1\u5b9e\u73b0\u7684\u73af\u5883\uff0c\u5219\u9700\u8981\u91cd\u65b0\u7f16\u8bd1\u5e76\u4fdd\u8bc1\u7f16\u8bd1\u548c\u8fd0\u884c\u65f6\u7684 python \u7248\u672c\u4e00\u81f4\u3002</p> <p>2.\u5b89\u88c5 Pytorch</p> <p>\u8fd0\u884c\u5f3a\u5316\u5b66\u4e60\u4ee3\u7801\u9700\u8981\u7528\u5230 <code>torch</code> \u5e93\uff1b\u6e90\u7801\u5728 <code>torch==2.6.0</code> \u4e0a\u6d4b\u8bd5\u8fd0\u884c\uff0c\u4f46\u7406\u8bba\u4e0a\u53ef\u4ee5\u5728\u4efb\u610f <code>torch&gt;1.0.0</code> \u4ee5\u53ca\u517c\u5bb9\u7684 CUDA \u7248\u672c\u4e0a\u8fd0\u884c\u3002\u4f8b\u5982\uff0c<code>PyTorch 2.6.0</code> \u548c <code>CUDA 11.8</code>\uff1a</p> <pre><code>$ pip install torch==2.6.0 --index-url https://download.pytorch.org/whl/cu118\n</code></pre> <p>3.\u4ece\u6e90\u4ee3\u7801\u5b89\u88c5 Aerodrome</p> <pre><code>$ git clone https://github.com/CH4ACKO3/Aerodrome.git --recursive\n$ cd Aerodrome\n$ pip install .\n</code></pre> <p>4.\u7f16\u8bd1 C++ \u90e8\u5206\u4ee3\u7801\uff08\u53ef\u9009\uff09</p> <p>\u5982\u679c\u4f60\u8981\u4f7f\u7528\u81ea\u5df1\u5b9e\u73b0\u7684\u73af\u5883\uff0c\u6216\u4f7f\u7528\u7684 python \u7248\u672c\u4e0e\u6e90\u7801\u4e2d\u4e8c\u8fdb\u5236\u6587\u4ef6\uff08<code>python==3.9</code>\uff09\u4e0d\u4e00\u81f4\uff0c\u5219\u9700\u8981\u91cd\u65b0\u7f16\u8bd1\u5e76\u5b89\u88c5\uff1a</p> <pre><code>$ cmake -B build\n$ cmake --build build\n$ pip install .\n</code></pre> <p>\u7f16\u8bd1\u65f6\u7684\u5e73\u53f0\u548c python \u7248\u672c\u4f1a\u5728\u4e8c\u8fdb\u5236\u6587\u4ef6\u540d\u4e2d\u663e\u793a\uff1b\u4f8b\u5982\uff0c<code>*.cp39-win_amd64.pyd</code> \u8868\u793a\u6587\u4ef6\u662f\u5728 Windows \u5e73\u53f0\u300164\u4f4d\u67b6\u6784\u4e0b\uff0c<code>python==3.9</code> \u73af\u5883\u4e2d\u7f16\u8bd1\u7684\u3002</p>"},{"location":"minimal_example/","title":"\u6700\u7b80\u73af\u5883","text":"<p>\u4e3a\u4e86\u65b9\u4fbf\u7528\u6237\u7406\u89e3 Aerodrome \u7684\u8fd0\u884c\u903b\u8f91\uff0c\u8fd9\u91cc\u63d0\u4f9b\u4e00\u4e2a\u6700\u7b80\u7684\u4f8b\u5b50\u3002</p> <p>\u4f7f\u7528\u5230\u7684\u4ee3\u7801\uff1a</p> <ul> <li>C++ \u73af\u5883\uff1a <code>src/simulator/MinimalExample/envs/MinimalEnv.h</code></li> <li>Pybind11 \u7ed1\u5b9a\uff1a <code>src/simulator/MinimalExample/envs/MinimalEnv.cpp</code></li> <li>Python \u73af\u5883\uff1a <code>python/aerodrome/envs/Minimal.py</code></li> <li>\u4ea4\u4e92\u4ee3\u7801\uff1a <code>examples/MinimalExample/MinimalExample.py</code></li> </ul>"},{"location":"minimal_example/#c","title":"C++ \u73af\u5883","text":"<pre><code>class MinimalEnv : public BaseEnv { // \u7ee7\u627f\u81ea BaseEnv\npublic:\n    MinimalEnv() : cpp_state(0) {} // \u521d\u59cb\u5316 cpp_state \u4e3a 0\n\n    ~MinimalEnv() {} // \u6790\u6784\u51fd\u6570\n\n    py::object reset() override // \u91cd\u5199 BaseEnv \u4e2d\u5b9a\u4e49\u7684 reset \u65b9\u6cd5\n    {\n        py::dict result; // \u521b\u5efa\u4e00\u4e2a\u5b57\u5178\u6765\u5b58\u50a8\u8981\u8fd4\u56de\u7684\u7ed3\u679c\n        cpp_state = 0; // \u5c06 cpp_state \u91cd\u7f6e\u4e3a 0\n        result[\"cpp_state\"] = cpp_state;\n        result[\"info\"] = \"\";\n        return result;\n    }\n\n    py::object step(const py::object&amp; action) override // step \u65b9\u6cd5\u4ece Python \u7aef\u63a5\u6536\u52a8\u4f5c\n    {\n        // \u5728\u6bcf\u4e00\u6b65\u4e2d\uff0c\u73af\u5883\u5c06 action[\"value\"] \u7684\u503c\u52a0\u5230\u5176 cpp_state \u4e0a\n        py::dict result;\n        if (action.contains(\"value\"))\n        {\n            try {\n                int value = action[\"value\"].cast&lt;int&gt;(); // \u5c06 action[\"value\"] \u7684\u503c\u8f6c\u6362\u4e3a\u6574\u6570\n                cpp_state += value; // \u5c06\u8be5\u503c\u52a0\u5230 cpp_state \u4e0a\n            } catch (const std::exception &amp;e) {\n                result[\"info\"] = std::string(\"failed to convert value to int: \") + e.what(); // \u5982\u679c\u8be5\u503c\u4e0d\u662f\u6574\u6570\uff0c\u5728\u7ed3\u679c\u4e2d\u6dfb\u52a0\u9519\u8bef\u4fe1\u606f\n            }\n        }\n        else\n        {\n            result[\"info\"] = \"error: action must contain 'value'\";\n        }\n\n        result[\"cpp_state\"] = cpp_state;\n        if (!result.contains(\"info\"))\n        {\n            // \u5982\u679c\u7ed3\u679c\u4e2d\u6ca1\u6709 info \u952e\uff0c\u6dfb\u52a0\u4e00\u4e2a\u7a7a\u5b57\u7b26\u4e32\uff0c\u4ee5\u907f\u514d key error\n            result[\"info\"] = \"\";\n        }\n        return result;\n    }\n\nprivate:\n    int cpp_state = 0; // \u79c1\u6709\u6210\u5458\u53d8\u91cf\uff0c\u7528\u4e8e\u5b58\u50a8\u73af\u5883\u7684\u72b6\u6001\n};\n</code></pre>"},{"location":"minimal_example/#python","title":"Python \u73af\u5883","text":"<pre><code>class Minimal(Env):\n    def __init__(self):\n        self.env = MinimalEnv() # \u521d\u59cb\u5316 C++ \u73af\u5883\n        self.state = 0 # \u521d\u59cb\u5316 Python \u73af\u5883\u5185\u90e8\u72b6\u6001\n        print(\"Initialize MinimalEnv\")\n\n    def step(self, action):\n        self.state += 1 # \u5728\u6bcf\u4e00\u6b65\u4e2d\uff0cPython \u73af\u5883\u5185\u90e8\u72b6\u6001\u52a0 1\n        try:\n            input_dict = {\n                \"value\": action, # \u5c06 Python \u73af\u5883\u63a5\u6536\u5230\u7684\u6574\u6570\u8f6c\u6362\u4e3a\u52a8\u4f5c\u5b57\u5178\n            }\n            result = self.env.step(input_dict) # \u8c03\u7528 C++ \u73af\u5883\u7684 step \u65b9\u6cd5\uff0c\u5e76\u63a5\u6536\u8fd4\u56de\u7ed3\u679c\n            result[\"py_state\"] = self.state # \u5c06 Python \u73af\u5883\u5185\u90e8\u72b6\u6001\u6dfb\u52a0\u5230\u8fd4\u56de\u7ed3\u679c\u4e2d\n            return result\n        except ValueError:\n            print(\"input a valid integer\")\n        except KeyboardInterrupt:\n            print(\"\\nquit\")\n\n    def reset(self):\n        self.state = 0 # \u91cd\u7f6e Python \u73af\u5883\u5185\u90e8\u72b6\u6001\n        print(\"Reset MinimalEnv\")\n        result = self.env.reset() # \u8c03\u7528 C++ \u73af\u5883\u7684 reset \u65b9\u6cd5\uff0c\u5e76\u63a5\u6536\u8fd4\u56de\u7ed3\u679c\n        result[\"py_state\"] = self.state # \u5c06 Python \u73af\u5883\u5185\u90e8\u72b6\u6001\u6dfb\u52a0\u5230\u8fd4\u56de\u7ed3\u679c\u4e2d\n        return result\n\n    def close(self):\n        print(\"Close MinimalEnv\") # \u5728\u6709\u4e9b\u60c5\u51b5\u4e0b\uff0c\u53ef\u80fd\u9700\u8981\u5728\u5173\u95ed\u73af\u5883\u65f6\u8fdb\u884c\u4e00\u4e9b\u6e05\u7406\u5de5\u4f5c\n</code></pre>"},{"location":"minimal_example/#_2","title":"\u4ea4\u4e92\u4ee3\u7801","text":"<pre><code>if __name__ == \"__main__\":\n    env = aerodrome.make(\"minimal-v0\") # \u521b\u5efa Python \u73af\u5883\n    result = env.reset() # \u91cd\u7f6e\u73af\u5883\n    print(result) # \u6253\u5370\u91cd\u7f6e\u540e\u8fd4\u56de\u7684\u7ed3\u679c\n\n    while True:\n        try:\n            action = input(\"Enter an action value: \") # \u4ece\u7528\u6237\u8f93\u5165\u83b7\u53d6\u52a8\u4f5c\uff08\u4e00\u4e2a\u6574\u6570\uff09\n        except KeyboardInterrupt:\n            env.close()\n            break\n\n        try:\n            action = int(action) # \u5c06\u7528\u6237\u8f93\u5165\u7684\u52a8\u4f5c\u8f6c\u6362\u4e3a\u6574\u6570\n        except ValueError:\n            print(\"Invalid action value\")\n            continue\n        result = env.step(action) # \u8c03\u7528\u73af\u5883 step \u65b9\u6cd5\uff0c\u5e76\u63a5\u6536\u8fd4\u56de\u7ed3\u679c\n        print(result) # \u6253\u5370\u8fd4\u56de\u7ed3\u679c\n\n        if result[\"py_state\"] &gt; 10: # \u5982\u679c Python \u73af\u5883\u5185\u90e8\u72b6\u6001\u5927\u4e8e 10\uff08\u5927\u4e8e 10 \u6b65\uff09\uff0c\u5219\u91cd\u7f6e\u73af\u5883\n            result = env.reset()\n            print(result)\n</code></pre>"},{"location":"minimal_example/#_3","title":"\u8fd0\u884c\u7ed3\u679c","text":"<pre><code>$ python examples/MinimalExample/MinimalExample.py\nInitialize MinimalEnv\nReset MinimalEnv\n{'cpp_state': 0, 'info': '', 'py_state': 0}\nEnter an action value: 2\n{'cpp_state': 2, 'info': '', 'py_state': 1}\nEnter an action value: 12\n{'cpp_state': 14, 'info': '', 'py_state': 2}\nEnter an action value: 18\n{'cpp_state': 32, 'info': '', 'py_state': 3}\nEnter an action value: Close MinimalEnv\n</code></pre>"},{"location":"minimal_example/#pybind11","title":"Pybind11 \u7ed1\u5b9a","text":"<p>\u5982\u679c\u4f60\u9700\u8981\u81ea\u5df1\u5b9e\u73b0\u73af\u5883\uff0c\u5e94\u5f53\u6309\u7167\u5982\u4e0b\u683c\u5f0f\u5199\u597d\u7ed1\u5b9a\u4ee3\u7801\uff0c\u6216\u53c2\u8003 <code>pybind11</code> \u7684 \u5b98\u65b9\u6587\u6863\u3002 <pre><code>PYBIND11_MODULE(MinimalEnv, m) {\n    py::class_&lt;MinimalEnv, BaseEnv&gt;(m, \"MinimalEnv\")\n        .def(py::init&lt;&gt;())\n        .def(\"reset\", &amp;MinimalEnv::reset)\n        .def(\"step\", &amp;MinimalEnv::step);\n}\n</code></pre></p>"},{"location":"project_structure/","title":"\u9879\u76ee\u7ed3\u6784","text":"<p>Aerodrome \u7531 C++ \u548c Python \u4e24\u90e8\u5206\u7ec4\u6210\uff1b\u5176\u4e2d C++ \u51fd\u6570/\u7c7b\u9700\u8981\u5148\u901a\u8fc7 <code>pybind11</code> \u7f16\u8bd1\u4e3a <code>.pyd</code> \u6216 <code>.so</code> \u6587\u4ef6\uff0c\u518d\u88ab Python \u4ee3\u7801\u8c03\u7528\u3002</p> <pre><code>./Aerodrome\n\u251c\u2500docs                              # \u9879\u76ee\u6587\u6863\n\u251c\u2500examples                          # \u793a\u4f8b\n\u2502  \u251c\u2500AircraftControl       \n\u2502  \u2502  \u251c\u2500 StepResponse.py            # \u4f20\u7edf\u63a7\u5236\u548c\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u7684\u9636\u8dc3\u54cd\u5e94\u6bd4\u8f83\n\u2502  |  \u251c\u2500 WingedCone_Classic.py      # \u4f20\u7edf\u63a7\u5236\u65b9\u6cd5(\u76f4\u63a5\u8c03\u7528 C++ \u4ee3\u7801)\n\u2502  |  \u251c\u2500 WingedCone_PPO.py          # \u5f3a\u5316\u5b66\u4e60\u63a7\u5236(C++ \u4eff\u771f/ Python \u4ea4\u4e92\u73af\u5883)\n\u2502  |  \u2514\u2500 WingedCone_TimeCompare.py  # C++ \u548c Python \u4eff\u771f\u8fd0\u884c\u901f\u5ea6\u6bd4\u8f83\n\u2502  \u251c\u2500CartPole                       # DQN \u5b9e\u73b0\u7684 CartPole \u63a7\u5236\n\u2502  \u2514\u2500MinimalExample                 # \u6700\u7b80\u793a\u4f8b\u73af\u5883\n\u251c\u2500include\n\u2502  \u2514\u2500pybind11\n\u251c\u2500models                            # \u9884\u8bad\u7ec3\u6a21\u578b\n\u251c\u2500python                            # Python \u6e90\u7801\n\u2502  \u251c\u2500aerodrome \n\u2502  \u2502  \u251c\u2500envs                        # \u4ea4\u4e92\u73af\u5883\uff0c\u5904\u7406\u7528\u6237\u548cC++\u4eff\u771f\u4e4b\u95f4\u7684\u4fe1\u606f\u4ea4\u4e92\n\u2502  \u2502  \u2514\u2500simulator                   # \u7f16\u8bd1\u597d\u7684 C++ \u4ee3\u7801\u4f1a\u81ea\u52a8\u5b58\u653e\u5230\u6b64\u5904\n\u2502  \u2502      \u251c\u2500CanonicalAircraftEnv \n\u2502  \u2502      \u2502  \u251c\u2500envs                 # \u73af\u5883\u7c7b(\u901a\u5e38\u60c5\u51b5\u4e0b\u73af\u5883\u548c\u5b9e\u4f53\u662f\u4f5c\u4e3a\u4e0d\u540c\u7c7b\u7f16\u5199\u7684)\n\u2502  \u2502      \u2502  \u2514\u2500objects              # \u5b9e\u4f53\u7c7b\n\u2502  \u2502      \u251c\u2500CartPole\n\u2502  \u2502      \u2502  \u2514\u2500envs\n\u2502  \u2502      \u251c\u2500Core\n\u2502  \u2502      \u2502  \u251c\u2500envs\n\u2502  \u2502      \u2502  \u2514\u2500objects\n\u2502  \u2502      \u2514\u2500MinimalExample\n\u2502  \u2502          \u2514\u2500envs\n\u2502  \u2514\u2500aerodrome.egg-info\n\u2514\u2500src                              # C++ \u6e90\u7801\n   \u2514\u2500simulator\n       \u251c\u2500CanonicalAircraftEnv\n       \u2502  \u251c\u2500envs\n       \u2502  \u2514\u2500objects\n       \u251c\u2500CartPole\n       \u2502  \u251c\u2500envs\n       \u2502  \u2514\u2500objects\n       \u251c\u2500Core\n       \u2502  \u251c\u2500envs\n       \u2502  \u2514\u2500objects\n       \u2514\u2500MinimalExample\n           \u251c\u2500envs\n           \u2514\u2500objects\n</code></pre>"},{"location":"en/","title":"Aerodrome - Overview","text":"<p>Aerodrome is a lightweight library based on the joint programming of C++ and Python, focusing on providing high-performance dynamics simulation, Python interaction interfaces, and code examples for reinforcement learning and traditional control. It primarily targets two types of users: beginners in reinforcement learning research, or researchers who wish to apply reinforcement learning to specific fields (such as flight control) and need custom simulation environments. To ensure good modifiability and readability, every part of Aerodrome avoids the use of complex generic programming or advanced language features, and includes detailed comments in the code.</p> <p>The main contents and features of Aerodrome include:</p> <ul> <li> <p>Mimicking the code and interface style of Gym</p> </li> <li> <p>An example environment and a migrated version of Gym-CartPole for testing the correctness of reinforcement learning algorithms</p> </li> <li> <p>Highly customizable fixed-wing aircraft simulation example code</p> </li> <li> <p>A nonlinear aerodynamic model of the Winged-Cone based on publicly available data, along with its dynamics simulation (available in both C++ and Python, including performance comparisons!)</p> </li> <li> <p>Traditional three-loop autopilot implementation and Proximal Policy Optimization (PPO) implementation for longitudinal load control of the Winged-Cone</p> </li> </ul> <p>Note Aerodrome is not a modular library, therefore it is not suitable for import and use. Aerodrome sacrifices some code duplication to ensure that all code is concise, easy to understand, and convenient to extend. Aerodrome also has its limitations, such as the lack of visualization and experimental result saving functions; if you need specific reinforcement learning algorithm examples, you can refer to the CleanRL library; if you need to implement other aircraft models (or even environments in other fields), you can modify the Aerodrome code or rewrite it entirely!</p>"},{"location":"en/get_started/","title":"Install Aerodrome","text":"<p>1.Create and activate conda environment</p> <pre><code>$ conda create -n aerodrome python==3.9\n$ conda activate aerodrome\n</code></pre> <p>Aerodrome has been tested on <code>python&gt;=3.9.0,&lt;3.12</code>, but the binary files included in the source code (C++ compiled files under <code>python/simulator</code>) were generated in a <code>python==3.9</code> environment. If you intend to use a different Python version or your own custom environment, you will need to recompile the binaries and ensure that the Python versions used for compilation and runtime are consistent.</p> <p>2.Install Pytorch</p> <p>Running reinforcement learning code requires the use of the <code>torch</code> library; the source code has been tested on <code>torch==2.6.0</code>, but theoretically, it can run on any <code>torch&gt;1.0.0</code> and compatible CUDA versions. For example, <code>PyTorch 2.6.0</code> with <code>CUDA 11.8</code>:</p> <pre><code>$ pip install torch==2.6.0 --index-url https://download.pytorch.org/whl/cu118\n</code></pre> <p>3.Install Aerodrome from source</p> <pre><code>$ git clone https://github.com/CH4ACKO3/Aerodrome.git --recursive\n$ cd Aerodrome\n$ pip install .\n</code></pre> <p>4.Compiling the C++ Code (Optional)</p> <p>If you intend to use a custom environment or a Python version that differs from the one used to generate the binary files in the source code (<code>python==3.9</code>), you will need to recompile and install the code:</p> <pre><code>$ cmake -B build\n$ cmake --build build\n$ pip install .\n</code></pre> <p>The platform and Python version used during compilation will be reflected in the binary file names. For example, a file named <code>*.cp39-win_amd64.pyd</code> indicates that it was compiled on a Windows platform with a 64-bit architecture and in a <code>python==3.9</code> environment.</p>"},{"location":"en/project_structure/","title":"Project Structure","text":"<p>Aerodrome consists of both C++ and Python components. The C++ functions/classes need to be compiled into <code>.pyd</code> files using <code>pybind11</code> first, after which they can be called by the Python code.</p> <pre><code>./Aerodrome\n\u251c\u2500docs                              # Project Documentation\n\u251c\u2500examples                          # Examples\n\u2502  \u251c\u2500AircraftControl       \n\u2502  \u2502  \u251c\u2500 StepResponse.py            # Comparison of Step Response Between Traditional Control and Reinforcement Learning Control\n\u2502  |  \u251c\u2500 WingedCone_Classic.py      # Traditional Control Method (Directly Calling C++ Code)\n\u2502  |  \u251c\u2500 WingedCone_PPO.py          # Reinforcement Learning Control (C++ Simulation / Python Interaction Environment)\n\u2502  |  \u2514\u2500 WingedCone_TimeCompare.py  # Comparison of Simulation Execution Speed Between C++ and Python\n\u2502  \u251c\u2500CartPole                       # DQN Implementation for CartPole Control\n\u2502  \u2514\u2500MinimalExample                 # Minimal Example Environment\n\u251c\u2500include\n\u2502  \u2514\u2500pybind11\n\u251c\u2500models                            # Pre-trained Models\n\u251c\u2500python                            # Python Source Code\n\u2502  \u251c\u2500aerodrome \n\u2502  \u2502  \u251c\u2500envs                        # Interaction Environment, Handling Information Exchange Between User and C++ Simulation\n\u2502  \u2502  \u2514\u2500simulator                   # Compiled C++ Code Will Be Automatically Stored Here\n\u2502  \u2502      \u251c\u2500CanonicalAircraftEnv \n\u2502  \u2502      \u2502  \u251c\u2500envs                 # Environment Class (Typically, Environment and Entity Are Written as Separate Classes)\n\u2502  \u2502      \u2502  \u2514\u2500objects              # Entity Class\n\u2502  \u2502      \u251c\u2500CartPole\n\u2502  \u2502      \u2502  \u2514\u2500envs\n\u2502  \u2502      \u251c\u2500Core\n\u2502  \u2502      \u2502  \u251c\u2500envs\n\u2502  \u2502      \u2502  \u2514\u2500objects\n\u2502  \u2502      \u2514\u2500MinimalExample\n\u2502  \u2502          \u2514\u2500envs\n\u2502  \u2514\u2500aerodrome.egg-info\n\u2514\u2500src                              # C++ Source Code\n   \u2514\u2500simulator\n       \u251c\u2500CanonicalAircraftEnv\n       \u2502  \u251c\u2500envs\n       \u2502  \u2514\u2500objects\n       \u251c\u2500CartPole\n       \u2502  \u251c\u2500envs\n       \u2502  \u2514\u2500objects\n       \u251c\u2500Core\n       \u2502  \u251c\u2500envs\n       \u2502  \u2514\u2500objects\n       \u2514\u2500MinimalExample\n           \u251c\u2500envs\n           \u2514\u2500objects\n</code></pre>"}]}