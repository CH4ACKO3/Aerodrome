{"config":{"lang":["en","zh"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Aerodrome - \u6982\u8ff0","text":"<p>Aerodrome \u662f\u4e00\u4e2a\u57fa\u4e8e C++ \u548c Python \u8054\u5408\u7f16\u7a0b\u7684\u8f7b\u91cf\u7ea7\u5e93\uff0c\u4e13\u6ce8\u4e8e\u63d0\u4f9b\u9ad8\u6027\u80fd\u52a8\u529b\u5b66\u4eff\u771f\u3001Python \u4ea4\u4e92\u63a5\u53e3\u4ee5\u53ca\u5f3a\u5316\u5b66\u4e60\u548c\u4f20\u7edf\u63a7\u5236\u7684\u4ee3\u7801\u793a\u4f8b\u3002\u5b83\u4e3b\u8981\u9762\u5411\u4e24\u7c7b\u7528\u6237\uff1a\u521d\u5b66\u5f3a\u5316\u5b66\u4e60\u7684\u7814\u7a76\u8005\uff0c\u6216\u5e0c\u671b\u5c06\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u7279\u5b9a\u9886\u57df\uff08\u5982\u98de\u63a7\uff09\u5e76\u9700\u8981\u81ea\u5b9a\u4e49\u4eff\u771f\u73af\u5883\u7684\u7814\u7a76\u8005\u3002\u4e3a\u4e86\u786e\u4fdd\u826f\u597d\u7684\u53ef\u4fee\u6539\u6027\u548c\u53ef\u8bfb\u6027\uff0cAerodrome \u7684\u6bcf\u4e2a\u90e8\u5206\u90fd\u5c3d\u91cf\u907f\u514d\u4f7f\u7528\u590d\u6742\u7684\u6cdb\u578b\u7f16\u7a0b\u6216\u9ad8\u7ea7\u8bed\u8a00\u7279\u6027\uff0c\u5e76\u5728\u4ee3\u7801\u4e2d\u4f5c\u4e86\u8be6\u5c3d\u7684\u6ce8\u91ca\u3002</p> <p>Aerodrome \u7684\u4e3b\u8981\u5185\u5bb9\u548c\u7279\u70b9\u5305\u62ec\uff1a</p> <ul> <li> <p>\u4eff\u7167 Gym \u7684\u4ee3\u7801\u548c\u63a5\u53e3\u98ce\u683c</p> </li> <li> <p>\u4e00\u4e2a\u793a\u4f8b\u73af\u5883\u548c\u8fc1\u79fb\u7248\u7684 Gym-CartPole \uff0c\u7528\u4e8e\u6d4b\u8bd5\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u6b63\u786e\u6027</p> </li> <li> <p>\u9ad8\u5ea6\u53ef\u81ea\u5b9a\u4e49\u7684\u56fa\u5b9a\u7ffc\u98de\u884c\u5668\u4eff\u771f\u793a\u4f8b\u4ee3\u7801</p> </li> <li> <p>\u57fa\u4e8e\u516c\u5f00\u8d44\u6599\u7684 Winged-Cone \u975e\u7ebf\u6027\u6c14\u52a8\u6a21\u578b\uff0c\u4ee5\u53ca\u5176\u52a8\u529b\u5b66\u4eff\u771f\uff08C++ \u548c Python \u4e24\u79cd\u8bed\u8a00\u7248\u672c\uff0c\u5e76\u5305\u542b\u8fd0\u884c\u6027\u80fd\u5bf9\u6bd4\uff01\uff09</p> </li> <li> <p>Winged-Cone \u7eb5\u5411\u8fc7\u8f7d\u63a7\u5236\u7684\u4f20\u7edf\u4e09\u56de\u8def\u9a7e\u9a76\u4eea\u5b9e\u73b0\u548c \u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO \uff09\u5b9e\u73b0</p> </li> </ul> <p>Note Aerodrome \u4e0d\u662f \u4e00\u4e2a\u6a21\u5757\u5316\u5e93\uff0c\u56e0\u6b64\u5b83\u5e76\u4e0d\u9002\u5408\u88ab\u5bfc\u5165\u4f7f\u7528\u3002Aerodrome \u4ee5\u90e8\u5206\u4ee3\u7801\u91cd\u590d\u4e3a\u4ee3\u4ef7\uff0c\u5c3d\u91cf\u4f7f\u5f97\u6240\u6709\u4ee3\u7801\u7b80\u6d01\u3001\u6613\u4e8e\u7406\u89e3\u4e14\u65b9\u4fbf\u6269\u5c55\u3002Aerodrome \u4e5f\u6709\u5176\u5c40\u9650\u6027\uff0c\u4f8b\u5982\u7f3a\u5c11\u53ef\u89c6\u5316\u548c\u5b9e\u9a8c\u7ed3\u679c\u4fdd\u5b58\u529f\u80fd\uff1b\u5982\u679c\u4f60\u9700\u8981\u7279\u5b9a\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u793a\u4f8b\uff0c\u53ef\u4ee5\u53c2\u8003 CleanRL \u5e93\uff1b\u5982\u679c\u4f60\u9700\u8981\u5b9e\u73b0\u5176\u5b83\u98de\u884c\u5668\u6a21\u578b\uff08\u6216\u8005\u751a\u81f3\u5176\u5b83\u9886\u57df\u7684\u73af\u5883\uff09\uff0c\u53ef\u4ee5\u5728 Aerodrome \u4ee3\u7801\u57fa\u7840\u4e0a\u4fee\u6539\uff0c\u6216\u8005\u5b8c\u5168\u91cd\u5199\uff01</p>"},{"location":"basics/","title":"\u57fa\u7840\u903b\u8f91\u548c\u7c7b","text":""},{"location":"basics/#_1","title":"\u57fa\u7840\u8fd0\u884c\u903b\u8f91","text":"<p>\u5728 Aerodrome \u4e2d\uff0c\u4e00\u4e2a\u5178\u578b\u7684 C++/Python \u8054\u5408\u7f16\u7a0b\u73af\u5883\u7684\u7ed3\u6784\u5982\u56fe\uff1a</p> <p>\u901a\u5e38\u6765\u8bf4\uff0cC++ \u73af\u5883\u7c7b\u76f4\u63a5\u7ba1\u7406 C++ \u5b9e\u4f53\u7684\u521d\u59cb\u5316\u3001\u8fd0\u884c\uff0c\u5e76\u5728\u9700\u8981\u65f6\u8bfb\u53d6\u5176\u4fe1\u606f\u5e76\u8f93\u51fa\uff1b Python \u73af\u5883\u7c7b\u5219\u8d1f\u8d23\u5904\u7406\u7528\u6237\u8f93\u5165\u3001C++ \u73af\u5883\u7684\u8f93\u51fa\uff08\u4f8b\u5982\uff0c\u6570\u636e\u7c7b\u578b\u7684\u5fc5\u8981\u8f6c\u6362\uff09\u7b49\uff1b</p> <p>\u5f53\u7136\uff0c\u8fd9\u79cd\u8bbe\u8ba1\u5e76\u4e0d\u662f\u5f3a\u5236\u7684\uff0c\u7528\u6237\u5b8c\u5168\u53ef\u4ee5\u6839\u636e\u9700\u8981\u81ea\u884c\u8bbe\u8ba1\uff0c\u4f8b\u5982\u4e0b\u9762\u4e24\u79cd\u90fd\u662f\u53ef\u884c\u7684\uff1a</p> \u8df3\u8fc7 Python \u73af\u5883\u7c7b\uff0c\u76f4\u63a5\u4ece C++ \u73af\u5883\u7c7b\u83b7\u53d6\u8f93\u51fa \u5728 Python \u4e2d\u76f4\u63a5\u5b9e\u73b0\u6240\u6709\u529f\u80fd"},{"location":"basics/#c","title":"C++ \u57fa\u7840\u7c7b","text":"<p>\u5728 Aerodrome \u4e2d\uff0c\u6709\u4e24\u4e2a\u6700\u57fa\u672c\u7684\u7c7b\u578b\uff0c\u53ef\u4ee5\u5728 <code>src/simulator/Core</code> \u4e2d\u627e\u5230\uff1a</p> <ul> <li><code>BaseEnv</code>\uff1a\u6240\u6709\u73af\u5883\u7684\u57fa\u7c7b\uff0c\u5b9a\u4e49\u4e86\u6240\u6709\u73af\u5883\u5171\u6709\u7684\u63a5\u53e3\uff1b</li> <li><code>Object3D</code>\uff1a\u6240\u6709\u4e09\u7ef4\u5bf9\u8c61\u7684\u57fa\u7c7b\uff0c\u5b9a\u4e49\u4e86\u4e09\u7ef4\u5bf9\u8c61\u7684\u901a\u7528\u5c5e\u6027\uff0c\u4f8b\u5982\u901f\u5ea6\u3001\u4f4d\u7f6e\u3001\u59ff\u6001\u7b49\uff1b</li> </ul> <p>\u5173\u4e8e pybind11 \u4ee3\u7801\u5b9e\u73b0</p> <p>\u7531\u4e8e pybind11 \u5728\u7f16\u8bd1\u65b9\u9762\u7684\u9650\u5236\uff0c\u76ee\u524d C++ \u4ee3\u7801 pybind \u7ed1\u5b9a\u7684\u5b9e\u73b0\u65b9\u5f0f\u662f\u5c06\u51fd\u6570/\u7c7b\u7684\u5b9a\u4e49\u548c\u5b9e\u73b0\u90fd\u5199\u5728 <code>.h</code> \u6587\u4ef6\u4e2d\uff1bpybind \u7ed1\u5b9a\u5219\u5199\u5728\u540c\u540d\u7684 <code>.cpp</code> \u6587\u4ef6\u4e2d\u3002</p> <p>\u5982\u679c\u6709\u66f4\u597d\u7684\u5b9e\u73b0\u65b9\u5f0f\uff0c\u975e\u5e38\u6b22\u8fce\u63d0\u51fa issue \u6216 PR\uff01</p>"},{"location":"basics/#baseenv","title":"BaseEnv","text":"<p>\u5728 BaseEnv \u4e2d\uff0c\u5b9a\u4e49\u4e86\u6240\u6709\u73af\u5883\u5171\u6709\u7684\u63a5\u53e3\uff0c\u5305\u62ec\uff1a</p> <ul> <li><code>reset()</code>\uff1a\u91cd\u7f6e\u73af\u5883\uff1b</li> <li><code>step(action)</code>\uff1a\u6267\u884c\u4e00\u6b65\u52a8\u4f5c\uff0c\u5e76\u8fd4\u56de\u4fe1\u606f\uff08\u4f8b\u5982\uff0c\u89c2\u6d4b\u3001\u5956\u52b1\u3001\u7ec8\u6b62\u7b49\uff09\uff1b</li> </ul> \u70b9\u51fb\u5c55\u5f00\u4ee3\u7801 BaseEnv.h<pre><code>class BaseEnv\n{\npublic:\n    BaseEnv() = default;\n    virtual ~BaseEnv() = default;\n\n    virtual py::object reset() = 0;\n    virtual py::object step(const py::object&amp; action) = 0;\n};\n</code></pre>"},{"location":"basics/#object3d","title":"Object3D","text":"<p>Object3D \u7684\u5185\u5bb9\u5219\u8f83\u591a\uff0c\u5305\u62ec\uff1a</p> <ul> <li>\u4f4d\u7f6e\u3001\u901f\u5ea6\u3001\u59ff\u6001\u7b49\u57fa\u672c\u5c5e\u6027\uff1b</li> <li>\u5c06\u81ea\u8eab\u5c5e\u6027\u8f93\u51fa\u4e3a\u5b57\u5178\u7684\u65b9\u6cd5\uff1b</li> <li>\u91cd\u7f6e\u81ea\u8eab\u5c5e\u6027\u7684\u65b9\u6cd5\uff1b</li> <li>\u8ba1\u7b97\u81ea\u8eab\u52a8\u529b\u5b66\u5bfc\u6570\u7684\u65b9\u6cd5\uff1b</li> <li>\u8fdb\u884c\u4e00\u6b65\u4eff\u771f\u7684\u65b9\u6cd5\uff1b</li> </ul> <p>\u4e3a\u4e86\u51c6\u786e\u65b9\u4fbf\u5730\u8ba1\u7b97\u81ea\u8eab\u7684\u52a8\u529b\u5b66\u5bfc\u6570\u5e76\u8fdb\u884c\u4eff\u771f\uff0c\u8fd8\u5bf9\u8fd0\u7b97\u7b26\u8fdb\u884c\u4e86\u91cd\u8f7d\u3002 \u5728\u540e\u9762\u4f1a\u770b\u5230\uff0c\u5bf9\u4e8e\u6d3e\u751f\u7c7b\uff0c\u4ee3\u7801\u5f88\u5927\u7a0b\u5ea6\u4e0a\u662f\u53ef\u4ee5\u590d\u7528\u7684\uff0c\u53ea\u9700\u8981\u91cd\u5199\u5c11\u91cf\u4ee3\u7801\u5c31\u53ef\u4ee5\u5b9e\u73b0\u4e00\u4e2a\u6b63\u786e\u4e14\u89c4\u8303\u7684\u7269\u7406\u5bf9\u8c61\u3002</p> <p>\u5173\u4e8e\u59ff\u6001\u8868\u793a</p> <p>Aerodrome \u4e2d\u91c7\u7528\u7684\u59ff\u6001\u63cf\u8ff0\u662f\u6b27\u62c9\u89d2\u6cd5\uff0c\u4f1a\u6709\u6b7b\u9501\u95ee\u9898\uff1b\u4f60\u4e5f\u53ef\u4ee5\u81ea\u5df1\u5b9e\u73b0\u4e00\u4e2a\u65cb\u8f6c\u77e9\u9635\u6216\u56db\u5143\u6570\u7b49\u5176\u5b83\u8868\u793a\u6cd5\u3002</p> \u70b9\u51fb\u5c55\u5f00\u4ee3\u7801 Object3D.h<pre><code>class Object3D {\npublic:\n    std::string name;\n    std::string integrator;\n\n    // \u4f4d\u7f6e\u5750\u6807\uff08\u5730\u9762\u7cfb\uff09\n    std::array&lt;double, 3&gt; pos;\n\n    // \u901f\u5ea6\u5411\u91cf\uff08\u5730\u9762\u7cfb\uff09\n    std::array&lt;double, 3&gt; vel;\n\n    // \u89d2\u901f\u5ea6\u5411\u91cf\uff08\u5f39\u4f53\u7cfb\uff09\n    std::array&lt;double, 3&gt; ang_vel;\n\n    // \u8f6c\u52a8\u60ef\u91cf\n    std::array&lt;double, 3&gt; J;\n\n    double V; // \u901f\u5ea6\n\n    // \u63cf\u8ff0\u521a\u4f53\u59ff\u6001\u7684\u516b\u4e2a\u89d2\u5ea6\n    double theta;    // \u4fef\u4ef0\u89d2\n    double phi;      // \u504f\u822a\u89d2\n    double gamma;    // \u503e\u659c\u89d2\n    double theta_v;  // \u901f\u5ea6\u503e\u89d2\n    double phi_v;    // \u901f\u5ea6\u504f\u89d2\n    double alpha;    // \u653b\u89d2\n    double beta;     // \u4fa7\u6ed1\u89d2\n    double gamma_v;  // \u901f\u5ea6\u503e\u659c\u89d2\n\n    py::dict initial_state;\n\n    Object3D() {}\n\n    Object3D(py::dict input_dict)\n    {\n        name = input_dict[\"name\"].cast&lt;std::string&gt;();\n        integrator = input_dict[\"integrator\"].cast&lt;std::string&gt;();\n        pos = input_dict[\"pos\"].cast&lt;std::array&lt;double, 3&gt;&gt;();\n        vel = input_dict[\"vel\"].cast&lt;std::array&lt;double, 3&gt;&gt;();\n        ang_vel = input_dict[\"ang_vel\"].cast&lt;std::array&lt;double, 3&gt;&gt;();\n        J = input_dict[\"J\"].cast&lt;std::array&lt;double, 3&gt;&gt;();\n        // V = input_dict[\"V\"].cast&lt;double&gt;();\n        V = sqrt(vel[0] * vel[0] + vel[1] * vel[1] + vel[2] * vel[2]);\n        theta = input_dict[\"theta\"].cast&lt;double&gt;();\n        phi = input_dict[\"phi\"].cast&lt;double&gt;();\n        gamma = input_dict[\"gamma\"].cast&lt;double&gt;();\n        theta_v = input_dict[\"theta_v\"].cast&lt;double&gt;();\n        phi_v = input_dict[\"phi_v\"].cast&lt;double&gt;();\n        gamma_v = input_dict[\"gamma_v\"].cast&lt;double&gt;();\n        alpha = input_dict[\"alpha\"].cast&lt;double&gt;();\n        beta = input_dict[\"beta\"].cast&lt;double&gt;();\n\n        initial_state = input_dict;\n    }\n\n    virtual void reset()\n    {\n        *this = Object3D(initial_state);\n    }\n\n    virtual py::dict to_dict()\n    {\n        py::dict output_dict;\n        output_dict[\"pos\"] = pos;\n        output_dict[\"vel\"] = vel;\n        output_dict[\"ang_vel\"] = ang_vel;\n        output_dict[\"J\"] = J;\n        output_dict[\"V\"] = V;\n        output_dict[\"theta\"] = theta;\n        output_dict[\"phi\"] = phi;\n        output_dict[\"gamma\"] = gamma;\n        output_dict[\"theta_v\"] = theta_v;\n        output_dict[\"phi_v\"] = phi_v;\n        output_dict[\"alpha\"] = alpha;\n        output_dict[\"beta\"] = beta;\n        output_dict[\"gamma_v\"] = gamma_v;\n        output_dict[\"name\"] = name;\n        return output_dict;\n    }\n\n    virtual py::object step(py::dict action)\n    {\n        double dt = action[\"dt\"].cast&lt;double&gt;();\n\n        pos = action[\"pos\"].cast&lt;std::array&lt;double, 3&gt;&gt;();\n        vel = action[\"vel\"].cast&lt;std::array&lt;double, 3&gt;&gt;();\n        ang_vel = action[\"ang_vel\"].cast&lt;std::array&lt;double, 3&gt;&gt;();\n        J = action[\"J\"].cast&lt;std::array&lt;double, 3&gt;&gt;();\n        // V = action[\"V\"].cast&lt;double&gt;();\n        V = sqrt(vel[0] * vel[0] + vel[1] * vel[1] + vel[2] * vel[2]);\n        theta = action[\"theta\"].cast&lt;double&gt;();\n        phi = action[\"phi\"].cast&lt;double&gt;();\n        gamma = action[\"gamma\"].cast&lt;double&gt;();\n        theta_v = action[\"theta_v\"].cast&lt;double&gt;();\n        phi_v = action[\"phi_v\"].cast&lt;double&gt;();\n        gamma_v = action[\"gamma_v\"].cast&lt;double&gt;();\n        alpha = action[\"alpha\"].cast&lt;double&gt;();\n        beta = action[\"beta\"].cast&lt;double&gt;();\n\n        if (integrator == \"euler\")\n        {\n            *this = *this + this-&gt;d() * dt;\n        }\n        else if (integrator == \"midpoint\")\n        {\n            auto temp1 = *this + this-&gt;d() * (0.5 * dt);\n            auto k1 = temp1.d();\n            *this = *this + k1 * dt;\n        }\n        else if (integrator == \"rk23\")\n        {\n            auto k1 = this-&gt;d();\n            auto temp1 = *this + k1 * (0.5 * dt);\n            auto k2 = temp1.d();\n            auto temp2 = *this + k2 * (0.5 * dt);\n            auto k3 = temp2.d();\n            *this = *this + (k1 + k2 * 2 + k3) * (dt / 4);\n        }\n        else if (integrator == \"rk45\")\n        {\n            auto k1 = this-&gt;d();\n            auto temp1 = *this + k1 * (0.5 * dt);\n            auto k2 = temp1.d();\n            auto temp2 = *this + k2 * (0.5 * dt);\n            auto k3 = temp2.d();\n            auto temp3 = *this + k3 * dt;\n            auto k4 = temp3.d();\n            *this = *this + (k1 + k2 * 2 + k3 * 2 + k4) * (dt / 6);\n        }\n\n        theta_v = atan2(vel[1], sqrt(vel[0] * vel[0] + vel[2] * vel[2]));\n        phi_v = atan2(-vel[2], vel[0]);\n\n        beta = cos(theta_v) * (cos(gamma) * sin(phi - phi_v) + sin(theta) * sin(gamma) * cos(phi - phi_v)) - sin(theta_v) * cos(theta) * sin(gamma);\n        alpha = (cos(theta_v) * (sin(theta) * cos(gamma) * cos(phi - phi_v) - sin(gamma) * sin(phi - phi_v)) - sin(theta_v) * cos(theta) * cos(gamma)) / cos(beta);\n        gamma_v = (cos(alpha) * sin(beta) * sin(theta) - sin(alpha) * sin(beta) * cos(gamma) * cos(theta) + cos(beta) * sin(gamma) * cos(theta)) / cos(theta_v);\n\n        V = sqrt(vel[0] * vel[0] + vel[1] * vel[1] + vel[2] * vel[2]);\n        return to_dict();\n    }\n\n    virtual Object3D d()\n    {\n        auto derivative = *this;\n\n        derivative.pos[0] = vel[0];\n        derivative.pos[1] = vel[1];\n        derivative.pos[2] = vel[2];\n\n        derivative.vel[0] = 0;\n        derivative.vel[1] = 0;\n        derivative.vel[2] = 0;\n\n        derivative.ang_vel[0] = 0;\n        derivative.ang_vel[1] = 0;\n        derivative.ang_vel[2] = 0;\n\n        derivative.theta = ang_vel[1] * sin(gamma) + ang_vel[2] * cos(gamma);\n        derivative.phi = (ang_vel[1] * cos(gamma) - ang_vel[2] * sin(gamma)) / cos(theta);\n        derivative.gamma = ang_vel[0] * - tan(theta) * (ang_vel[1] * cos(gamma) - ang_vel[2] * sin(gamma));\n\n        derivative.theta_v = 0;\n        derivative.phi_v = 0;\n        derivative.gamma_v = 0;\n\n        derivative.alpha = 0;\n        derivative.beta = 0;\n\n        return derivative;\n    }\n\n    template&lt;typename T, typename P&gt;\n    friend T operator+(const T&amp; lop, const P&amp; rop)\n    {\n        auto result = lop;\n\n        for (int i = 0; i &lt; 3; ++i)\n        {   \n            result.pos[i] = lop.pos[i] + rop.pos[i];\n            result.vel[i] = lop.vel[i] + rop.vel[i];\n            result.ang_vel[i] = lop.ang_vel[i] + rop.ang_vel[i];\n        }   \n\n        result.V = lop.V + rop.V;\n        result.theta = lop.theta + rop.theta;\n        result.phi = lop.phi + rop.phi;\n        result.gamma = lop.gamma + rop.gamma;\n        result.theta_v = lop.theta_v + rop.theta_v;\n        result.phi_v = lop.phi_v + rop.phi_v; \n        result.alpha = lop.alpha + rop.alpha;\n        result.beta = lop.beta + rop.beta;\n        result.gamma_v = lop.gamma_v + rop.gamma_v;\n\n        return result;\n    }\n\n    template&lt;typename T, typename P&gt;\n    friend T operator-(const T&amp; lop, const P&amp; rop)\n    {\n        auto result = lop;\n\n        for (int i = 0; i &lt; 3; ++i)\n        {\n            result.pos[i] = lop.pos[i] - rop.pos[i];\n            result.vel[i] = lop.vel[i] - rop.vel[i];\n            result.ang_vel[i] = lop.ang_vel[i] - rop.ang_vel[i];\n        }\n\n        result.V = lop.V - rop.V;\n        result.theta = lop.theta - rop.theta;\n        result.phi = lop.phi - rop.phi;\n        result.gamma = lop.gamma - rop.gamma;\n        result.theta_v = lop.theta_v - rop.theta_v;\n        result.phi_v = lop.phi_v - rop.phi_v;\n        result.alpha = lop.alpha - rop.alpha;\n        result.beta = lop.beta - rop.beta;\n        result.gamma_v = lop.gamma_v - rop.gamma_v;\n\n        return result;\n    }\n\n    template&lt;typename T&gt;\n    friend T operator*(const T&amp; lop, const double&amp; rop)\n    {\n        auto result = lop;\n\n        for (int i = 0; i &lt; 3; ++i)\n        {\n            result.pos[i] = lop.pos[i] * rop; \n            result.vel[i] = lop.vel[i] * rop;\n            result.ang_vel[i] = lop.ang_vel[i] * rop;\n        }   \n\n        result.V = lop.V * rop;\n        result.theta = lop.theta * rop;\n        result.phi = lop.phi * rop;\n        result.gamma = lop.gamma * rop;\n        result.theta_v = lop.theta_v * rop;\n        result.phi_v = lop.phi_v * rop;\n        result.alpha = lop.alpha * rop;\n        result.beta = lop.beta * rop;\n        result.gamma_v = lop.gamma_v * rop;\n\n        return result;\n    }\n\n    template&lt;typename T&gt;\n    friend T operator/(const T&amp; lop, const double&amp; rop)\n    {\n        auto result = lop;\n\n        for (int i = 0; i &lt; 3; ++i)\n        {\n            result.pos[i] = lop.pos[i] / rop; \n            result.vel[i] = lop.vel[i] / rop;\n            result.ang_vel[i] = lop.ang_vel[i] / rop;\n        }   \n\n        result.V = lop.V / rop;\n        result.theta = lop.theta / rop;\n        result.phi = lop.phi / rop;\n        result.gamma = lop.gamma / rop;\n        result.theta_v = lop.theta_v / rop;\n        result.phi_v = lop.phi_v / rop;   \n        result.alpha = lop.alpha / rop;\n        result.beta = lop.beta / rop;\n        result.gamma_v = lop.gamma_v / rop;\n\n        return result;\n    }\n};\n</code></pre>"},{"location":"cartpole_dqn/","title":"CartPole \u548c DQN","text":"<p>\u5728 Aerodrome \u4e2d\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ece <code>gymnasium</code> \u590d\u523b\u7684 CartPole \u73af\u5883\uff0c\u5e76\u4f7f\u7528\u6700\u57fa\u7840\u7684 DQN \u7b97\u6cd5\u8fdb\u884c\u8bad\u7ec3\u3002\u7528\u6237\u53ef\u4ee5\u5728\u8fd9\u4e2a\u7b80\u5355\u7684\u73af\u5883\u4e0a\u8bd5\u9a8c\u81ea\u5df1\u7684\u7b97\u6cd5\uff0c\u4ee5\u9a8c\u8bc1\u4ee3\u7801\u7684\u6b63\u786e\u6027\u3002</p> <p>\u4f7f\u7528\u5230\u7684\u4ee3\u7801\uff1a</p> <ul> <li>C++ \u73af\u5883\uff1a <code>src/simulator/CartPole/envs/CartPoleEnv.h</code></li> <li>Python \u73af\u5883\uff1a <code>python/aerodrome/envs/CartPole.py</code></li> <li>\u4ea4\u4e92\u4ee3\u7801\uff1a <code>examples/CartPole/CartPole_dqn.py</code></li> </ul>"},{"location":"cartpole_dqn/#c","title":"C++ \u73af\u5883","text":"<p>\u5012\u7acb\u6446\u4eff\u771f\uff0c\u8fc1\u79fb\u81ea <code>gymnasium</code> \u7684 CartPole\u3002\u5176\u5b9e gymnasium \u4e5f\u662f\u590d\u5236\u7684\u522b\u4eba\u7684\u4ee3\u7801</p> \u70b9\u51fb\u5c55\u5f00\u4ee3\u7801 CartPoleEnv.h<pre><code>class CartPoleEnv : public BaseEnv\n{\nprivate:\n    double gravity = 9.81;\n    double masscart = 1.0;\n    double masspole = 0.1;\n    double total_mass = masspole + masscart;\n    double length = 0.5; // half the pole's length\n    double polemass_length = masspole * length;\n    double force_mag = 10.0;\n    double tau = 0.02; // seconds between state updates\n    std::string kinematic_integrator = \"euler\";\n\n    double theta_threshold_radians = 12 * 2 * 3.1415926 / 360; // angle at which to fail the episode\n    double x_threshold = 2.4; // distance at which to fail the episode\n\n    double x = 0;\n    double theta = 0;\n    double x_dot = 0;\n    double theta_dot = 0;\n\n    int time_step = 0;\n    int max_steps = 200;\n    bool steps_beyond_done = false;\n\npublic:\n    CartPoleEnv() {}\n\n    ~CartPoleEnv() {}\n\n    py::object reset() override\n    {\n        py::dict result;\n        std::random_device rd;\n        std::mt19937 gen(rd());\n        std::uniform_real_distribution&lt;&gt; dis(-0.05, 0.05);\n\n        x = dis(gen);\n        x_dot = dis(gen);\n        theta = dis(gen);\n        theta_dot = dis(gen);\n        time_step = 0;\n        steps_beyond_done = false;\n\n        result[\"observation\"] = py::make_tuple(x, x_dot, theta, theta_dot);\n        result[\"info\"] = \"\";\n        return result;\n    }\n\n    py::object step(const py::object&amp; input_dict) override\n    {\n        py::dict result;\n        if (!input_dict.contains(\"action\"))\n        {\n            result[\"info\"] = \"input_dict does not contain 'action'\";\n            return result;\n        }\n\n        int action;\n        try\n        {\n            action = input_dict[\"action\"].cast&lt;int&gt;();\n        }\n        catch (const std::exception &amp;e)\n        {\n            result[\"info\"] = std::string(\"failed to convert action to int: \") + e.what();\n            return result;\n        }\n\n        if (action != 0 &amp;&amp; action != 1)\n        {\n            result[\"info\"] = \"action must be either 0 or 1\";\n            return result;\n        }\n\n        double force = action * force_mag;\n        double costheta = cos(theta);\n        double sintheta = sin(theta);\n\n        // For the interested reader:\n        // https://coneural.org/florian/papers/05_cart_pole.pdf\n        double temp = (force + polemass_length * theta_dot * theta_dot * sintheta) / total_mass;\n        double theta_acc = (gravity * sintheta - costheta * temp) / (length * (4.0 / 3.0 - masspole * costheta * costheta / total_mass));\n        double x_acc = temp - polemass_length * theta_acc * costheta / total_mass;\n\n        if (kinematic_integrator == \"euler\")\n        {\n            x = x + tau * x_dot;\n            x_dot = x_dot + tau * x_acc;\n            theta = theta + tau * theta_dot;\n            theta_dot = theta_dot + tau * theta_acc;\n        }\n        else if (kinematic_integrator == \"semi-implicit-euler\")\n        {\n            x_dot = x_dot + tau * x_acc;\n            x = x + tau * x_dot;\n            theta_dot = theta_dot + tau * theta_acc;\n            theta = theta + tau * theta_dot;\n        }\n        else\n        {\n            result[\"info\"] = \"unknown kinematic integrator\";\n            return result;\n        }\n\n        time_step ++;\n        bool terminated = ((x &lt; -x_threshold) || (x &gt; x_threshold) || (theta &lt; -theta_threshold_radians) || (theta &gt; theta_threshold_radians));\n        bool truncated = (time_step &gt;= max_steps);\n\n        double reward;\n        if (!terminated &amp;&amp; !truncated)\n        {\n            reward = 1.0;\n        }\n        else if (!steps_beyond_done)\n        {\n            if (terminated)\n            {\n                reward = 0.0;\n            }\n            else if (truncated)\n            {\n                reward = 1.0;\n            }\n            steps_beyond_done = true;\n        }\n        else\n        {\n            reward = 0.0;\n            result[\"info\"] = \"You are calling 'step()' even though this environment has already returned terminated = True. \"\n                              \"You should always call 'reset()' once you receive 'terminated = True' -- any further steps are undefined behavior.\";\n        }\n\n        result[\"observation\"] = py::make_tuple(x, x_dot, theta, theta_dot);\n        result[\"reward\"] = reward;\n        result[\"terminated\"] = terminated;\n        result[\"truncated\"] = truncated;\n\n        if (!result.contains(\"info\"))\n        {\n            result[\"info\"] = \"\";\n        }\n\n        return result;\n    }\n};\n</code></pre>"},{"location":"cartpole_dqn/#python","title":"Python \u73af\u5883","text":"<p>\u975e\u5e38\u7b80\u5355\u7684 Python \u73af\u5883\uff0c\u628a C++ \u73af\u5883\u5305\u88c5\u4e86\u4e00\u4e0b\uff0c\u628a\u8fd4\u56de\u503c\u5904\u7406\u6210 <code>gymnasium</code> \u7684\u683c\u5f0f\u3002</p> CartPole.py<pre><code>class CartPole(Env):\n    def __init__(self):\n        self.env = CartPoleEnv()\n\n    def reset(self):\n        output_dict = self.env.reset()\n        return output_dict[\"observation\"], output_dict[\"info\"]\n\n    def step(self, action: int):\n        input_dict = {\n            \"action\": action\n        }\n\n        output_dict = self.env.step(input_dict)\n        return output_dict[\"observation\"], output_dict[\"reward\"], output_dict[\"terminated\"], output_dict[\"truncated\"], output_dict[\"info\"]\n</code></pre>"},{"location":"cartpole_dqn/#dqn","title":"DQN","text":"<p>\u8fd9\u91cc\u5b9e\u73b0\u7684 DQN \u4ee3\u7801\u6765\u81ea <code>CleanRL</code> \u7684 DQN\uff0c\u8fdb\u884c\u4e86\u4e00\u5b9a\u7684\u7b80\u5316\uff0c\u53bb\u6389\u4e86\u7ed3\u679c\u50a8\u5b58\u7b49\u90e8\u5206\u3002</p> \u70b9\u51fb\u5c55\u5f00\u4ee3\u7801 CartPole_dqn.py<pre><code>import random\nimport numpy as np\nimport argparse\nfrom copy import deepcopy\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport aerodrome\n\nclass ReplayBuffer:\n    def __init__(self, buffer_size: int):\n        self.buffer_size = buffer_size\n        self.full = False\n        self.pointer = 0\n        self.obs = np.zeros((buffer_size, 4), dtype=np.float32)\n        self.act = np.zeros((buffer_size, 1), dtype=np.float32)\n        self.reward = np.zeros((buffer_size, 1), dtype=np.float32)\n        self.next_obs = np.zeros((buffer_size, 4), dtype=np.float32)\n        self.terminated = np.zeros((buffer_size, 1), dtype=np.float32)\n        self.truncated = np.zeros((buffer_size, 1), dtype=np.float32)\n\n    def push(self, obs, act, reward, next_obs, terminated, truncated):\n        self.obs[self.pointer] = obs\n        self.act[self.pointer] = act\n        self.reward[self.pointer] = reward\n        self.next_obs[self.pointer] = next_obs\n        self.terminated[self.pointer] = terminated\n        self.truncated[self.pointer] = truncated\n        self.pointer = (self.pointer + 1) % self.buffer_size\n        if not self.full and self.pointer == 0:\n            self.full = True\n\n    def sample(self, batch_size: int):\n        if self.full:\n            indices = np.random.randint(0, self.buffer_size, size=batch_size)\n        else:\n            indices = np.random.randint(0, self.pointer, size=batch_size)\n\n        data = {\n            \"obs\": self.obs[indices],\n            \"act\": self.act[indices],\n            \"reward\": self.reward[indices],\n            \"next_obs\": self.next_obs[indices],\n            \"terminated\": self.terminated[indices],\n            \"truncated\": self.truncated[indices]\n        }\n        return data\n\nclass QNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Linear(4, 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, 2),\n        )\n\n    def forward(self, x):\n        return self.network(x)\n\ndef linear_schedule(start_e, end_e, duration, t):\n    return start_e + (end_e - start_e) * min(t / duration, 1)\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--seed\", type=int, default=0,\n                        help=\"random seed of the experiment\")\n    parser.add_argument(\"--batch_size\", type=int, default=2048,\n                        help=\"the batch size of sample from the reply memory\")\n    parser.add_argument(\"--gamma\", type=float, default=0.99,\n                        help=\"discount factor\")\n    parser.add_argument(\"--tau\", type=float, default=0.1,\n                        help=\"the target network update rate\")\n    parser.add_argument(\"--target_network_frequency\", type=int, default=1_000,\n                        help=\"the frequency of target network update\")\n    parser.add_argument(\"--start_e\", type=float, default=1.0,\n                        help=\"starting epsilon\")\n    parser.add_argument(\"--end_e\", type=float, default=0.01,\n                        help=\"ending epsilon\")\n    parser.add_argument(\"--exploration_fraction\", type=float, default=0.5,\n                        help=\"the timesteps it takes to update the target network\")\n    parser.add_argument(\"--learning_rate\", type=float, default=1e-3,\n                        help=\"learning rate\")\n    parser.add_argument(\"--total_timesteps\", type=int, default=1_000_000,\n                        help=\"total number of timesteps\")\n    parser.add_argument(\"--buffer_size\", type=int, default=100_000,\n                        help=\"buffer size\")\n    parser.add_argument(\"--learning_starts\", type=int, default=10_000,\n                        help=\"timestep to start learning\")\n    parser.add_argument(\"--train_frequency\", type=int, default=10,\n                        help=\"the frequency of training\")\n    parser.add_argument(\"--device\", type=str, default=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n                        help=\"Device to run the experiment on\")\n    args = parser.parse_args()\n\n    random.seed(args.seed)\n    np.random.seed(args.seed)\n    torch.manual_seed(args.seed)\n    torch.backends.cudnn.deterministic = True\n\n    device = torch.device(args.device)\n    print(f\"Using device: {device}\")\n\n    q_network = QNetwork().to(device)\n    target_network = QNetwork().to(device)\n    target_network.load_state_dict(q_network.state_dict())\n    target_network.eval()\n\n    optimizer = optim.Adam(q_network.parameters(), lr=args.learning_rate)\n    cos_annealing_scheduler = CosineAnnealingLR(optimizer, T_max=args.total_timesteps, eta_min=args.learning_rate * 0.01)\n\n    replay_buffer = ReplayBuffer(args.buffer_size)\n\n    env = aerodrome.make(\"cartpole-v0\")\n    obs, info = env.reset()\n    obs = np.array(obs, dtype=np.float32)\n    print(obs, info)\n\n    episode_length = []\n    current_step = 0\n    for step in tqdm(range(args.total_timesteps)):\n        current_step += 1\n        epsilon = linear_schedule(args.start_e, args.end_e, args.exploration_fraction * args.total_timesteps, step)\n        if random.random() &lt; epsilon:\n            action = random.randint(0, 1)\n        else:\n            with torch.no_grad():\n                q_values = q_network(torch.from_numpy(obs).unsqueeze(0).to(device))\n                action = torch.argmax(q_values, dim=1).cpu().numpy().item()\n\n        next_obs, reward, terminated, truncated, info = env.step(action)\n        next_obs = np.array(next_obs, dtype=np.float32)\n\n        real_next_obs = deepcopy(next_obs)\n        replay_buffer.push(obs, action, reward, real_next_obs, terminated, truncated)\n\n        obs = next_obs\n\n        if step &gt; args.learning_starts:\n            if step % args.train_frequency == 0:\n                batch = replay_buffer.sample(args.batch_size)\n                batch[\"obs\"] = torch.from_numpy(batch[\"obs\"]).to(device)\n                batch[\"act\"] = torch.from_numpy(batch[\"act\"]).to(device)\n                batch[\"reward\"] = torch.from_numpy(batch[\"reward\"]).to(device)\n                batch[\"next_obs\"] = torch.from_numpy(batch[\"next_obs\"]).to(device)\n                batch[\"terminated\"] = torch.from_numpy(batch[\"terminated\"]).to(device)\n                batch[\"truncated\"] = torch.from_numpy(batch[\"truncated\"]).to(device)\n\n                with torch.no_grad():\n                    target_max, _ = target_network(batch[\"next_obs\"]).max(dim=1, keepdim=True)\n                    td_target = batch[\"reward\"] + args.gamma * (1 - batch[\"terminated\"]) * target_max - 10.0 * batch[\"terminated\"]\n\n                old_val = q_network(batch[\"obs\"])\n                old_val = old_val.gather(1, batch[\"act\"].long())\n\n                loss = F.mse_loss(td_target, old_val)\n\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n\n            if step % args.target_network_frequency == 0:\n                for target_param, param in zip(target_network.parameters(), q_network.parameters()):\n                    target_param.data.copy_(args.tau * param.data + (1 - args.tau) * target_param.data)\n\n        cos_annealing_scheduler.step()\n\n        if terminated or truncated:\n            obs, info = env.reset()\n            obs = np.array(obs, dtype=np.float32)\n            episode_length.append((step, current_step))\n            current_step = 0\n\n    episode_length = np.array(episode_length)\n    fig, ax = plt.subplots()\n    ax.plot(episode_length[:, 0], episode_length[:, 1], alpha=0.5, c=\"skyblue\")\n    moving_average = np.convolve(episode_length[:, 1], np.ones(100) / 100, mode='valid')\n    ax.plot(episode_length[99:, 0], moving_average, c=\"royalblue\")\n    ax.set_xlabel(\"steps\")\n    ax.set_ylabel(\"cumulative reward\")\n    plt.show()\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"cartpole_dqn/#_1","title":"\u8fd0\u884c\u7ed3\u679c","text":"<p>\u4ec5\u4f5c\u6f14\u793a\u7528\uff0c\u672a\u7ecf\u8fc7\u4ed4\u7ec6\u8c03\u53c2\uff0c\u53ef\u4ee5\u770b\u5230\u6709\u4e00\u5b9a\u7684\u8bad\u7ec3\u6548\u679c\u3002</p>"},{"location":"fixed_wing_template/","title":"\u56fa\u5b9a\u7ffc\u98de\u884c\u5668\u6a21\u677f","text":"<p>\u5728 Aerodrome \u4e2d\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e2a\u56fa\u5b9a\u7ffc\u98de\u884c\u5668\u7684\u6a21\u677f\u7c7b <code>Aircraft3D</code>\uff0c\u8be5\u7c7b\u7ee7\u627f\u81ea <code>Object3D</code> \u7c7b\uff0c\u5e76\u589e\u52a0\u4e86\u4e00\u4e9b\u7528\u4e8e\u63cf\u8ff0\u56fa\u5b9a\u7ffc\u98de\u884c\u5668\u7279\u6027\u7684\u5c5e\u6027\u3002</p> <p>\u4f7f\u7528\u5230\u7684\u4ee3\u7801\uff1a</p> <ul> <li>Aircraft3D\uff1a <code>src/simulator/Core/objects/Aircraft3D.h</code></li> </ul>"},{"location":"fixed_wing_template/#aircraft3d","title":"Aircraft3D","text":"<p>\u53ef\u4ee5\u770b\u5230\uff0c<code>Aircraft3D</code> \u7c7b\u589e\u52a0\u4e86\u4e00\u4e9b\u63cf\u8ff0\u56fa\u5b9a\u7ffc\u98de\u884c\u5668\u7279\u6027\u7684\u5c5e\u6027\uff0c\u5e76\u590d\u5199\u4e86\u4e00\u4e9b\u65b9\u6cd5\uff0c\u4f46\u6ca1\u6709\u65b0\u589e\u7684\u65b9\u6cd5\u3002\u540e\u9762\u4f1a\u8be6\u7ec6\u89e3\u91ca\u6bcf\u4e2a\u65b9\u6cd5\u7684\u5185\u5bb9\u3002</p> Aircraft3D.h<pre><code>class Aircraft3D : public Object3D {\npublic:\n    double S; // \u53c2\u8003\u9762\u79ef\n    double c; // \u7279\u5f81\u957f\u5ea6\n    double m; // \u8d28\u91cf\n\n    double h; // \u9ad8\u5ea6\n    double q; // \u52a8\u538b\n\n    double Rho; // \u7a7a\u6c14\u5bc6\u5ea6\n    double Tem; // \u6e29\u5ea6\n    double Pres; // \u538b\u529b\n    double a; // \u58f0\u901f\n    double g; // \u91cd\u529b\u52a0\u901f\u5ea6\n\n    double L; // \u5347\u529b\n    double D; // \u963b\u529b\n    double N; // \u4fa7\u529b\n    double T; // \u63a8\u529b\n    std::array&lt;double, 3&gt; M; // \u529b\u77e9\n\n    Aircraft3D() {} // \u9ed8\u8ba4\u6784\u9020\u51fd\u6570\n\n    Aircraft3D(py::dict input_dict) : Object3D(input_dict); // \u4ece\u5b57\u5178\u6784\u9020\n\n    virtual void reset() override; // \u91cd\u7f6e\n\n    virtual py::dict to_dict() override; // \u5c5e\u6027\u8f6c\u6362\u4e3a\u5b57\u5178\n\n    virtual py::object step(py::dict action) override; // \u6b65\u8fdb\n\n    virtual Object3D d() override; // \u8fd0\u52a8\u5b66\u5bfc\u6570\n}\n</code></pre>"},{"location":"fixed_wing_template/#_2","title":"\u6784\u9020\u51fd\u6570","text":"<p><code>Aircraft3D</code> \u7684\u6784\u9020\u51fd\u6570\u63a5\u6536\u4e00\u4e2a\u53c2\u6570\u5b57\u5178 <code>input_dict</code>\uff0c\u5176\u4e2d\u5305\u542b\u6784\u9020 <code>Object3D</code> \u7c7b\u6240\u9700\u7684\u53c2\u6570\uff0c\u4ee5\u53ca <code>Aircraft3D</code> \u7c7b\u65b0\u589e\u7684\u53c2\u6570\u3002</p> <p>\u5927\u6c14\u5c5e\u6027\u7684\u8ba1\u7b97</p> <p>\u6784\u9020\u51fd\u6570\u548c\u4e4b\u540e\u4f7f\u7528\u5230\u7684\u8ba1\u7b97\u5927\u6c14\u5c5e\u6027\uff08\u5982\u5bc6\u5ea6\u3001\u58f0\u901f\u7b49\uff09\u7684\u51fd\u6570\u53c2\u8003\u81ea\u516c\u5f00\u8d44\u6599\uff0c\u5177\u4f53\u5b9e\u73b0\u89c1 <code>src/simulator/y_atmosphere.h</code>\u3002</p> <pre><code>Aircraft3D(py::dict input_dict) : Object3D(input_dict) // \u8c03\u7528\u7236\u7c7b\u6784\u9020\u51fd\u6570\uff0c`Object3D` \u7684\u6784\u9020\u51fd\u6570\u4f1a\u4ece `input_dict` \u4e2d\u8bfb\u53d6\u5176\u9700\u8981\u7684\u503c\n{\n    V = sqrt(vel[0] * vel[0] + vel[1] * vel[1] + vel[2] * vel[2]); // \u4ece\u4f20\u5165\u53c2\u6570\u7684\u901f\u5ea6\u5206\u91cf\u81ea\u52a8\u8ba1\u7b97\u901f\u5ea6\n    h = pos[1]; // \u81ea\u52a8\u8ba1\u7b97\u9ad8\u5ea6\uff08\u8fd9\u91cc\u5047\u8bbe\u98de\u884c\u5668\u5728\u5c0f\u8303\u56f4\u5185\u98de\u884c\uff0c\u4e0d\u8003\u8651\u5730\u9762\u66f2\u7387\uff0c\u56e0\u6b64\u9ad8\u5ea6\u7b49\u4e8e y \u5750\u6807\uff09\n    S = input_dict[\"S\"].cast&lt;double&gt;(); // \u53c2\u8003\u9762\u79ef\n    c = input_dict[\"c\"].cast&lt;double&gt;(); // \u7279\u5f81\u957f\u5ea6\n    m = input_dict[\"m\"].cast&lt;double&gt;(); // \u8d28\u91cf\uff08\u4e5f\u53ef\u4ee5\u5b9a\u4e49\u4e3a\u521d\u59cb\u8d28\u91cf\uff09\n\n    Tem = Temperature(h); // \u6839\u636e\u9ad8\u5ea6\u8ba1\u7b97\u6e29\u5ea6\n    Pres = Pressure(h); // \u6839\u636e\u9ad8\u5ea6\u8ba1\u7b97\u538b\u529b\n    Rho = Density(Tem, Pres); // \u6839\u636e\u6e29\u5ea6\u548c\u538b\u529b\u8ba1\u7b97\u5bc6\u5ea6\n    a = SpeedofSound(Tem); // \u6839\u636e\u6e29\u5ea6\u8ba1\u7b97\u58f0\u901f\n    g = Gravity(h); // \u6839\u636e\u9ad8\u5ea6\u8ba1\u7b97\u91cd\u529b\u52a0\u901f\u5ea6\n\n    q = 0.5 * Rho * V * V; // \u8ba1\u7b97\u52a8\u538b\n\n    L = 0.0; // \u521d\u59cb\u5347\u529b\n    D = 0.0; // \u521d\u59cb\u963b\u529b\n    N = 0.0; // \u521d\u59cb\u4fa7\u529b\n    T = 0.0; // \u521d\u59cb\u63a8\u529b\n    M = {0.0, 0.0, 0.0}; // \u521d\u59cb\u529b\u77e9\n}\n</code></pre>"},{"location":"fixed_wing_template/#to_dict","title":"to_dict()","text":"<p><code>to_dict()</code> \u51fd\u6570\u5c06 <code>Aircraft3D</code> \u5b9e\u4f8b\u7684\u5c5e\u6027\u8f6c\u6362\u4e3a\u5b57\u5178\u5e76\u8f93\u51fa\uff0c\u65b9\u4fbf\u5728 Python \u4e2d\u4f7f\u7528\u3002\u5176\u9996\u5148\u8c03\u7528\u7236\u7c7b <code>Object3D</code> \u7684 <code>to_dict()</code> \u51fd\u6570\uff0c\u7136\u540e\u5c06 <code>Aircraft3D</code> \u7c7b\u65b0\u589e\u7684\u5c5e\u6027\u6dfb\u52a0\u5230\u5b57\u5178\u4e2d\u3002</p> <pre><code>virtual py::dict to_dict() override // `virtual` \u8868\u793a\u8be5\u51fd\u6570\u53ef\u4ee5\u88ab\u91cd\u5199\uff0c`override` \u8868\u793a\u91cd\u5199\u7236\u7c7b\u4e2d\u7684\u540c\u540d\u51fd\u6570\n{\n    py::dict output_dict = Object3D::to_dict(); // \u8c03\u7528\u7236\u7c7b `Object3D` \u7684 `to_dict()` \u51fd\u6570\n    output_dict[\"S\"] = S; // \u5f80 `output_dict` \u4e2d\u6dfb\u52a0 `Aircraft3D` \u7c7b\u65b0\u589e\u7684\u5c5e\u6027\n    output_dict[\"c\"] = c;\n    output_dict[\"m\"] = m;\n    output_dict[\"V\"] = V;\n    output_dict[\"h\"] = h;\n    output_dict[\"q\"] = q;\n    output_dict[\"Rho\"] = Rho;\n    output_dict[\"Tem\"] = Tem;\n    output_dict[\"Pres\"] = Pres;\n    output_dict[\"a\"] = a;\n    output_dict[\"g\"] = g;\n    output_dict[\"L\"] = L;\n    output_dict[\"D\"] = D;\n    output_dict[\"N\"] = N;\n    output_dict[\"T\"] = T;\n    output_dict[\"M\"] = M;\n    return output_dict;\n}\n</code></pre>"},{"location":"fixed_wing_template/#d","title":"d()","text":"<p><code>d()</code> \u51fd\u6570\u8ba1\u7b97 <code>Aircraft3D</code> \u5b9e\u4f8b\u7684\u8fd0\u52a8\u5b66\u5bfc\u6570\u3002\u5047\u8bbe\u4e0d\u8003\u8651\u52a0\u901f\u5ea6\u548c\u89d2\u52a0\u901f\u5ea6\u7684\u53d8\u5316\uff08\u5373\uff0c\u52a0\u901f\u5ea6\u548c\u89d2\u52a0\u901f\u5ea6\u662f\u7531\u98de\u884c\u5668\u6240\u53d7\u529b\u5f15\u8d77\u6216\u7531\u8f93\u5165\u51b3\u5b9a\u7684\uff09\uff0c\u5219\u6c42\u89e3\u4ee5\u4e0b\u51e0\u4e2a\u91cf\u7684\u5bfc\u6570\u53ef\u4ee5\u6ee1\u8db3\u8ba1\u7b97\u8981\u6c42\uff1a</p> <ul> <li>\u4f4d\u7f6e\uff08<code>pos</code>\uff09</li> <li>\u901f\u5ea6\uff08\u5305\u62ec\u901f\u5ea6\u5927\u5c0f\u548c\u89d2\u5ea6\uff0c\u5373<code>V</code>\u3001<code>theta_v</code>\u3001<code>phi_v</code>\uff09</li> <li>\u59ff\u6001\u89d2\uff08<code>theta</code>\u3001<code>phi</code>\u3001<code>gamma</code>\uff09</li> <li>\u89d2\u901f\u5ea6\uff08<code>ang_vel</code>\uff09</li> </ul> <p>\u5173\u4e8e\u98de\u884c\u5668\u59ff\u6001\u63cf\u8ff0</p> <p>\u63cf\u8ff0\u98de\u884c\u5668\u7684\u4f4d\u7f6e\u59ff\u6001\u8fd8\u6709\u5176\u5b83\u53c2\u6570\uff0c\u4f8b\u5982\u8fce\u89d2 <code>alpha</code>\u3001\u4fa7\u6ed1\u89d2 <code>beta</code> \u7b49\uff1b\u8fd8\u6709\u4e00\u4e9b\u91cf\u9700\u8981\u968f\u7740\u6b65\u8fdb\u66f4\u65b0\uff0c\u4f8b\u5982\u98de\u884c\u5668\u7684\u9ad8\u5ea6 <code>h</code>\u3001\u52a8\u538b <code>q</code> \u7b49\u3002\u4f46\u8fd9\u4e9b\u91cf\u5e76\u4e0d\u662f\u76f8\u4e92\u72ec\u7acb\u7684\uff0c \u56e0\u6b64\u53ef\u4ee5\u53ea\u6c42\u89e3\u4e0a\u8ff0\u51e0\u4e2a\u91cf\uff0c\u5728 <code>step()</code> \u51fd\u6570\u4e2d\u5b8c\u6210\u8fd0\u52a8\u5b66\u79ef\u5206\u4e4b\u540e\uff0c\u518d\u6839\u636e\u9700\u8981\u66f4\u65b0\u5176\u5b83\u91cf\u3002</p> <p>\u8fd4\u56de\u7684\u662f\u548c\u8c03\u7528\u8be5\u65b9\u6cd5\u7684\u5b9e\u4f8b\u7c7b\u578b\u76f8\u540c\u7684\u4e00\u4e2a\u65b0\u5b9e\u4f8b\uff0c\u5176\u6bcf\u4e2a\u5c5e\u6027\u7684\u503c\u662f\u539f\u5b9e\u4f8b\u5bf9\u5e94\u5c5e\u6027\u7684\u5bfc\u6570\u3002\u4f8b\u5982\uff0c\u8fd4\u56de\u5b9e\u4f8b\u7684 <code>V</code> \u5c5e\u6027\u662f\u4f20\u5165\u5b9e\u4f8b\u7684 <code>V</code> \u5c5e\u6027\u7684\u5bfc\u6570\uff0c\u5373\u52a0\u901f\u5ea6\uff08\u66f4\u51c6\u786e\u5730\u8bf4\u662f <code>V</code> \u7684\u53d8\u5316\u7387\uff09 <pre><code>virtual Object3D d() override\n{   \n    auto derivative = *this;\n\n    derivative.V = (T * cos(alpha) * cos(beta) - D - m * g * sin(theta_v)) / m;\n    derivative.theta_v = (T * (sin(alpha) * cos(gamma_v) - cos(alpha) * sin(beta) * sin(gamma_v))\n                            + L * cos(gamma_v) - N * sin(gamma_v) - m * g * cos(theta_v)) / (m * V);\n    derivative.phi_v = -(T * (sin(alpha) * sin(gamma_v) - cos(alpha) * sin(beta) * cos(gamma_v))\n                        + L * sin(gamma_v) + N * cos(gamma_v)) / (m * V * cos(theta_v));\n\n    derivative.ang_vel[0] = (M[0] - (J[2] - J[1]) * ang_vel[1] * ang_vel[2]) / J[0];\n    derivative.ang_vel[1] = (M[1] - (J[0] - J[2]) * ang_vel[2] * ang_vel[0]) / J[1];\n    derivative.ang_vel[2] = (M[2] - (J[1] - J[0]) * ang_vel[0] * ang_vel[1]) / J[2];\n\n    derivative.theta = ang_vel[1] * sin(gamma) + ang_vel[2] * cos(gamma);\n    derivative.phi = (ang_vel[1] * cos(gamma) - ang_vel[2] * sin(gamma)) / cos(theta);\n    derivative.gamma = ang_vel[0] * - tan(theta) * (ang_vel[1] * cos(gamma) - ang_vel[2] * sin(gamma));\n\n    derivative.pos[0] = V * cos(theta_v) * cos(phi_v);\n    derivative.pos[1] = V * sin(theta_v);\n    derivative.pos[2] = -V * cos(theta_v) * sin(phi_v);\n\n    return derivative;\n}\n</code></pre></p>"},{"location":"fixed_wing_template/#step","title":"step()","text":"<p><code>step()</code> \u662f\u4e0d\u540c\u98de\u884c\u5668\u7c7b\u4e2d\u53d8\u5316\u6700\u5927\u7684\u51fd\u6570\u3002<code>step()</code> \u51fd\u6570\u63a5\u6536\u4e00\u4e2a\u52a8\u4f5c\u5b57\u5178 <code>action</code>\uff0c\u5176\u4e2d\u5305\u542b\u63a7\u5236\u8f93\u5165\uff08\u5982\u63a8\u529b\u3001\u8235\u504f\u89d2\u7b49\uff0c\u6216\u8fc7\u8f7d\u6307\u4ee4\uff0c\u7531\u6d3e\u751f\u7c7b\u578b\u51b3\u5b9a\uff09\u548c\u65f6\u95f4\u6b65\u957f <code>dt</code>\u3002</p> <p>\u7531\u4e8e\u79ef\u5206\u6b65\u957f <code>dt</code> \u5728\u73af\u5883\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u6709\u53ef\u80fd\u4f1a\u53d8\u5316\uff08\u4ee5\u652f\u6301\u4e00\u4e9b\u81ea\u9002\u5e94\u6b65\u957f\u7684\u7b97\u6cd5\uff09\uff0c\u56e0\u6b64 <code>dt</code> \u5e76\u6ca1\u6709\u786c\u7f16\u7801\u5728 <code>Aircraft3D</code> \u7c7b\u7684\u5c5e\u6027\u4e2d\uff0c\u800c\u662f\u968f\u52a8\u4f5c\u4f20\u5165\u3002</p> <p>\u5728 <code>step()</code> \u51fd\u6570\u4e2d\uff0c\u7528\u6237\u9700\u8981\u6839\u636e\u52a8\u4f5c\u5b57\u5178 <code>action</code> \u4e2d\u7684\u63a7\u5236\u8f93\u5165\u66f4\u65b0\u98de\u884c\u5668\u7684\u72b6\u6001\uff0c\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\u8ba1\u7b97\u98de\u884c\u5668\u53d7\u529b\u3001\u8fd0\u52a8\u5b66\u6b65\u8fdb\u3001\u66f4\u65b0\u76f8\u5173\u53d8\u91cf\u7b49\u3002</p> <p>\u5728 <code>Aircraft3D</code> \u7c7b\u4e2d\uff0c\u98de\u884c\u5668\u6240\u53d7\u5916\u529b\uff08\u5347\u529b <code>L</code>\u3001\u963b\u529b <code>D</code>\u3001\u4fa7\u529b <code>N</code>\u3001\u63a8\u529b <code>T</code>\u3001\u529b\u77e9 <code>M</code>\uff09\u4ee5\u52a8\u4f5c\u7684\u5f62\u5f0f\u4f20\u5165\uff0c\u4ee5\u6f14\u793a\u57fa\u672c\u7684\u8ba1\u7b97\u6d41\u7a0b\u3002</p> <p>\u5173\u4e8e\u8fd0\u7b97\u7b26\u91cd\u8f7d</p> <p>\u7531\u4e8e\u5728 <code>Object3D</code> \u7c7b\u4e2d\u91cd\u8f7d\u4e86\u56db\u5219\u8fd0\u7b97\u7b26\uff0c\u5c06\u4e24\u4e2a <code>Object3D</code> \u6216 <code>Object3D</code> \u7684\u5b50\u7c7b\u4e4b\u95f4\u7684\u52a0\u51cf\u4e58\u9664\u5b9a\u4e49\u4e3a\u5176\u67d0\u4e9b\u5c5e\u6027\u7684\u5bf9\u5e94\u8fd0\u7b97\uff08\u5177\u4f53\u5b9e\u73b0\u89c1\u4e0b\u9762\u4ee3\u7801\uff09\uff0c\u5728\u52a8\u529b\u5b66\u79ef\u5206\u65f6\u53ef\u4ee5\u66f4\u65b9\u4fbf\u5730\u5904\u7406\u6570\u503c\u8ba1\u7b97\uff08\u4f8b\u5982\u6d89\u53ca\u5fae\u5206\u7684\u8fd0\u7b97\uff09\u3002</p> <pre><code>virtual py::object step(py::dict action) override // `virtual` \u8868\u793a\u8be5\u51fd\u6570\u53ef\u4ee5\u88ab\u91cd\u5199\uff0c`override` \u8868\u793a\u91cd\u5199\u7236\u7c7b\u4e2d\u7684\u540c\u540d\u51fd\u6570\n{\n    double dt = action[\"dt\"].cast&lt;double&gt;(); // \u4ece\u52a8\u4f5c\u5b57\u5178\u4e2d\u8bfb\u53d6\u79ef\u5206\u6b65\u957f\n\n    L = action[\"L\"].cast&lt;double&gt;(); // \u4ece\u52a8\u4f5c\u5b57\u5178\u4e2d\u8bfb\u53d6\u98de\u884c\u5668\u6240\u53d7\u5916\u529b\n    D = action[\"D\"].cast&lt;double&gt;();\n    N = action[\"N\"].cast&lt;double&gt;();\n    T = action[\"T\"].cast&lt;double&gt;();\n    M = action[\"M\"].cast&lt;std::array&lt;double, 3&gt;&gt;();\n\n    // \u4f7f\u7528\u4e0d\u540c\u7684\u79ef\u5206\u65b9\u6cd5\u66f4\u65b0\u98de\u884c\u5668\u72b6\u6001\n\n    if (integrator == \"euler\")\n    {\n        // \u8fd9\u91cc\u53ef\u4ee5\u76f4\u63a5\u8fd0\u7b97\u662f\u56e0\u4e3a\u5728 Object3D \u7c7b\u4e2d\u91cd\u8f7d\u4e86\u56db\u5219\u8fd0\u7b97\n        // this-&gt;d() \u8c03\u7528\u6c42\u5bfc\u65b9\u6cd5\uff0c\u8fd4\u56de\u52a8\u529b\u5b66\u5bfc\u6570\uff08\u5373\uff0c\u8fd4\u56de\u7684\u5b9e\u4f8b\u7684\u6bcf\u4e2a\u5c5e\u6027\u662f\u4f20\u5165\u7684\u5b9e\u4f8b\u5bf9\u5e94\u5c5e\u6027\u7684\u5bfc\u6570\uff09\n        // this-&gt;d() * dt \u5373\u8868\u793a\u589e\u91cf\n        *this = *this + this-&gt;d() * dt;\n    }\n    else if (integrator == \"midpoint\")\n    {\n        auto temp1 = *this + this-&gt;d() * (0.5 * dt);\n        auto k1 = temp1.d();\n        *this = *this + k1 * dt;\n    }\n    else if (integrator == \"rk23\")\n    {\n        auto k1 = this-&gt;d();\n        auto temp1 = *this + k1 * (0.5 * dt);\n        auto k2 = temp1.d();\n        auto temp2 = *this + k2 * (0.5 * dt);\n        auto k3 = temp2.d();\n        *this = *this + (k1 + k2 * 2 + k3) * (dt / 4);\n    }\n    else if (integrator == \"rk45\")\n    {\n        auto k1 = this-&gt;d();\n        auto temp1 = *this + k1 * (0.5 * dt);\n        auto k2 = temp1.d();\n        auto temp2 = *this + k2 * (0.5 * dt);\n        auto k3 = temp2.d();\n        auto temp3 = *this + k3 * dt;\n        auto k4 = temp3.d();\n        *this = *this + (k1 + k2 * 2 + k3 * 2 + k4) * (dt / 6);\n    }\n\n    // \u7531\u4e8e\u5728\u4e0a\u9762\u7684\u52a8\u529b\u5b66\u79ef\u5206\u4e2d\u53ea\u8ba1\u7b97\u4e86\u5fc5\u8981\u7684\u91cf\n    // \u6b64\u5904\u8fd8\u9700\u8981\u5bf9\u672a\u66f4\u65b0\u7684\u5c5e\u6027\u8fdb\u884c\u8ba1\u7b97\n    beta = cos(theta_v) * (cos(gamma) * sin(phi - phi_v) + sin(theta) * sin(gamma) * cos(phi - phi_v)) - sin(theta_v) * cos(theta) * sin(gamma);\n    alpha = (cos(theta_v) * (sin(theta) * cos(gamma) * cos(phi - phi_v) - sin(gamma) * sin(phi - phi_v)) - sin(theta_v) * cos(theta) * cos(gamma)) / cos(beta);\n    gamma_v = (cos(alpha) * sin(beta) * sin(theta) - sin(alpha) * sin(beta) * cos(gamma) * cos(theta) + cos(beta) * sin(gamma) * cos(theta)) / cos(theta_v);\n\n    vel[0] = V * cos(theta_v) * cos(phi_v);\n    vel[1] = V * sin(theta_v);\n    vel[2] = -V * cos(theta_v) * sin(phi_v);\n    h = pos[1];\n\n    Tem = Temperature(h);\n    Pres = Pressure(h);\n    Rho = Density(Tem, Pres);\n    a = SpeedofSound(Tem);\n    g = Gravity(h);\n\n    q = 0.5 * Rho * V * V;\n    return to_dict();\n}\n</code></pre>"},{"location":"fixed_wing_template/#space3d","title":"Space3D","text":"<p><code>Space3D</code> \u7c7b\u662f <code>BaseEnv</code> \u7684\u5b50\u7c7b\uff0c\u5305\u542b\u4e00\u4e9b\u5904\u7406\u8f93\u5165\u8f93\u51fa\u7684\u5fc5\u8981\u5c5e\u6027\u548c\u65b9\u6cd5\uff0c\u5b9e\u73b0\u6bd4\u8f83\u7b80\u5355\u3002</p> Space3D.h<pre><code>class Space3D : public BaseEnv\n{\nprivate: // [tl! collapse:start]\n    double tau; // \u6bcf\u6b21\u79ef\u5206\u7684\u65f6\u95f4\u957f\u5ea6\uff0ctau = dt / integrate_steps\n    double dt; // \u6bcf\u6b21\u88ab\u8c03\u7528 step() \u65b9\u6cd5\u65f6\uff0c\u6b65\u8fdb\u7684\u65f6\u95f4\u957f\u5ea6\n    double eps; // \u5bb9\u5dee\uff0c\u53ef\u4ee5\u7528\u4e8e\u68c0\u67e5\u52a8\u529b\u5b66\u79ef\u5206\u7684\u7cbe\u5ea6\uff0c\u672a\u5b9e\u88c5\n    int integrate_steps; // \u6bcf\u6b21\u88ab\u8c03\u7528 step() \u65b9\u6cd5\u65f6\uff0c\u8c03\u7528\u73af\u5883\u5185\u5bf9\u8c61\u7684 step() \u65b9\u6cd5\u7684\u6b21\u6570\uff08\u5c06\u6bcf\u6b21\u6b65\u8fdb\u5212\u5206\u4e3a\u51e0\u6b21\u79ef\u5206\uff09 // [tl! collapse:end]\n\npublic:\n    std::vector&lt;std::shared_ptr&lt;Object3D&gt;&gt; objects;\n\n    Space3D(double tau, double eps, int integrate_steps)\n        : tau(tau), eps(eps), integrate_steps(integrate_steps)\n    {\n        dt = tau / integrate_steps;\n    }\n\n    py::object reset()\n    {\n        for (auto&amp; object : objects)\n        {\n            object-&gt;reset();\n        }\n        return to_dict();\n    }\n\n    void add_object(std::shared_ptr&lt;Object3D&gt; object)\n    {\n        objects.push_back(object); // \u5c06\u4f20\u5165\u7684\u5bf9\u8c61(Object3D\u53ca\u5176\u5b50\u7c7b)\u5b58\u5165\u5217\u8868\u4e2d\n    }\n\n    bool check_consistency()\n    {\n        return true;\n    }\n\n    py::dict to_dict() // \u8c03\u7528\u73af\u5883\u4e2d\u6bcf\u4e2a\u5bf9\u8c61\u7684 to_dict() \u65b9\u6cd5\uff0c\u5e76\u5c06\u6240\u6709\u8fd4\u56de\u503c\u5b58\u5165\u4e00\u4e2a\u5b57\u5178\u4e2d\u5e76\u8fd4\u56de\n    {\n        py::dict output_dict;\n        for (auto&amp; object : objects)\n        {\n            output_dict[py::str(object-&gt;name)] = object-&gt;to_dict(); \n        }\n        return output_dict;\n    }\n\n    py::dict get_d() // \u83b7\u53d6\u73af\u5883\u4e2d\u6240\u6709\u5bf9\u8c61\u7684\u8fd0\u52a8\u5b66\u5bfc\u6570\uff0c\u7528\u4e8e debug\n    {\n        py::dict output_dict;\n        for (auto&amp; object : objects)\n        {\n            output_dict[py::str(object-&gt;name)] = (object-&gt;d()).to_dict(); \n        }\n        return output_dict;\n    }\n\n    py::object step(const py::object&amp; actions) // \u6b65\u8fdb\u65f6\u4f1a\u8c03\u7528\u73af\u5883\u4e2d\u6240\u6709\u5bf9\u8c61\u7684 step() \u65b9\u6cd5\u82e5\u5e72\u6b21\uff0c\u5e76\u83b7\u53d6\u8fd4\u56de\u503c\n    {\n        py::dict result, info;\n\n        for (int i = 0; i &lt; integrate_steps; ++i)\n        {\n            for (auto&amp; object : objects)\n            {\n                actions[py::str(object-&gt;name)][\"dt\"] = dt;   \n                result[py::str(object-&gt;name)] = object-&gt;step(actions[py::str(object-&gt;name)]);\n            }\n        }\n\n        return result;\n    }\n};\n</code></pre>"},{"location":"get_started/","title":"\u5b89\u88c5 Aerodrome","text":"<p>1.\u521b\u5efa\u5e76\u6fc0\u6d3b Conda \u73af\u5883</p> <pre><code>$ conda create -n aerodrome python==3.9\n$ conda activate aerodrome\n</code></pre> <p>\u5173\u4e8e\u7f16\u8bd1\u73af\u5883</p> <p>Aerodrome \u5728 <code>py&gt;=3.9.0,&lt;3.12</code> \u4e0a\u6d4b\u8bd5\uff0c\u4f46\u6e90\u7801\u4e2d\u5305\u542b\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\uff08python/simulator \u4e0b\u7684 C++ \u7f16\u8bd1\u51fa\u7684\u6587\u4ef6\uff09\u662f\u5728 <code>py==3.9</code> \u73af\u5883\u4e0b\u751f\u6210\u7684\uff1b\u5982\u679c\u4f60\u8981\u4f7f\u7528\u5176\u5b83 python \u7248\u672c\u6216\u81ea\u5df1\u5b9e\u73b0\u7684\u73af\u5883\uff0c\u5219\u9700\u8981\u91cd\u65b0\u7f16\u8bd1\u5e76\u4fdd\u8bc1\u7f16\u8bd1\u548c\u8fd0\u884c\u65f6\u7684 python \u7248\u672c\u4e00\u81f4\u3002</p> <p>2.\u5b89\u88c5 Pytorch</p> <p>\u8fd0\u884c\u5f3a\u5316\u5b66\u4e60\u4ee3\u7801\u9700\u8981\u7528\u5230 <code>torch</code> \u5e93\uff1b\u6e90\u7801\u5728 <code>torch==2.6.0</code> \u4e0a\u6d4b\u8bd5\u8fd0\u884c\uff0c\u4f46\u7406\u8bba\u4e0a\u53ef\u4ee5\u5728\u4efb\u610f <code>torch&gt;1.0.0</code> \u4ee5\u53ca\u517c\u5bb9\u7684 CUDA \u7248\u672c\u4e0a\u8fd0\u884c\u3002\u4f8b\u5982\uff0c<code>PyTorch 2.6.0</code> \u548c <code>CUDA 11.8</code>\uff1a</p> <pre><code>$ pip install torch==2.6.0 --index-url https://download.pytorch.org/whl/cu118\n</code></pre> <p>3.\u4ece\u6e90\u4ee3\u7801\u5b89\u88c5 Aerodrome</p> <pre><code>$ git clone https://github.com/CH4ACKO3/Aerodrome.git --recursive\n$ cd Aerodrome\n$ pip install .\n</code></pre> <p>4.\u7f16\u8bd1 C++ \u90e8\u5206\u4ee3\u7801\uff08\u53ef\u9009\uff09</p> <p>\u5982\u679c\u4f60\u8981\u4f7f\u7528\u81ea\u5df1\u5b9e\u73b0\u7684\u73af\u5883\uff0c\u6216\u4f7f\u7528\u7684 python \u7248\u672c\u4e0e\u6e90\u7801\u4e2d\u4e8c\u8fdb\u5236\u6587\u4ef6\uff08<code>python==3.9</code>\uff09\u4e0d\u4e00\u81f4\uff0c\u5219\u9700\u8981\u91cd\u65b0\u7f16\u8bd1\u5e76\u5b89\u88c5\uff1a</p> <pre><code>$ cmake -B build\n$ cmake --build build\n$ pip install .\n</code></pre> <p>\u7f16\u8bd1\u65f6\u7684\u5e73\u53f0\u548c python \u7248\u672c\u4f1a\u5728\u4e8c\u8fdb\u5236\u6587\u4ef6\u540d\u4e2d\u663e\u793a\uff1b\u4f8b\u5982\uff0c<code>*.cp39-win_amd64.pyd</code> \u8868\u793a\u6587\u4ef6\u662f\u5728 Windows \u5e73\u53f0\u300164\u4f4d\u67b6\u6784\u4e0b\uff0c<code>python==3.9</code> \u73af\u5883\u4e2d\u7f16\u8bd1\u7684\u3002</p>"},{"location":"longitudinal_control_classic/","title":"\u7eb5\u5411\u8fc7\u8f7d\u63a7\u5236 - \u7ecf\u5178\u63a7\u5236","text":"<p>\u5728 Aerodrome \u4e2d\u63d0\u4f9b\u4e86\u4e00\u4e2a\u98de\u884c\u5668\u7eb5\u5411\u8fc7\u8f7d\u63a7\u5236\u7684\u793a\u4f8b\u9879\u76ee\u3002\u88ab\u63a7\u5bf9\u8c61\u4e3a Winged-Cone\uff0c\u5176\u6c14\u52a8\u6a21\u578b\u53c2\u8003\u81ea\u516c\u5f00\u6570\u636e\u3002\u9879\u76ee\u4e2d\u5206\u522b\u91c7\u7528\u4f20\u7edf\u4e09\u56de\u8def\u9a7e\u9a76\u4eea\u548c\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff08\u8fde\u7eed\u52a8\u4f5cPPO\uff09\u8fdb\u884c\u8fc7\u8f7d\u63a7\u5236\u5668\u8bbe\u8ba1\uff0c\u4ee5\u5c55\u793a\u4f20\u7edf\u63a7\u5236\u7b97\u6cd5\u4ee5\u53ca\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u8bad\u7ec3\u90e8\u7f72\u7684\u57fa\u672c\u6d41\u7a0b\u548c\u5b9e\u73b0\u3002</p> <p>\u4f7f\u7528\u5230\u7684\u4ee3\u7801\uff1a</p> <ul> <li>WingedCone2D\uff1a <code>src/simulator/CanonicalAircraftEnv/objects/WingedCone2D.h</code></li> <li>WingedCone2D - Classic\uff1a <code>src/simulator/CanonicalAircraftEnv/objects/WingedCone2D_Classic.h</code></li> <li>Python \u4e2d\u8c03\u7528 WingedCone2d - Classic \u8fdb\u884c\u8ba1\u7b97\uff1a<code>examples/AircraftControl/WingedCone_Classic.py</code></li> </ul>"},{"location":"longitudinal_control_classic/#wingedcone2d","title":"WingedCone2D","text":"<p><code>WingedCone2D</code> \u5b9e\u73b0\u4e3a <code>Aircraft3D</code> \u7684\u5b50\u7c7b\uff0c\"<code>2D</code>\" \u8868\u793a\u5176\u6c14\u52a8\u6a21\u578b\u53ea\u5b9e\u73b0\u4e86\u7eb5\u5411\u7684\u90e8\u5206\u3002</p> <p>\u76f8\u5bf9\u4e8e <code>Aircraft3D</code>\uff0c<code>WingedCone2D</code> \u589e\u52a0\u4e86\u5347\u964d\u8235\u504f\u89d2 <code>delta_e</code> \u5c5e\u6027\uff0c\u5e76\u590d\u5199\u4e86 <code>Aircraft3D</code> \u7684 <code>step()</code> \u65b9\u6cd5\uff0c\u5728\u5176\u4e2d\u589e\u52a0\u4e86\u8ba1\u7b97\u6c14\u52a8\u529b\u7684\u90e8\u5206\u3002\u76f8\u5e94\u5730\uff0c\u6c14\u52a8\u529b\uff08<code>L</code>\uff0c<code>D</code>\uff0c<code>T</code>\uff0c<code>M</code>\uff09\u7684\u8ba1\u7b97\u88ab\u5b9e\u73b0\u4e3a\u5355\u72ec\u7684\u51fd\u6570\uff08<code>_L()</code>\uff0c<code>_D()</code>\uff0c<code>_T()</code>\uff0c<code>_M()</code>\uff09\u3002\u8f93\u5165\u52a8\u4f5c\u76f4\u63a5\u5bf9 <code>delta_e</code> \u8fdb\u884c\u4fee\u6539\u3002</p> \u70b9\u51fb\u5c55\u5f00\u4ee3\u7801 WingedCone2D.h<pre><code>class WingedCone2D : public Aircraft3D\n{\npublic:\n    double delta_e; // \u5347\u964d\u8235\u504f\u89d2\n\n    WingedCone2D() {}\n\n    WingedCone2D(py::dict input_dict) : Aircraft3D(input_dict)\n    {\n        delta_e = 0.0;        \n    }\n\n    virtual void reset() override\n    {\n        *this = WingedCone2D(initial_state);\n    }\n\n    void _D()\n    {\n        double CD = 0.645 * alpha * alpha + 0.0043378 * alpha + 0.003772;\n        D = q * S * CD;\n    }\n\n    void _L()\n    {\n        double CL = 0.6203 * alpha + 2.4 * sin(0.08 * alpha);\n        L = q * S * CL;\n    }\n\n    virtual void _T()\n    {\n        T = 4.959e3;\n    }\n\n    void _M()\n    {\n        double CM1 = -0.035 * alpha * alpha + 0.036617 * alpha + 5.3261e-6;\n        double CM2 = ang_vel[2] * c * (-6.796 * alpha * alpha + 0.3015 * alpha - 0.2289) / (2 * V);\n        double CM3 = 0.0292 * (delta_e - alpha);\n        M[2] = q * S * c * (CM1 + CM2 + CM3);\n    }\n\n    virtual py::dict to_dict() override\n    {\n        py::dict output_dict = Aircraft3D::to_dict();\n        output_dict[\"delta_e\"] = delta_e;\n        return output_dict;\n    }\n\n    virtual py::object step(py::dict action) override\n    {\n        double dt = action[\"dt\"].cast&lt;double&gt;();\n\n        delta_e = action[\"delta_e\"].cast&lt;double&gt;(); // \u4f20\u5165\u52a8\u4f5c\u76f4\u63a5\u4fee\u6539 delta_e\n\n        // \u65b0\u589e\u8ba1\u7b97\u6c14\u52a8\u529b\u7684\u90e8\u5206\n        _D();\n        _L();\n        _T();\n        _M();\n\n        if (integrator == \"euler\")\n        {\n            *this = *this + this-&gt;d() * dt;\n        }\n        else if (integrator == \"midpoint\")\n        {\n            auto temp1 = *this + this-&gt;d() * (0.5 * dt);\n            auto k1 = temp1.d();\n            *this = *this + k1 * dt;\n        }\n        else if (integrator == \"rk23\")\n        {\n            auto k1 = this-&gt;d();\n            auto temp1 = *this + k1 * (0.5 * dt);\n            auto k2 = temp1.d();\n            auto temp2 = *this + k2 * (0.5 * dt);\n            auto k3 = temp2.d();\n            *this = *this + (k1 + k2 * 2 + k3) * (dt / 4);\n        }\n        else if (integrator == \"rk45\")\n        {\n            auto k1 = this-&gt;d();\n            auto temp1 = *this + k1 * (0.5 * dt);\n            auto k2 = temp1.d();\n            auto temp2 = *this + k2 * (0.5 * dt);\n            auto k3 = temp2.d();\n            auto temp3 = *this + k3 * dt;\n            auto k4 = temp3.d();\n            *this = *this + (k1 + k2 * 2 + k3 * 2 + k4) * (dt / 6);\n        }\n\n        beta = cos(theta_v) * (cos(gamma) * sin(phi - phi_v) + sin(theta) * sin(gamma) * cos(phi - phi_v)) - sin(theta_v) * cos(theta) * sin(gamma);\n        alpha = (cos(theta_v) * (sin(theta) * cos(gamma) * cos(phi - phi_v) - sin(gamma) * sin(phi - phi_v)) - sin(theta_v) * cos(theta) * cos(gamma)) / cos(beta);\n        gamma_v = (cos(alpha) * sin(beta) * sin(theta) - sin(alpha) * sin(beta) * cos(gamma) * cos(theta) + cos(beta) * sin(gamma) * cos(theta)) / cos(theta_v);\n\n        vel[0] = V * cos(theta_v) * cos(phi_v);\n        vel[1] = V * sin(theta_v);\n        vel[2] = -V * cos(theta_v) * sin(phi_v);\n        h = pos[1];\n\n        Tem = Temperature(h);\n        Pres = Pressure(h);\n        Rho = Density(Tem, Pres);\n        a = SpeedofSound(Tem);\n        g = Gravity(h);\n\n        q = 0.5 * Rho * V * V;\n        return to_dict();\n    }\n};\n</code></pre>"},{"location":"longitudinal_control_classic/#wingedcone2d-classic","title":"WingedCone2D - Classic","text":"<p><code>WingedCone2D_Classic</code> \u7c7b\u662f <code>WingedCone2D</code> \u7684\u5b50\u7c7b\uff0c\u63d0\u4f9b\u4e86\u7eb5\u5411\u8fc7\u8f7d\u63a7\u5236\u7684\u4f20\u7edf\u4e09\u56de\u8def\u9a7e\u9a76\u4eea\u5b9e\u73b0\u3002</p> <p>\u5177\u4f53\u5730\uff0c<code>WingedCone2D_Classic</code> \u589e\u52a0\u4e86\u82e5\u5e72\u63a7\u5236\u53c2\u6570\uff08\u4f8b\u5982\uff0c<code>Kiz</code>\uff0c<code>Kwz</code> \u7b49\uff09\uff0c\u63a7\u5236\u5668\u6240\u9700\u8981\u7684\u6570\u503c\uff08\u4f8b\u5982\uff0c\u8fc7\u8f7d\u8ddf\u8e2a\u8bef\u5dee <code>eNy</code> \u53ca\u5176\u79ef\u5206\u9879 <code>i_eNy</code> \u7b49\uff09\uff1b\u4f20\u5165\u52a8\u4f5c\u4e3a\u8fc7\u8f7d\u6307\u4ee4\uff0c\u8235\u504f\u89d2\u4e0d\u518d\u7531\u52a8\u4f5c\u63a7\u5236\uff0c\u800c\u662f\u7531\u63a7\u5236\u5668\u8ba1\u7b97\uff1b<code>step()</code> \u65b9\u6cd5\u4e2d\u65b0\u589e\u7531\u63a7\u5236\u5668\u8ba1\u7b97\u8235\u504f\u7684\u90e8\u5206\u3002</p> <p>\u867d\u7136\u4f20\u5165\u52a8\u4f5c\u4e2d\u6709\u901f\u5ea6\u6307\u4ee4 <code>Vc</code>\uff0c\u5e76\u4e14\u6709\u7531\u901f\u5ea6\u6307\u4ee4\u63a7\u5236\u53d1\u52a8\u673a\u5f00\u5ea6\u7684\u51fd\u6570 <code>V_controller()</code>\uff0c\u4f46\u51fa\u4e8e\u7b80\u6613\u8d77\u89c1\u6700\u7ec8\u5e76\u672a\u5b9e\u88c5\uff08\u5373\uff0c\u63a8\u529b <code>T</code> \u4e0d\u53d7\u63a7\u5236\u5668\u5f71\u54cd\uff0c\u4e3a\u56fa\u5b9a\u503c <code>T = 4.959e3</code>\uff09\u3002</p> \u70b9\u51fb\u5c55\u5f00\u4ee3\u7801 WingedCone2D_Classic.h<pre><code>class WingedCone2D_Classic : public WingedCone2D\n{\npublic:\n    // \u4fef\u4ef0\u89d2\u589e\u7a33\u8fc7\u8f7d\u9a7e\u9a76\u4eea\u63a7\u5236\u53c2\u6570\n    double Kiz;   // \u79ef\u5206\u589e\u76ca\n    double Kwz;   // \u89d2\u901f\u5ea6\u589e\u76ca\n    double Kaz;   // \u589e\u7a33\u56de\u8def\u589e\u76ca\n    double Kpz;   // \u6bd4\u4f8b\u589e\u76ca\n\n    double eNy; // \u8fc7\u8f7d\u8ddf\u8e2a\u8bef\u5dee\n    double i_eNy; // \u8fc7\u8f7d\u79ef\u5206\u9879\n    double p_eNy; // \u8fc7\u8f7d\u6bd4\u4f8b\u9879\n\n    double i_eSAC; // \u589e\u7a33\u56de\u8def\u79ef\u5206\u9879\n\n    double Kp_V, Ki_V, Kd_V; // \u901f\u5ea6\u63a7\u5236\u53c2\u6570\n\n    double i_V; // \u901f\u5ea6\u79ef\u5206\u9879\n    double d_eV; // \u901f\u5ea6\u5fae\u5206\u9879\n    double eV_prev; // \u901f\u5ea6\u8bef\u5dee\u524d\u503c\n\n    double Ny; // \u5f53\u524d\u8fc7\u8f7d\n    double wz; // \u5f53\u524d\u6eda\u8f6c\u89d2\u901f\u5ea6\n\n    WingedCone2D_Classic() {}\n\n    WingedCone2D_Classic(py::dict input_dict) : WingedCone2D(input_dict)\n    {\n        Kiz = input_dict[\"Kiz\"].cast&lt;double&gt;();\n        Kwz = input_dict[\"Kwz\"].cast&lt;double&gt;();\n        Kaz = input_dict[\"Kaz\"].cast&lt;double&gt;();\n        Kpz = input_dict[\"Kpz\"].cast&lt;double&gt;();\n\n        Kp_V = input_dict[\"Kp_V\"].cast&lt;double&gt;();\n        Ki_V = input_dict[\"Ki_V\"].cast&lt;double&gt;();\n        Kd_V = input_dict[\"Kd_V\"].cast&lt;double&gt;();\n\n        eNy = 0;\n        i_eNy = 0;\n        p_eNy = 0;\n        i_eSAC = 0;\n        i_V = 0;\n        d_eV = 0;\n        eV_prev = 0;\n\n        _D();\n        _L();\n        _T();\n        _M();\n\n        Ny = (T * (sin(alpha) * cos(gamma_v) - cos(alpha) * sin(beta) * sin(gamma_v))\n                                + L * cos(gamma_v) - N * sin(gamma_v) - m * g * cos(theta_v)) / (m * g);\n        wz = ang_vel[2];\n    }\n\n    virtual void reset() override\n    {\n        *this = WingedCone2D_Classic(initial_state);\n    }\n\n    double V_controller(double Vc, double V, double dt)\n    {\n        // \u901f\u5ea6\u8ddf\u8e2a\u8bef\u5dee\n        double eV = Vc - V;\n        i_V += eV * dt;\n        d_eV = (eV - eV_prev) / dt;\n        eV_prev = eV;\n\n        double u1a = Kp_V * eV + Ki_V * i_V + Kd_V * d_eV;\n        if (u1a &lt; 0) \n        {\n            u1a = 0;\n        }\n\n        return u1a;\n    }\n\n    double Ny_controller(double Nyc, double Ny, double wz, double dt)\n    {\n        // \u8fc7\u8f7d\u8ddf\u8e2a\u8bef\u5dee\n        eNy = Nyc - Ny;\n\n        // PI\u6821\u6b63\u73af\u8282\n        i_eNy += eNy * dt;\n        p_eNy = eNy;\n\n        double pi_eNy = Kiz * i_eNy + Kpz * p_eNy;\n\n        // \u589e\u7a33\u56de\u8def\n        double eSAC = pi_eNy - Kaz * wz;\n        i_eSAC += eSAC * dt;\n\n        // \u963b\u5c3c\u56de\u8def\n        double eDamp = i_eSAC - Kwz * wz;\n\n        return eDamp;\n    }\n\n    virtual py::dict to_dict() override\n    {\n        py::dict output_dict = WingedCone2D::to_dict();\n        output_dict[\"Ny\"] = Ny;\n        return output_dict;\n    }\n\n    virtual py::object step(py::dict action) override\n    {\n        double dt = action[\"dt\"].cast&lt;double&gt;();\n\n        double Nyc = action[\"Nyc\"].cast&lt;double&gt;();\n        double Vc = action[\"Vc\"].cast&lt;double&gt;();\n\n        delta_e = Ny_controller(Nyc, Ny, wz, dt*0.1);\n        delta_e = std::clamp(delta_e, -25 / 57.3, 25 / 57.3);\n\n        double Phi = V_controller(Vc, V, dt*0.1);\n\n        // \u8ba1\u7b97\u6c14\u52a8\u529b\n        _D();\n        _L();\n        _T();\n        _M();\n\n        if (integrator == \"euler\")\n        {\n            *this = *this + this-&gt;d() * dt;\n        }\n        else if (integrator == \"midpoint\")\n        {\n            auto temp1 = *this + this-&gt;d() * (0.5 * dt);\n            auto k1 = temp1.d();\n            *this = *this + k1 * dt;\n        }\n        else if (integrator == \"rk23\")\n        {\n            auto k1 = this-&gt;d();\n            auto temp1 = *this + k1 * (0.5 * dt);\n            auto k2 = temp1.d();\n            auto temp2 = *this + k2 * (0.5 * dt);\n            auto k3 = temp2.d();\n            *this = *this + (k1 + k2 * 2 + k3) * (dt / 4);\n        }\n        else if (integrator == \"rk45\")\n        {\n            auto k1 = this-&gt;d();\n            auto temp1 = *this + k1 * (0.5 * dt);\n            auto k2 = temp1.d();\n            auto temp2 = *this + k2 * (0.5 * dt);\n            auto k3 = temp2.d();\n            auto temp3 = *this + k3 * dt;\n            auto k4 = temp3.d();\n            *this = *this + (k1 + k2 * 2 + k3 * 2 + k4) * (dt / 6);\n        }\n\n        beta = cos(theta_v) * (cos(gamma) * sin(phi - phi_v) + sin(theta) * sin(gamma) * cos(phi - phi_v)) - sin(theta_v) * cos(theta) * sin(gamma);\n        alpha = (cos(theta_v) * (sin(theta) * cos(gamma) * cos(phi - phi_v) - sin(gamma) * sin(phi - phi_v)) - sin(theta_v) * cos(theta) * cos(gamma)) / cos(beta);\n        gamma_v = (cos(alpha) * sin(beta) * sin(theta) - sin(alpha) * sin(beta) * cos(gamma) * cos(theta) + cos(beta) * sin(gamma) * cos(theta)) / cos(theta_v);\n\n        vel[0] = V * cos(theta_v) * cos(phi_v);\n        vel[1] = V * sin(theta_v);\n        vel[2] = -V * cos(theta_v) * sin(phi_v);\n        h = pos[1];\n\n        Tem = Temperature(h);\n        Pres = Pressure(h);\n        Rho = Density(Tem, Pres);\n        a = SpeedofSound(Tem);\n        g = Gravity(h);\n\n        q = 0.5 * Rho * V * V;\n\n        Ny = (T * (sin(alpha) * cos(gamma_v) - cos(alpha) * sin(beta) * sin(gamma_v))\n                                + L * cos(gamma_v) - N * sin(gamma_v) - m * g * cos(theta_v)) / (m * g);\n        wz = ang_vel[2];\n\n        return to_dict();\n    }\n};\n</code></pre>"},{"location":"longitudinal_control_classic/#python","title":"Python \u4ee3\u7801","text":"<p>\u7531\u4e8e <code>WingedCone2D_Classic</code> \u7684\u63a7\u5236\u4ee3\u7801\u76f4\u63a5\u5728 C++ \u7c7b\u4e2d\u5b9e\u73b0\uff0c\u56e0\u6b64 Python \u90e8\u5206\u4ee3\u7801\u8f83\u5c11\uff0c\u800c\u4e14 \u76f4\u63a5\u8c03\u7528 C++ \u7c7b\uff0c\u6ca1\u6709\u7ecf\u8fc7 Python \u5305\u88c5 \uff08\u4e5f\u5c31\u662f <code>\u57fa\u7840\u903b\u8f91\u548c\u7c7b</code> \u7ae0\u8282\u4e2d\u4ecb\u7ecd\u7684\u7b2c\u4e8c\u79cd\u8bbe\u8ba1\u6a21\u5f0f\uff09\uff0c\u53ea\u6709 C++ \u73af\u5883\u8c03\u7528\u3001\u6b65\u8fdb\u5faa\u73af\u548c\u7ed8\u56fe\u90e8\u5206\u3002\u8fd9\u4e5f\u662f\u7b2c\u4e00\u4e2a\u6d89\u53ca <code>Space3D</code> \u7c7b\u4f7f\u7528\u7684\u793a\u4f8b\u3002</p> WingedCone_Classic.py<pre><code># \u76f4\u63a5\u4ece\u7f16\u8bd1\u597d\u7684 C++ \u6a21\u5757\u4e2d\u53d6\u51fa WingedCone2D_Classic \u548c Space3D \u7c7b\u4f7f\u7528\uff0c\u4e0d\u7ecf\u8fc7 Python\nfrom aerodrome.simulator.CanonicalAircraftEnv.objects.WingedCone2D_Classic import WingedCone2D_Classic\nfrom aerodrome.simulator.Core.envs.Space3D import Space3D\nfrom math import *\n\nif __name__ == \"__main__\":\n    dt = 0.001 # \u5b9a\u4e49\u6b65\u8fdb\u6b65\u957f\uff0c\u8fd9\u91cc\u8bbe\u7f6e\u4e3a\u56fa\u5b9a\u503c 0.001\n    # \u5b9e\u4f8b\u5316 Space3D \u7c7b\uff0c\u7b2c\u4e8c\u4e2a\u5b9e\u53c2\u8868\u793a\u6b65\u8fdb\u6b65\u957f\uff0c\u7b2c\u4e09\u4e2a\u5b9e\u53c2\u8868\u793a\u6bcf\u6b21\u6b65\u8fdb\u5206\u6210\u7684\u79ef\u5206\u6b21\u6570\n    env = Space3D(dt, 0.001, 1) \n\n    # \u5b9a\u4e49\u4eff\u771f\u5bf9\u8c61\u7684\u53c2\u6570\u5b57\u5178\uff0c\u7528\u4e8e\u751f\u6210\u5bf9\u8c61\n    object_dict = {\n        \"name\": \"test\",\n        \"integrator\": \"rk45\",\n        \"S\": 3603.0,\n        \"c\": 80.0,\n        \"m\": 9375.0,\n\n        \"pos\": [0.0, 33528.0, 0.0],\n        \"vel\": [4590.29, 0.0, 0.0],\n        \"ang_vel\": [0.0, 0.0, 0.0],\n        \"J\": [1.0, 7*10**6, 7*10**6],\n        \"theta\": 0.00/180*pi,\n        \"phi\": 0.0,\n        \"gamma\": 0.0,   \n        \"theta_v\": 0.0,\n        \"phi_v\": 0.0,\n        \"gamma_v\": 0.0,\n        \"alpha\": 0.00/180*pi,\n        \"beta\": 0.0,\n\n        \"Kiz\": 0.2597,\n        \"Kwz\": 1.6,\n        \"Kaz\": 13/2,\n        \"Kpz\": 0.14,\n        \"Kp_V\": 5.0,\n        \"Ki_V\": 1.0,\n        \"Kd_V\": 0.3\n    }\n\n    object = WingedCone2D_Classic(object_dict) # \u4ece\u5b57\u5178\u751f\u6210\u5bf9\u8c61\n    env.add_object(object) # \u5c06\u5bf9\u8c61\u6dfb\u52a0\u5230\u73af\u5883\u4e2d\n\n    # \u7528\u4e8e\u4fdd\u5b58\u6570\u636e\u7684\u6570\u7ec4\n    import numpy as np\n\n    cnt = 10000\n    x = np.arange(cnt) * dt\n    y = np.zeros(cnt)\n\n    Nyc = 0.0 # \u8fc7\u8f7d\u6307\u4ee4\n    Vc = 3000 # \u901f\u5ea6\u6307\u4ee4\n\n    for i in range(cnt):\n        action = {\"test\": {\"Nyc\":Nyc, \"Vc\":Vc}} # \u5b9a\u4e49\u52a8\u4f5c\n        result = env.step(action) # \u6b65\u8fdb\u5e76\u63a5\u53d7\u8fd4\u56de\u503c\n        y[i] = result[\"test\"][\"Ny\"] # \u4ece\u8fd4\u56de\u7684\u5b57\u5178\u4e2d\u63d0\u53d6\u9700\u8981\u7684\u503c\n\n    # \u7ed8\u56fe\n    import matplotlib.pyplot as plt\n    plt.plot(x, y)\n    plt.xlabel(\"Time (s)\")\n    plt.ylabel(\"Ny\")\n    plt.axhline(y=Nyc, color='r', linestyle='--', alpha=0.5)\n    plt.show()\n\n    print(env.to_dict())\n</code></pre> <p>\u4ee3\u7801\u8fd0\u884c\u7ed3\u679c\uff1a</p> \u8fc7\u8f7d\u54cd\u5e94\u66f2\u7ebf"},{"location":"longitudinal_control_classic_python/","title":"\u7eb5\u5411\u8fc7\u8f7d\u63a7\u5236 - \u7ecf\u5178\u63a7\u5236\uff08\u7eaf Python \u5b9e\u73b0\uff09","text":"<p>\u672c\u7ae0\u4e0e\u4e0a\u4e00\u7ae0\u5b9e\u73b0\u7684\u529f\u80fd\u5b8c\u5168\u76f8\u540c\uff0c\u4f46\u5c06 C++ \u90e8\u5206\u4ee3\u7801\u5b8c\u5168\u8fc1\u79fb\u81f3 Python\uff0c\u5e76\u8fdb\u884c\u4e86\u6027\u80fd\u6bd4\u8f83\u3002</p> WingedCone_py.py<pre><code>import numpy as np\nfrom math import pi\nfrom aerodrome.registration import register\n\nTABLE4 = [\n    [00000, -0.0065, 288.150, 1.01325000000000E+5],\n    [11000, 0.0000, 216.650, 2.26320639734629E+4],\n    [20000, 0.0010, 216.650, 5.47488866967777E+3],\n    [32000, 0.0028, 228.650, 8.68018684755228E+2],\n    [47000, 0.0000, 270.650, 1.10906305554966E+2],\n    [51000, -0.0028, 270.650, 6.69388731186873E+1],\n    [71000, -0.0020, 214.650, 3.95642042804073E+0],\n    [84852, 0.0000, 186.946, 3.73383589976215E-1]\n]\n\ndef Temperature(z):\n    H = z * 6356766 / (z + 6356766)\n    for b in range(7):\n        if H &lt; TABLE4[b+1][0]:\n            break\n    return TABLE4[b][2] + TABLE4[b][1] * (H - TABLE4[b][0])\n\ndef Pressure(z):\n    H = z * 6356766 / (z + 6356766)\n    for b in range(7):\n        if H &lt; TABLE4[b+1][0]:\n            break\n    C = -0.0341631947363104\n    Hb = TABLE4[b][0]\n    Lb = TABLE4[b][1]\n    Tb = TABLE4[b][2]\n    Pb = TABLE4[b][3]\n    if abs(Lb) &gt; 1E-12:\n        return Pb * pow(1 + Lb/Tb * (H-Hb), C/Lb)\n    else:\n        return Pb * np.exp(C * (H-Hb)/Tb)\n\ndef Density(T, P):\n    return P * 0.00348367635597379 / T\n\ndef SpeedofSound(T):\n    return np.sqrt(401.87430086589 * T)\n\ndef Gravity(z):\n    return 9.80665 * pow(1 + z/6356766, -2)\n\nclass WingedCone_py:\n    def __init__(self, input_dict):\n        # Object3D\n        self.name = input_dict[\"name\"]\n        self.integrator = input_dict[\"integrator\"]\n        self.pos = input_dict[\"pos\"]\n        self.vel = input_dict[\"vel\"]\n        self.ang_vel = input_dict[\"ang_vel\"]\n        self.J = input_dict[\"J\"]\n        self.V = np.sqrt(self.vel[0] * self.vel[0] + self.vel[1] * self.vel[1] + self.vel[2] * self.vel[2])\n        self.theta = input_dict[\"theta\"]\n        self.phi = input_dict[\"phi\"]\n        self.gamma = input_dict[\"gamma\"]\n        self.theta_v = input_dict[\"theta_v\"]\n        self.phi_v = input_dict[\"phi_v\"]\n        self.gamma_v = input_dict[\"gamma_v\"]\n        self.alpha = input_dict[\"alpha\"]\n        self.beta = input_dict[\"beta\"]\n\n        # Aircraft3D\n        self.V = np.sqrt(self.vel[0] * self.vel[0] + self.vel[1] * self.vel[1] + self.vel[2] * self.vel[2])\n        self.h = self.pos[1]\n        self.S = input_dict[\"S\"]\n        self.c = input_dict[\"c\"]\n        self.m = input_dict[\"m\"]\n\n        self.Tem = Temperature(self.h)\n        self.Pres = Pressure(self.h)\n        self.Rho = Density(self.Tem, self.Pres)\n        self.a = SpeedofSound(self.Tem)\n        self.g = Gravity(self.h)\n\n        self.q = 0.5 * self.Rho * self.V * self.V\n\n        self.L = 0.0\n        self.D = 0.0\n        self.N = 0.0\n        self.T = 0.0\n        self.M = [0.0, 0.0, 0.0]\n\n        # WingedCone2D\n        self.delta_e = 0.0\n\n        # WingedCone2D_Classic\n        self.Kiz = input_dict[\"Kiz\"]\n        self.Kwz = input_dict[\"Kwz\"]\n        self.Kaz = input_dict[\"Kaz\"]\n        self.Kpz = input_dict[\"Kpz\"]\n\n        self.Kp_V = input_dict[\"Kp_V\"]\n        self.Ki_V = input_dict[\"Ki_V\"]\n        self.Kd_V = input_dict[\"Kd_V\"]\n\n        self.eNy = 0.0\n        self.i_eNy = 0.0\n        self.p_eNy = 0.0\n        self.i_eSAC = 0.0\n        self.i_V = 0.0\n        self.d_eV = 0.0\n        self.eV_prev = 0.0\n\n        self._D()\n        self._L()\n        self._T()\n        self._M()\n\n        self.Ny = (self.T * (np.sin(self.alpha) * np.cos(self.gamma_v) - np.cos(self.alpha) * np.sin(self.beta) * np.sin(self.gamma_v))\n                                + self.L * np.cos(self.gamma_v) - self.N * np.sin(self.gamma_v) - self.m * self.g * np.cos(self.theta_v)) / (self.m * self.g)\n        self.wz = self.ang_vel[2]\n\n        self.initial_state = input_dict\n\n    def reset(self):\n        self.__init__(self.initial_state)\n\n    def _D(self):\n        CD = 0.645 * self.alpha * self.alpha + 0.0043378 * self.alpha + 0.003772\n        self.D = self.q * self.S * CD\n\n    def _L(self):\n        CL = 0.6203 * self.alpha + 2.4 * np.sin(0.08 * self.alpha)\n        self.L = self.q * self.S * CL\n\n    def _T(self):\n        self.T = 4.959e3\n\n    def _M(self):\n        CM1 = -0.035 * self.alpha * self.alpha + 0.036617 * self.alpha + 5.3261e-6\n        CM2 = self.ang_vel[2] * self.c * (-6.796 * self.alpha * self.alpha + 0.3015 * self.alpha - 0.2289) / (2 * self.V)\n        CM3 = 0.0292 * (self.delta_e - self.alpha)\n        self.M[2] = self.q * self.S * self.c * (CM1 + CM2 + CM3)\n\n    def to_dict(self):\n        return {\n            # Object3D\n            \"name\": self.name,\n            \"integrator\": self.integrator,\n            \"pos\": self.pos,\n            \"vel\": self.vel,\n            \"ang_vel\": self.ang_vel,\n            \"J\": self.J,\n            \"V\": np.sqrt(self.vel[0] * self.vel[0] + self.vel[1] * self.vel[1] + self.vel[2] * self.vel[2]),\n            \"theta\": self.theta,\n            \"phi\": self.phi,\n            \"gamma\": self.gamma,\n            \"theta_v\": self.theta_v,\n            \"phi_v\": self.phi_v,\n            \"gamma_v\": self.gamma_v,\n            \"alpha\": self.alpha,\n            \"beta\": self.beta,\n            \"h\": self.pos[1],\n            \"S\": self.S,\n            \"c\": self.c,\n            \"m\": self.m,\n            \"Tem\": self.Tem,\n            \"Pres\": self.Pres,\n            \"Rho\": self.Rho,\n            \"a\": self.a,\n            \"g\": self.g,\n            \"q\": self.q,\n            \"L\": self.L,\n            \"D\": self.D,\n            \"N\": self.N,\n            \"T\": self.T,\n            \"M\": self.M,\n            \"delta_e\": self.delta_e,\n            \"Kiz\": self.Kiz,\n            \"Kwz\": self.Kwz,\n            \"Kaz\": self.Kaz,\n            \"Kpz\": self.Kpz,\n            \"Kp_V\": self.Kp_V,\n            \"Ki_V\": self.Ki_V,\n            \"Kd_V\": self.Kd_V,\n            \"eNy\": self.eNy,\n            \"i_eNy\": self.i_eNy,\n            \"p_eNy\": self.p_eNy,\n            \"i_eSAC\": self.i_eSAC,\n            \"i_V\": self.i_V,\n            \"d_eV\": self.d_eV,\n            \"eV_prev\": self.eV_prev,\n            \"Ny\": self.Ny,\n            \"wz\": self.wz\n        }\n\n    def d(self, state):\n        pos = state[:3]\n        vel = state[3:6]\n        ang_vel = state[6:9]\n        V, theta, phi, gamma, theta_v, phi_v, alpha, beta, gamma_v = state[9:]\n\n        d_V = (self.T * np.cos(alpha) * np.cos(beta) - self.D - self.m * self.g * np.sin(theta_v)) / self.m\n        d_theta_v = (self.T * (np.sin(alpha) * np.cos(gamma_v) - np.cos(alpha) * np.sin(beta) * np.sin(gamma_v))\n                                + self.L * np.cos(gamma_v) - self.N * np.sin(gamma_v) - self.m * self.g * np.cos(theta_v)) / (self.m * V)\n        d_phi_v = -(self.T * (np.sin(alpha) * np.sin(gamma_v) - np.cos(alpha) * np.sin(beta) * np.cos(gamma_v))\n                            + self.L * np.sin(gamma_v) + self.N * np.cos(gamma_v)) / (self.m * V * np.cos(theta_v))\n\n        d_ang_vel = np.zeros(3)\n        d_ang_vel[0] = (self.M[0] - (self.J[2] - self.J[1]) * ang_vel[1] * ang_vel[2]) / self.J[0]\n        d_ang_vel[1] = (self.M[1] - (self.J[0] - self.J[2]) * ang_vel[2] * ang_vel[0]) / self.J[1]\n        d_ang_vel[2] = (self.M[2] - (self.J[1] - self.J[0]) * ang_vel[0] * ang_vel[1]) / self.J[2]\n\n        d_theta = ang_vel[1] * np.sin(gamma) + ang_vel[2] * np.cos(gamma)\n        d_phi = (ang_vel[1] * np.cos(gamma) - ang_vel[2] * np.sin(gamma)) / np.cos(theta)\n        d_gamma = ang_vel[0] * - np.tan(theta) * (ang_vel[1] * np.cos(gamma) - ang_vel[2] * np.sin(gamma))\n\n        d_pos = np.zeros(3)\n        d_pos[0] = V * np.cos(theta_v) * np.cos(phi_v)\n        d_pos[1] = V * np.sin(theta_v)\n        d_pos[2] = -V * np.cos(theta_v) * np.sin(phi_v)\n\n        d_vel = np.zeros(3)\n\n        derivative = np.concatenate([d_pos, d_vel, d_ang_vel, [d_V, d_theta, d_phi, d_gamma, d_theta_v, d_phi_v, 0, 0, 0]])\n        return derivative\n\n    def Ny_controller(self, Nyc, Ny, wz, dt):\n        # \u8fc7\u8f7d\u8ddf\u8e2a\u8bef\u5dee\n        self.eNy = Nyc - Ny\n\n        # PI\u6821\u6b63\u73af\u8282\n        self.i_eNy += self.eNy * dt\n        self.p_eNy = self.eNy\n\n        pi_eNy = self.Kiz * self.i_eNy + self.Kpz * self.p_eNy\n\n        # \u589e\u7a33\u56de\u8def\n        eSAC = pi_eNy - self.Kaz * wz\n        self.i_eSAC += eSAC * dt\n\n        # \u963b\u5c3c\u56de\u8def\n        eDamp = self.i_eSAC - self.Kwz * wz\n\n        return eDamp\n\n    def step(self, action):\n        dt = action[\"dt\"]\n        Nyc = action[\"Nyc\"]\n        Vc = action[\"Vc\"]\n\n        self.delta_e = self.Ny_controller(Nyc, self.Ny, self.wz, dt*0.1)\n        self.delta_e = np.clip(self.delta_e, -25 / 57.3, 25 / 57.3)\n\n        # \u8ba1\u7b97\u6c14\u52a8\u529b\n        self._D()\n        self._L()\n        self._T()\n        self._M()\n\n        state = np.concatenate([self.pos, self.vel, self.ang_vel, [self.V, self.theta, self.phi, self.gamma, self.theta_v, self.phi_v, self.alpha, self.beta, self.gamma_v]])\n\n        if self.integrator == \"euler\":\n            derivative = self.d(state)\n            state = state + derivative * dt\n        elif self.integrator == \"midpoint\":\n            temp1 = state + self.d(state) * (0.5 * dt)\n            k1 = self.d(temp1)\n            state = state + k1 * dt\n        elif self.integrator == \"rk23\":\n            k1 = self.d(state)\n            temp1 = state + k1 * (0.5 * dt)\n            k2 = self.d(temp1)\n            temp2 = state + k2 * (0.5 * dt)\n            k3 = self.d(temp2)\n            state = state + (k1 + k2 * 2 + k3) * (dt / 4)\n        elif self.integrator == \"rk45\":\n            k1 = self.d(state)\n            temp1 = state + k1 * (0.5 * dt)\n            k2 = self.d(temp1)\n            temp2 = state + k2 * (0.5 * dt)\n            k3 = self.d(temp2)\n            temp3 = state + k3 * dt\n            k4 = self.d(temp3)\n            state = state + (k1 + k2 * 2 + k3 * 2 + k4) * (dt / 6)\n\n        self.pos = state[:3]\n        self.vel = state[3:6] \n        self.ang_vel = state[6:9]\n        self.V, self.theta, self.phi, self.gamma, self.theta_v, self.phi_v, self.alpha, self.beta, self.gamma_v = state[9:]\n\n        self.beta = np.cos(self.theta_v) * (np.cos(self.gamma) * np.sin(self.phi - self.phi_v) + np.sin(self.theta) * np.sin(self.gamma) * np.cos(self.phi - self.phi_v)) - np.sin(self.theta_v) * np.cos(self.theta) * np.sin(self.gamma)\n        self.alpha = (np.cos(self.theta_v) * (np.sin(self.theta) * np.cos(self.gamma) * np.cos(self.phi - self.phi_v) - np.sin(self.gamma) * np.sin(self.phi - self.phi_v)) - np.sin(self.theta_v) * np.cos(self.theta) * np.cos(self.gamma)) / np.cos(self.beta)\n        self.gamma_v = (np.cos(self.alpha) * np.sin(self.beta) * np.sin(self.theta) - np.sin(self.alpha) * np.sin(self.beta) * np.cos(self.gamma) * np.cos(self.theta) + np.cos(self.beta) * np.sin(self.gamma) * np.cos(self.theta)) / np.cos(self.theta_v)\n\n        self.vel[0] = self.V * np.cos(self.theta_v) * np.cos(self.phi_v)\n        self.vel[1] = self.V * np.sin(self.theta_v)\n        self.vel[2] = -self.V * np.cos(self.theta_v) * np.sin(self.phi_v)\n        self.h = self.pos[1]\n\n        self.Tem = Temperature(self.h)\n        self.Pres = Pressure(self.h)\n        self.Rho = Density(self.Tem, self.Pres)\n        self.a = SpeedofSound(self.Tem)\n        self.g = Gravity(self.h)\n\n        self.q = 0.5 * self.Rho * self.V * self.V\n        self.Ny = (self.T * (np.sin(self.alpha) * np.cos(self.gamma_v) - np.cos(self.alpha) * np.sin(self.beta) * np.sin(self.gamma_v))\n                                + self.L * np.cos(self.gamma_v) - self.N * np.sin(self.gamma_v) - self.m * self.g * np.cos(self.theta_v)) / (self.m * self.g)\n        self.wz = self.ang_vel[2]\n\n        return self.to_dict()\n\nregister(\"wingedcone_py-v0\", \"aerodrome.envs.WingedCone_py:WingedCone_py\")\n</code></pre> <p>\u4e0b\u9762\u662f\u7eaf Python \u7248\u672c\u548c\u6df7\u5408\u7248\u672c\uff08C++ \u4eff\u771f &amp; Python \u4ea4\u4e92\uff09\u7684\u8fd0\u884c\u6548\u7387\u6bd4\u8f83\uff1b \u770b\u8d77\u6765\u53ea\u6709\u4e00\u6761\u66f2\u7ebf\u662f\u56e0\u4e3a\u4e24\u6761\u66f2\u7ebf\u91cd\u5408\u4e86\uff0c\u8bc1\u660e\u4e24\u79cd\u5b9e\u73b0\u5728\u6570\u503c\u4e0a\u662f\u7b49\u6548\u7684\u3002</p> \u8fd0\u884c\u65f6\u95f4\u6bd4\u8f83"},{"location":"longitudinal_control_rl/","title":"\u7eb5\u5411\u8fc7\u8f7d\u63a7\u5236 - \u5f3a\u5316\u5b66\u4e60","text":"<p>\u672c\u7ae0\u4e0e\u4e0a\u4e00\u7ae0\u91c7\u7528\u76f8\u540c\u7684\u88ab\u63a7\u5bf9\u8c61\uff0c\u4fdd\u7559\u4e09\u56de\u8def\u9a7e\u9a76\u4eea\u7684\u5185\u56de\u8def\uff0c\u4f7f\u7528 <code>PPO</code> \u7b97\u6cd5\u66ff\u4ee3 PI \u63a7\u5236\u5668\u3002</p> <p>\u4e0e\u4e0a\u4e00\u7ae0\u4e0d\u540c\uff0c\u672c\u7ae0\u4f1a\u4ee5\u81ea\u9876\u5411\u4e0b\u7684\u987a\u5e8f\u4ecb\u7ecd\u4ee3\u7801\u7ed3\u6784\uff0c\u5373\u5f3a\u5316\u5b66\u4e60 \\(\\rightarrow\\) \u4ea4\u4e92\u73af\u5883 \\(\\rightarrow\\) \u5e95\u5c42\u4eff\u771f\u3002</p> <p>\u4f7f\u7528\u5230\u7684\u4ee3\u7801\uff1a</p> <ul> <li>WingedCone2D - PPO\uff1a <code>src/simulator/CanonicalAircraftEnv/objects/WingedCone2D_RL.h</code></li> <li>Python \u73af\u5883\uff1a <code>python/aerodrome/envs/WingedCone_RL.py</code></li> <li>PPO\u8bad\u7ec3\uff1a<code>examples/AircraftControl/WingedCone_PPO.py</code></li> </ul>"},{"location":"longitudinal_control_rl/#proximal-policy-optimization","title":"\u8fd1\u7aef\u7b56\u7565\u4f18\u5316 (Proximal Policy Optimization)","text":"<p>\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09 \u662f\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\uff0c\u901a\u8fc7\u622a\u65ad\u5f0f\u7b56\u7565\u68af\u5ea6\u786e\u4fdd\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002\u5176\u6838\u5fc3\u601d\u60f3\u662f\u5728\u66f4\u65b0\u7b56\u7565\u65f6\u9650\u5236\u65b0\u65e7\u7b56\u7565\u4e4b\u95f4\u7684\u5dee\u5f02\uff08\u901a\u8fc7\u91cd\u8981\u6027\u91c7\u6837\u6bd4\u7387\u88c1\u526a\uff09\uff0c\u907f\u514d\u8fc7\u5927\u7684\u53c2\u6570\u66f4\u65b0\u5bfc\u81f4\u6027\u80fd\u5d29\u6e83\u3002PPO \u7ed3\u5408\u4e86\u6837\u672c\u9ad8\u6548\u6027\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u652f\u6301\u5e76\u884c\u5316\u91c7\u6837\uff0c\u56e0\u6b64\u6210\u4e3a\u5c11\u6709\u7684\u5728\u5b9e\u7269\u4e0a\u88ab\u5e7f\u6cdb\u5e94\u7528\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4e4b\u4e00\u3002</p> <p>\u672c\u9879\u76ee\u4e2d\u4f7f\u7528\u7ecf\u8fc7\u4fee\u6539\u7684 CleanRL PPO \u4ee3\u7801\uff0c\u6784\u5efa\u4e86\u57fa\u672c\u7684\u8bad\u7ec3\u5de5\u4f5c\u6d41\u3002\u7531\u4e8e\u73af\u5883\u63a5\u53e3\u8bbe\u8ba1\u4eff\u7167\u4e86 Gymnasium \u7684\u6807\u51c6\uff0c\u56e0\u6b64\u53ea\u9700\u8981\u5f88\u5c11\u7684\u6539\u52a8\u3002</p> WingedCone_PPO.py &gt; \u5e93\u5bfc\u5165<pre><code>import random \nimport numpy as np\nimport argparse\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\nfrom math import *\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.distributions.normal import Normal\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nimport aerodrome\nfrom aerodrome.simulator.CanonicalAircraftEnv.objects.WingedCone2D_RL import WingedCone2D_RL\n</code></pre> <p>\u8fd9\u91cc\u91c7\u7528\u4e00\u79cd\u5e38\u7528\u7684\u8fde\u7eed\u52a8\u4f5c PPO \u7684 actor \u5b9a\u4e49\uff0c\u5373\u52a8\u4f5c\u8f93\u51fa\u91cd\u53c2\u6570\u5316\u4e3a\u52a8\u4f5c\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee\uff0c\u5728\u4ece\u5176\u5bf9\u5e94\u7684\u6b63\u6001\u5206\u5e03\u4e2d\u91c7\u6837\u51fa\u52a8\u4f5c\u3002\u6b64\u5904\u7684\u5b9e\u73b0\u4e0e CleanRL PPO \u7565\u6709\u4e0d\u540c\uff0c\u5373\u52a8\u4f5c\u91c7\u6837\u589e\u52a0\u4e86\u4e00\u4e2a evaluate \u53c2\u6570\uff0c\u4f5c\u7528\u662f\u5728\u90e8\u7f72\u65f6\u5c06\u6b63\u6001\u5206\u5e03\u7684\u52a8\u4f5c\u8f6c\u6362\u4e3a\u56fa\u5b9a\u52a8\u4f5c\u3002\u8f93\u51fa\u52a8\u4f5c\u5747\u503c\u7684\u7f51\u7edc <code>actor_mean</code> \u6700\u540e\u8fd8\u52a0\u4e0a\u4e86\u4e00\u5c42 <code>Tanh</code> \u5c42\uff0c\u5e76\u5728\u91c7\u6837\u65f6\u9650\u5236\u52a8\u4f5c\u8303\u56f4\uff0c\u4ee5\u6ee1\u8db3\u4efb\u52a1\u9700\u8981\u3002</p> WingedCone_PPO.py &gt; \u6a21\u578b\u5b9a\u4e49<pre><code>def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n    torch.nn.init.orthogonal_(layer.weight, std)\n    torch.nn.init.constant_(layer.bias, bias_const)\n    return layer\n\nclass Agent(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.critic = nn.Sequential(\n            layer_init(nn.Linear(3, 256)),\n            nn.ReLU(),\n            layer_init(nn.Linear(256, 256)),\n            nn.ReLU(),\n            layer_init(nn.Linear(256, 256)),\n            nn.ReLU(),\n            layer_init(nn.Linear(256, 1), std=1.0),\n        )\n        self.actor_mean = nn.Sequential(\n            layer_init(nn.Linear(3, 128)),\n            nn.ReLU(),\n            layer_init(nn.Linear(128, 128)),\n            nn.ReLU(),\n            layer_init(nn.Linear(128, 128)),\n            nn.ReLU(),\n            layer_init(nn.Linear(128, 1), std=0.01),\n            nn.Tanh(),\n        )\n        self.actor_logstd = nn.Parameter(torch.zeros(1, 1))\n\n    def get_value(self, x):\n        return self.critic(x)\n\n    def get_action_and_value(self, x, action=None, evaluate=False):\n        action_mean = self.actor_mean(x)\n        action_logstd = self.actor_logstd.expand_as(action_mean)\n        action_std = torch.exp(action_logstd)\n        if evaluate:\n            probs = Normal(action_mean, action_std*1e-6) # \u8fd9\u91cc\u76f4\u63a5\u5c06 std \u4e58\u4ee5\u4e00\u4e2a\u5c0f\u6570\u6765\u6a21\u62df\u56fa\u5b9a\u52a8\u4f5c\uff0c\u6709\u70b9\u7b28b\u4f46\u662f\u53ef\u4ee5\u4fdd\u6301\u4e4b\u540e\u7684\u4ee3\u7801\u4e00\u81f4\u6027\n        else:\n            probs = Normal(action_mean, action_std)\n        if action is None:\n            action = probs.sample()\n        action = torch.clamp(action, -1.0, 1.0)\n        return action, probs.log_prob(action).sum(1), probs.entropy().sum(1), self.critic(x)\n\n\ndef linear_schedule(start_e, end_e, duration, t):\n    return start_e + (end_e - start_e) * min(t / duration, 1)\n</code></pre> WingedCone_PPO.py &gt; \u53c2\u6570\u89e3\u5305<pre><code>def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--seed\", type=int, default=0,\n                        help=\"random seed of the experiment\")\n    parser.add_argument(\"--num_steps\", type=int, default=1024,\n                        help=\"the number of steps to run per policy rollout\")\n    parser.add_argument(\"--total_timesteps\", type=int, default=300_000,\n                        help=\"the number of iterations\")\n    parser.add_argument(\"--batch_size\", type=int, default=256,\n                        help=\"the batch size of sample from the replay memory\")\n    parser.add_argument(\"--gamma\", type=float, default=0.99,\n                        help=\"discount factor\")\n    parser.add_argument(\"--gae_lambda\", type=float, default=0.95,\n                        help=\"lambda for the general advantage estimation\")\n    parser.add_argument(\"--num_minibatches\", type=int, default=1,\n                        help=\"the number of mini-batches\")\n    parser.add_argument(\"--update_epochs\", type=int, default=20,\n                        help=\"the K epochs to update the policy\")\n    parser.add_argument(\"--norm_adv\", type=bool, default=True,\n                        help=\"Toggles advantages normalization\")\n    parser.add_argument(\"--clip_coef\", type=float, default=0.2,\n                        help=\"the surrogate clipping coefficient\")\n    parser.add_argument(\"--clip_vloss\", type=bool, default=True,\n                        help=\"Toggles whether or not to use a clipped loss for the value function\")\n    parser.add_argument(\"--ent_coef\", type=float, default=0.2,\n                        help=\"coefficient of the entropy\")\n    parser.add_argument(\"--vf_coef\", type=float, default=2.,\n                        help=\"coefficient of the value function\")\n    parser.add_argument(\"--max_grad_norm\", type=float, default=0.5,\n                        help=\"the maximum norm for the gradient clipping\")\n    parser.add_argument(\"--target_kl\", type=float, default=None,\n                        help=\"the target KL divergence threshold\")\n\n    parser.add_argument(\"--learning_rate\", type=float, default=1e-4,\n                        help=\"learning rate\")\n    parser.add_argument(\"--device\", type=str, default=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n                        help=\"Device to run the experiment on\")\n    args = parser.parse_args()\n</code></pre> <p>\u8fd9\u90e8\u5206\u4ee3\u7801\u57fa\u672c\u4e0e CleanRL PPO \u76f8\u540c\uff0c\u9664\u4e86\u52a0\u5165\u4e86\u4e00\u4e9b\u6570\u636e\u50a8\u5b58\u7684\u90e8\u5206\u3001\u5220\u9664\u4e86\u539f\u7248\u7684 <code>tensorboard</code> \u90e8\u5206\u3002\u6b64\u5916\uff0c\u84dd\u8272\u9ad8\u4eae\u90e8\u5206\u7684\u4ee3\u7801\u4e0e\u539f\u7248\u4e5f\u6709\u5fae\u5999\u7684\u5dee\u522b\uff0c\u8fd9\u662f\u56e0\u4e3a\u539f\u7248\u4ee3\u7801\u6240\u4f7f\u7528\u7684\u73af\u5883\u548c\u6211\u4eec\u7684\u73af\u5883\u5bf9\u7ec8\u6b62\u7684\u5b9a\u4e49\u6709\u6240\u4e0d\u540c\u3002</p> WingedCone_PPO.py &gt; \u4e3b\u51fd\u6570 &amp; \u8bad\u7ec3\u5faa\u73af<pre><code>    args.batch_size = args.num_steps \n    args.minibatch_size = int(args.batch_size // args.num_minibatches)\n    args.num_iterations = args.total_timesteps // args.batch_size\n\n    random.seed(args.seed)\n    np.random.seed(args.seed)\n    torch.manual_seed(args.seed)\n    torch.backends.cudnn.deterministic = True\n\n    device = torch.device(args.device)\n    print(f\"Using device: {device}\")\n\n    env = aerodrome.make(\"wingedcone-v0\")\n    object_dict = {\n        \"name\": \"test\",\n        \"integrator\": \"rk45\",\n        \"S\": 3603.0,\n        \"c\": 80.0,\n        \"m\": 9375.0,\n\n        \"pos\": [0.0, 33528.0, 0.0],\n        \"vel\": [4590.29, 0.0, 0.0],\n        \"ang_vel\": [0.0, 0.0, 0.0],\n        \"J\": [1.0, 7*10**6, 7*10**6],\n        \"theta\": 0.00/180*pi,\n        \"phi\": 0.0,\n        \"gamma\": 0.0,   \n        \"theta_v\": 0.0,\n        \"phi_v\": 0.0,\n        \"gamma_v\": 0.0,\n        \"alpha\": 0.00/180*pi,\n        \"beta\": 0.0,\n\n        \"Kiz\": 0.2597,\n        \"Kwz\": 1.6,\n        \"Kaz\": 13/2,\n        \"Kpz\": 0.14,\n        \"Kp_V\": 5.0,\n        \"Ki_V\": 1.0,\n        \"Kd_V\": 0.3\n    }\n\n    object = WingedCone2D_RL(object_dict)\n    env.add_object(object)\n\n    agent = Agent().to(device)\n    optimizer = optim.Adam(agent.parameters(), lr=args.learning_rate, eps=1e-5)\n    cos_annealing_scheduler = CosineAnnealingLR(optimizer, T_max=args.num_iterations, eta_min=args.learning_rate/10)\n\n    # Storage setup\n    obs = torch.zeros((args.num_steps, 3)).to(device)\n    actions = torch.zeros((args.num_steps, 1)).to(device)\n    logprobs = torch.zeros((args.num_steps, 1)).to(device)\n    rewards = torch.zeros((args.num_steps, 1)).to(device)\n    dones = torch.zeros((args.num_steps, 1)).to(device)\n    values = torch.zeros((args.num_steps, 1)).to(device)\n\n    global_step = 0\n\n    records = {\n        \"reward\": np.zeros(args.num_iterations),\n        \"learning_rate\": np.zeros(args.num_iterations),\n        \"value_loss\": np.zeros(args.num_iterations),\n        \"policy_loss\": np.zeros(args.num_iterations),\n        \"entropy\": np.zeros(args.num_iterations),\n    }\n\n    for iteration in tqdm(range(1, args.num_iterations + 1)):\n        env = aerodrome.make(\"wingedcone-v0\")\n        object = WingedCone2D_RL(object_dict)\n        env.add_object(object)\n\n        next_obs, info = env.reset()\n        next_obs = torch.Tensor(next_obs).reshape((1, -1)).to(device)\n        first_rollout = True\n        rollout_return = 0.0\n        for step in range(0, args.num_steps):\n            global_step += 1\n            obs[step] = next_obs\n\n            # ALGO LOGIC: action logic\n            with torch.no_grad():\n                action, logprob, _, value = agent.get_action_and_value(next_obs)\n                values[step] = value.flatten()\n            actions[step] = action\n            logprobs[step] = logprob\n\n            # TRY NOT TO MODIFY: execute the game and log data.\n            step_action = {\n                \"test\": {\"Nyc\":1.0, \"Vc\":4590.29, \"nn_control\":action.item()},\n            }\n            next_obs, reward, terminations, truncations, infos = env.step(step_action)\n            next_done = np.logical_or(terminations, truncations)\n            rewards[step] = torch.tensor(reward).to(device).view(-1)\n            next_obs, next_done = torch.Tensor(next_obs).reshape((1, -1)).to(device), torch.Tensor(next_done).reshape((1, -1)).to(device)\n\n            dones[step] = next_done\n\n            if first_rollout:\n                rollout_return += reward\n                if next_done or step == args.num_steps - 1:\n                    first_rollout = False\n                    rewards[step] = rollout_return\n\n            if next_done:\n                \"\"\"\n                \u8fd9\u91cc\u5176\u5b9e\u662f\u5728\u505a\u73af\u5883 reset \uff0c\n                \u4f46\u7531\u4e8e python \u5bf9\u6765\u81ea pybind11 \u7684 C++ \u5bf9\u8c61\u7684\u5e8f\u5217\u5316 (picklize) \u7684\u652f\u6301\u6709\u95ee\u9898\uff0c\n                \u6240\u4ee5\u6682\u65f6\u6ca1\u6709\u76f4\u63a5\u5b9e\u73b0\u73af\u5883\u7684 reset\uff0c\u5148\u7528\u8fd9\u79cd\u65b9\u5f0f\u4ee3\u66ff\uff08\u91cd\u5efa\u4e00\u4e2a\u73af\u5883\uff09\n                \"\"\"\n                env = aerodrome.make(\"wingedcone-v0\")\n                object = WingedCone2D_RL(object_dict)\n                env.add_object(object)\n\n                next_obs, info = env.reset()\n                next_obs = torch.Tensor(next_obs).to(device)\n\n        # bootstrap value if not done\n        with torch.no_grad():\n            next_value = agent.get_value(next_obs).reshape(1, -1)\n            advantages = torch.zeros_like(rewards).to(device)\n            lastgaelam = 0\n            for t in reversed(range(args.num_steps)):\n                if t == args.num_steps - 1:\n                    nextnonterminal = 1.0 - next_done\n                    nextvalues = next_value\n                else:\n                    nextnonterminal = 1.0 - dones[t]\n                    nextvalues = values[t + 1]\n                delta = rewards[t] + args.gamma * nextvalues * nextnonterminal - values[t]\n                advantages[t] = lastgaelam = delta + args.gamma * args.gae_lambda * nextnonterminal * lastgaelam\n            returns = advantages + values\n\n        # flatten the batch\n        b_obs = obs.reshape((-1, 3))\n        b_logprobs = logprobs.reshape(-1)\n        b_actions = actions.reshape((-1, 1))\n        b_advantages = advantages.reshape(-1)\n        b_returns = returns.reshape(-1)\n        b_values = values.reshape(-1)\n\n        # Optimizing the policy and value network\n        b_inds = np.arange(args.batch_size)\n        clipfracs = []\n        for epoch in range(args.update_epochs):\n            np.random.shuffle(b_inds)\n            for start in range(0, args.batch_size, args.minibatch_size):\n                end = start + args.minibatch_size\n                mb_inds = b_inds[start:end]\n\n                _, newlogprob, entropy, newvalue = agent.get_action_and_value(b_obs[mb_inds], b_actions[mb_inds])\n                logratio = newlogprob - b_logprobs[mb_inds]\n                ratio = logratio.exp()\n\n                with torch.no_grad():\n                    # calculate approx_kl http://joschu.net/blog/kl-approx.html\n                    old_approx_kl = (-logratio).mean()\n                    approx_kl = ((ratio - 1) - logratio).mean()\n                    clipfracs += [((ratio - 1.0).abs() &gt; args.clip_coef).float().mean().item()]\n\n                mb_advantages = b_advantages[mb_inds]\n                if args.norm_adv:\n                    mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)\n\n                # Policy loss\n                pg_loss1 = -mb_advantages * ratio\n                pg_loss2 = -mb_advantages * torch.clamp(ratio, 1 - args.clip_coef, 1 + args.clip_coef)\n                pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n\n                # Value loss\n                newvalue = newvalue.view(-1)\n                if args.clip_vloss:\n                    v_loss_unclipped = (newvalue - b_returns[mb_inds]) ** 2\n                    v_clipped = b_values[mb_inds] + torch.clamp(\n                        newvalue - b_values[mb_inds],\n                        -args.clip_coef,\n                        args.clip_coef,\n                    )\n                    v_loss_clipped = (v_clipped - b_returns[mb_inds]) ** 2\n                    v_loss_max = torch.max(v_loss_unclipped, v_loss_clipped)\n                    v_loss = 0.5 * v_loss_max.mean()\n                else:\n                    v_loss = 0.5 * ((newvalue - b_returns[mb_inds]) ** 2).mean()\n\n                entropy_loss = entropy.mean()\n                loss = pg_loss - args.ent_coef * entropy_loss + v_loss * args.vf_coef\n\n                optimizer.zero_grad()\n                loss.backward()\n                nn.utils.clip_grad_norm_(agent.parameters(), args.max_grad_norm)\n                optimizer.step()\n\n            if args.target_kl is not None and approx_kl &gt; args.target_kl:\n                break\n\n        y_pred, y_true = b_values.cpu().numpy(), b_returns.cpu().numpy()\n        var_y = np.var(y_true)\n        explained_var = np.nan if var_y == 0 else 1 - np.var(y_true - y_pred) / var_y\n\n        records[\"reward\"][iteration - 1] = rewards.sum().item()\n        records[\"learning_rate\"][iteration - 1] = optimizer.param_groups[0][\"lr\"]\n        records[\"value_loss\"][iteration - 1] = v_loss.item()\n        records[\"policy_loss\"][iteration - 1] = pg_loss.item()\n        records[\"entropy\"][iteration - 1] = entropy_loss.item()\n\n        cos_annealing_scheduler.step()\n\n        if iteration == args.num_iterations:\n            states = []\n            rewards = []\n            env = aerodrome.make(\"wingedcone-v0\")\n            object = WingedCone2D_RL(object_dict)\n            env.add_object(object)\n            next_obs, info = env.reset()\n            next_obs = torch.Tensor(next_obs).reshape((1, -1)).to(device)\n            step = 0\n            while True:\n                step += 1\n                # ALGO LOGIC: action logic\n                states.append(env.get_state())\n                with torch.no_grad():\n                    action, logprob, _, value = agent.get_action_and_value(next_obs, evaluate=True)\n\n                # TRY NOT TO MODIFY: execute the game and log data.\n                step_action = {\n                    \"test\": {\"Nyc\":1.0, \"Vc\":4590.29, \"nn_control\":action.item()},\n                }\n                next_obs, reward, terminations, truncations, infos = env.step(step_action)\n                next_done = np.logical_or(terminations, truncations)\n                next_obs = torch.Tensor(next_obs).reshape((1, -1)).to(device)\n                rewards.append(reward)\n                if next_done or step &gt;= 1000:\n                    break\n            fig, ax = plt.subplots(1, 1)\n            x = np.array([states[i][\"pos\"][0] for i in range(len(states))])\n            y = np.array([states[i][\"Ny\"] for i in range(len(states))])\n            ax.plot(x, y)\n            ax.plot(x, rewards)\n            plt.show()\n\n    fig, ax = plt.subplots(1, 1)\n    ax.plot(records[\"reward\"])\n    ax.set_xlabel(\"Iteration\")\n    ax.set_ylabel(\"Reward\")\n    plt.show()\n\n    torch.save(agent.state_dict(), \"models/wingedcone_ppo.pth\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> PPO \u8bad\u7ec3\u66f2\u7ebf\uff0c\u6027\u80fd\u7531 5 \u4e2a\u968f\u673a\u79cd\u5b50\u5e73\u5747"},{"location":"longitudinal_control_rl/#wingedcone-python","title":"WingedCone - Python \u73af\u5883","text":"<p>\u8fd9\u91cc\u662f <code>wingedcone-v0</code> \u73af\u5883\uff08\u4e5f\u5c31\u662f\u4e0a\u9762\u7684 PPO \u4ee3\u7801\u4e2d\u7684 <code>env</code> \u6240\u5c5e\u7684\u7c7b\uff09\u7684\u5b9e\u73b0\uff1a</p> WingedCone_RL.py<pre><code>from aerodrome.core import Env\nfrom aerodrome.registration import register\nfrom aerodrome.simulator.Core.envs.Space3D import Space3D\nfrom copy import deepcopy\nimport numpy as np\n\nclass WingedCone_RL(Env):\n    def __init__(self):\n        self.env = Space3D(0.01, 0.001, 5) # \u521d\u59cb\u5316\u65f6\u521b\u5efa\u4e00\u4e2a Space3D \u7c7b\u5b9e\u4f8b\n        self.object_name = None\n        self.eNy_bound = 1 # \u8bbe\u7f6e\u7528\u4e8e\u8ba1\u7b97\u5956\u52b1\u51fd\u6570\u7684\u8d85\u53c2\u6570\n\n    def add_object(self, object):\n        self.env.add_object(object) # \u4ece\u4ea4\u4e92\u4e2d\u63a5\u6536\u4e00\u4e2a Aircraft3D \u7c7b\uff0c\u5e76\u52a0\u5165\u5230\u73af\u5883\u4e2d\n        self.object_name = object.to_dict()[\"name\"]\n\n    def reset(self):\n        # \u8fd9\u4e2a\u51fd\u6570\u5b9e\u9645\u4e0a\u662f\u4e0d\u53ef\u7528\u7684\uff01\u56e0\u4e3a C++ \u73af\u5883\u6ca1\u6709\u5b9e\u73b0 reset \u65b9\u6cd5\uff08\u56e0\u4e3a\u6ca1\u6709\u5408\u9002\u7684\u65b9\u6cd5\u6765\u91cd\u7f6e\u4e00\u4e2a C++ \u7c7b\uff09\n        # \u5f53\u7136\u4e5f\u6ca1\u529e\u6cd5\u76f4\u63a5 deepcopy \uff08\u4e0d\u652f\u6301\u5bf9 C++ \u5bf9\u8c61\u7684\u5e8f\u5217\u5316\uff09\n        # \u6240\u4ee5\u5f53\u4f60\u8981\u8c03\u7528\u8fd9\u4e2a\u65b9\u6cd5\u7684\u65f6\u5019\uff0c\u76f4\u63a5\u91cd\u5efa\u4e00\u4e2a\u73af\u5883\u597d\u4e86\n        self.env.reset()\n        state = self.env.to_dict()[self.object_name]\n        obs = np.array([state[\"eNy\"], state[\"i_eNy\"], state[\"d_eNy\"]])\n\n        return obs, {}\n\n    def step(self, action):\n        state = self.env.step(action)[self.object_name] # \u4ece\u4ea4\u4e92\u63a5\u6536\u52a8\u4f5c\uff0c\u8f93\u5165\u73af\u5883\uff0c\u83b7\u53d6\u8fd4\u56de\u72b6\u6001\n        obs = np.array([state[\"eNy\"], state[\"i_eNy\"], state[\"d_eNy\"]]) # \u89c2\u6d4b\u503c\u4e3a\u72b6\u6001\u4e2d\u7684 eNy\uff0ci_eNy \u548c d_eNy \uff08\u5373PI\u63a7\u5236\u5668\u539f\u5148\u63a5\u6536\u7684\u91cf\uff09\n\n        # \u5956\u52b1\u51fd\u6570\u7684\u8ba1\u7b97\uff08\u5176\u5b9e\u8fd9\u4e00\u90e8\u5206\u4e5f\u53ef\u4ee5\u632a\u5230 C++ \u4ee3\u7801\u4e2d\uff09\n        # \u5b9e\u73b0\u4e0a\u6765\u8bf4\u76f4\u63a5\u4f7f\u7528\u6700\u7b80\u5355\u7684 -np.tanh(np.abs(state[\"eNy\"]) / self.eNy_bound) + 1 \u6548\u679c\u597d\u50cf\u6700\u597d\n        if state[\"eNy\"] &gt; self.eNy_bound:\n            if state[\"d_eNy\"] &lt; 0:\n                reward = -np.tanh(np.abs(state[\"eNy\"]) / self.eNy_bound) + 1\n            else:\n                reward = -np.tanh(np.abs(state[\"eNy\"]) / self.eNy_bound)\n        elif state[\"eNy\"] &lt; -self.eNy_bound:\n            if state[\"d_eNy\"] &gt; 0:\n                reward = -np.tanh(np.abs(state[\"eNy\"]) / self.eNy_bound) + 1\n            else:\n                reward = -np.tanh(np.abs(state[\"eNy\"]) / self.eNy_bound)\n        else:\n            reward = -np.tanh(np.abs(state[\"eNy\"]) / self.eNy_bound) + 1\n\n        if state[\"alpha\"] &gt; 88*np.pi/180 or state[\"alpha\"] &lt; -88*np.pi/180:\n            terminated = np.array([1], dtype=np.bool_)\n            reward -= 10.0\n        else:\n            terminated = np.array([0], dtype=np.bool_)\n\n        return obs, reward, terminated, False, {}\n\n    def get_state(self):\n        state = self.env.to_dict()[self.object_name]\n        return state\n\nregister(\"wingedcone-v0\", \"aerodrome.envs.WingedCone_RL:WingedCone_RL\") # \u628a\u73af\u5883\u6ce8\u518c\u5230 Aerodrome \u6a21\u5757\u4e2d\n</code></pre>"},{"location":"longitudinal_control_rl/#wingedcone2d-ppo","title":"WingedCone2D - PPO","text":"<p><code>WingedCone2D_PPO</code> \u7c7b\u4e5f\u662f <code>WingedCone2D</code> \u7684\u5b50\u7c7b\uff0c\u4e0e <code>WingedCone2D_Classic</code> \u57fa\u672c\u76f8\u540c\uff0c\u533a\u522b\u4ec5\u4e3a\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u66ff\u6362\u4e86 PI \u63a7\u5236\u5668\uff1a</p> <pre><code>// \u5f3a\u5316\u5b66\u4e60\u63a7\u5236\ndouble Ny_controller(double nn_control, double wz, double dt)\n{\n    // \u589e\u7a33\u56de\u8def\uff0c\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u4ee3\u66ffPI\u73af\u8282\n    double eSAC = nn_control - Kaz * wz;\n    i_eSAC += eSAC * dt;\n\n    // \u963b\u5c3c\u56de\u8def\n    double eDamp = i_eSAC - Kwz * wz;\n\n    return eDamp;\n}\n\n// \u4f20\u7edf\u63a7\u5236\ndouble Ny_controller(double Nyc, double Ny, double wz, double dt)\n{\n    // \u8fc7\u8f7d\u8ddf\u8e2a\u8bef\u5dee\n    eNy = Nyc - Ny;\n\n    // PI\u6821\u6b63\u73af\u8282\n    i_eNy += eNy * dt;\n    p_eNy = eNy;\n\n    double pi_eNy = Kiz * i_eNy + Kpz * p_eNy;\n\n    // \u589e\u7a33\u56de\u8def\n    double eSAC = pi_eNy - Kaz * wz;\n    i_eSAC += eSAC * dt;\n\n    // \u963b\u5c3c\u56de\u8def\n    double eDamp = i_eSAC - Kwz * wz;\n\n    return eDamp;\n}\n</code></pre> <p>\u5176\u4e2d\u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u5165\u4e0e PI \u63a7\u5236\u5668\u76f8\u540c\uff0c\u4e3a\u8fc7\u8f7d\u504f\u5dee <code>eNy</code> \u53ca\u5176\u5fae\u5206 <code>d_eNy</code>\u3001\u79ef\u5206 <code>i_eNy</code>\uff1b</p> \u70b9\u51fb\u5c55\u5f00\u5b8c\u6574\u4ee3\u7801 WingedCone2D_RL.h<pre><code>#pragma once\n\n#include &lt;pybind11/pybind11.h&gt;\n#include &lt;pybind11/stl.h&gt;\n#include \"WingedCone2D.h\"\n#include &lt;vector&gt;\n#include &lt;string&gt;\n#include &lt;array&gt;\n#include &lt;cmath&gt;\n\nnamespace py = pybind11;\n\nclass WingedCone2D_RL : public WingedCone2D\n{\npublic:\n    // \u4fef\u4ef0\u89d2\u589e\u7a33\u8fc7\u8f7d\u9a7e\u9a76\u4eea\u63a7\u5236\u53c2\u6570\n    double Kiz;   // \u79ef\u5206\u589e\u76ca\n    double Kwz;   // \u89d2\u901f\u5ea6\u589e\u76ca\n    double Kaz;   // \u589e\u7a33\u56de\u8def\u589e\u76ca\n    double Kpz;   // \u6bd4\u4f8b\u589e\u76ca\n\n    double eNy; // \u8fc7\u8f7d\u8ddf\u8e2a\u8bef\u5dee\n    double eNy_prev; // \u8fc7\u8f7d\u8bef\u5dee\u524d\u503c\n    double i_eNy; // \u8fc7\u8f7d\u79ef\u5206\u9879\n    double d_eNy; // \u8fc7\u8f7d\u6bd4\u4f8b\u9879\n\n    double i_eSAC; // \u589e\u7a33\u56de\u8def\u79ef\u5206\u9879\n\n    double Kp_V, Ki_V, Kd_V; // \u901f\u5ea6\u63a7\u5236\u53c2\u6570\n\n    double i_V; // \u901f\u5ea6\u79ef\u5206\u9879\n    double d_eV; // \u901f\u5ea6\u5fae\u5206\u9879\n    double eV_prev; // \u901f\u5ea6\u8bef\u5dee\u524d\u503c\n\n    double Ny; // \u5f53\u524d\u8fc7\u8f7d\n    double wz; // \u5f53\u524d\u6eda\u8f6c\u89d2\u901f\u5ea6\n\n    WingedCone2D_RL() {}\n\n    WingedCone2D_RL(py::dict input_dict) : WingedCone2D(input_dict)\n    {\n        Kiz = input_dict[\"Kiz\"].cast&lt;double&gt;();\n        Kwz = input_dict[\"Kwz\"].cast&lt;double&gt;();\n        Kaz = input_dict[\"Kaz\"].cast&lt;double&gt;();\n        Kpz = input_dict[\"Kpz\"].cast&lt;double&gt;();\n\n        Kp_V = input_dict[\"Kp_V\"].cast&lt;double&gt;();\n        Ki_V = input_dict[\"Ki_V\"].cast&lt;double&gt;();\n        Kd_V = input_dict[\"Kd_V\"].cast&lt;double&gt;();\n\n        eNy = 0;\n        eNy_prev = 0;\n        i_eNy = 0;\n        d_eNy = 0;\n        i_eSAC = 0;\n        i_V = 0;\n        d_eV = 0;\n        eV_prev = 0;\n\n        _D();\n        _L();\n        _T();\n        _M();\n\n        Ny = (T * (sin(alpha) * cos(gamma_v) - cos(alpha) * sin(beta) * sin(gamma_v))\n                                + L * cos(gamma_v) - N * sin(gamma_v) - m * g * cos(theta_v)) / (m * g);\n        wz = ang_vel[2];\n    }\n\n    virtual void reset() override\n    {\n        *this = WingedCone2D_RL(initial_state);\n    }\n\n    double V_controller(double Vc, double V, double dt)\n    {\n        // \u901f\u5ea6\u8ddf\u8e2a\u8bef\u5dee\n        double eV = Vc - V;\n        i_V += eV * dt;\n        d_eV = (eV - eV_prev) / dt;\n        eV_prev = eV;\n\n        double u1a = Kp_V * eV + Ki_V * i_V + Kd_V * d_eV;\n        if (u1a &lt; 0) \n        {\n            u1a = 0;\n        }\n\n        return u1a;\n    }\n\n    double Ny_controller(double nn_control, double wz, double dt)\n    {\n        // \u589e\u7a33\u56de\u8def\uff0c\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u4ee3\u66ffPI\u73af\u8282\n        double eSAC = nn_control - Kaz * wz;\n        i_eSAC += eSAC * dt;\n\n        // \u963b\u5c3c\u56de\u8def\n        double eDamp = i_eSAC - Kwz * wz;\n\n        return eDamp;\n    }\n\n    virtual py::dict to_dict() override\n    {\n        py::dict output_dict = WingedCone2D::to_dict();\n        output_dict[\"Ny\"] = Ny;\n        output_dict[\"eNy\"] = eNy;\n        output_dict[\"i_eNy\"] = i_eNy;\n        output_dict[\"d_eNy\"] = d_eNy;\n\n        return output_dict;\n    }\n\n    virtual py::object step(py::dict action) override\n    {\n        double dt = action[\"dt\"].cast&lt;double&gt;();\n\n        double Nyc = action[\"Nyc\"].cast&lt;double&gt;();\n        double Vc = action[\"Vc\"].cast&lt;double&gt;();\n        double nn_control = action[\"nn_control\"].cast&lt;double&gt;();\n\n        delta_e = Ny_controller(nn_control, wz, dt*0.1);\n        delta_e = std::clamp(delta_e, -25 / 57.3, 25 / 57.3);\n\n        double Phi = V_controller(Vc, V, dt*0.1);\n\n        // \u8ba1\u7b97\u6c14\u52a8\u529b\n        _D();\n        _L();\n        _T();\n        _M();\n\n        if (integrator == \"euler\")\n        {\n            *this = *this + this-&gt;d() * dt;\n        }\n        else if (integrator == \"midpoint\")\n        {\n            auto temp1 = *this + this-&gt;d() * (0.5 * dt);\n            auto k1 = temp1.d();\n            *this = *this + k1 * dt;\n        }\n        else if (integrator == \"rk23\")\n        {\n            auto k1 = this-&gt;d();\n            auto temp1 = *this + k1 * (0.5 * dt);\n            auto k2 = temp1.d();\n            auto temp2 = *this + k2 * (0.5 * dt);\n            auto k3 = temp2.d();\n            *this = *this + (k1 + k2 * 2 + k3) * (dt / 4);\n        }\n        else if (integrator == \"rk45\")\n        {\n            auto k1 = this-&gt;d();\n            auto temp1 = *this + k1 * (0.5 * dt);\n            auto k2 = temp1.d();\n            auto temp2 = *this + k2 * (0.5 * dt);\n            auto k3 = temp2.d();\n            auto temp3 = *this + k3 * dt;\n            auto k4 = temp3.d();\n            *this = *this + (k1 + k2 * 2 + k3 * 2 + k4) * (dt / 6);\n        }\n\n        beta = cos(theta_v) * (cos(gamma) * sin(phi - phi_v) + sin(theta) * sin(gamma) * cos(phi - phi_v)) - sin(theta_v) * cos(theta) * sin(gamma);\n        alpha = (cos(theta_v) * (sin(theta) * cos(gamma) * cos(phi - phi_v) - sin(gamma) * sin(phi - phi_v)) - sin(theta_v) * cos(theta) * cos(gamma)) / cos(beta);\n        gamma_v = (cos(alpha) * sin(beta) * sin(theta) - sin(alpha) * sin(beta) * cos(gamma) * cos(theta) + cos(beta) * sin(gamma) * cos(theta)) / cos(theta_v);\n\n        V = Vc;\n        vel[0] = V * cos(theta_v) * cos(phi_v);\n        vel[1] = V * sin(theta_v);\n        vel[2] = -V * cos(theta_v) * sin(phi_v);\n        h = pos[1];\n\n        Tem = Temperature(h);\n        Pres = Pressure(h);\n        Rho = Density(Tem, Pres);\n        a = SpeedofSound(Tem);\n        g = Gravity(h);\n\n        q = 0.5 * Rho * V * V;\n\n        Ny = (T * (sin(alpha) * cos(gamma_v) - cos(alpha) * sin(beta) * sin(gamma_v))\n                                + L * cos(gamma_v) - N * sin(gamma_v) - m * g * cos(theta_v)) / (m * g);\n        wz = ang_vel[2];\n\n        eNy = Nyc - Ny;\n        i_eNy += eNy * dt;\n        d_eNy = (eNy - eNy_prev) / dt;\n        eNy_prev = eNy;\n\n        return to_dict();\n    }\n};\n</code></pre>"},{"location":"longitudinal_control_rl/#ppo","title":"PPO \u548c\u4f20\u7edf\u63a7\u5236\u7684\u6bd4\u8f83","text":"<p>\u4f7f\u7528\u524d\u9762\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u6587\u4ef6 <code>wingedcone_ppo.pth</code>\uff0c\u4e0e\u4f20\u7edf\u63a7\u5236\u65b9\u6cd5\uff08\u4e09\u56de\u8def\u9a7e\u9a76\u4eea\uff09\u5728\u9636\u8dc3\u54cd\u5e94\u4e0b\u8fdb\u884c\u6bd4\u8f83\uff1a</p> \u70b9\u51fb\u5c55\u5f00\u5b8c\u6574\u4ee3\u7801 StepResponse.py<pre><code>import random\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom math import *\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.distributions.normal import Normal\n\nimport aerodrome\nfrom aerodrome.simulator.CanonicalAircraftEnv.objects.WingedCone2D_RL import WingedCone2D_RL\nfrom aerodrome.simulator.CanonicalAircraftEnv.objects.WingedCone2D_Classic import WingedCone2D_Classic\nfrom aerodrome.simulator.Core.envs.Space3D import Space3D\n\ndef layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n    torch.nn.init.orthogonal_(layer.weight, std)\n    torch.nn.init.constant_(layer.bias, bias_const)\n    return layer\n\nclass Agent(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.critic = nn.Sequential(\n            layer_init(nn.Linear(3, 256)),\n            nn.ReLU(),\n            layer_init(nn.Linear(256, 256)),\n            nn.ReLU(),\n            layer_init(nn.Linear(256, 256)),\n            nn.ReLU(),\n            layer_init(nn.Linear(256, 1), std=1.0),\n        )\n        self.actor_mean = nn.Sequential(\n            layer_init(nn.Linear(3, 128)),\n            nn.ReLU(),\n            layer_init(nn.Linear(128, 128)),\n            nn.ReLU(),\n            layer_init(nn.Linear(128, 128)),\n            nn.ReLU(),\n            layer_init(nn.Linear(128, 1), std=0.01),\n            nn.Tanh(),\n        )\n        self.actor_logstd = nn.Parameter(torch.zeros(1, 1))\n\n    def get_value(self, x):\n        return self.critic(x)\n\n    def get_action_and_value(self, x, action=None, evaluate=False):\n        action_mean = self.actor_mean(x)\n        action_logstd = self.actor_logstd.expand_as(action_mean)\n        action_std = torch.exp(action_logstd)\n        if evaluate:\n            probs = Normal(action_mean, action_std*1e-6)\n        else:\n            probs = Normal(action_mean, action_std)\n        if action is None:\n            action = probs.sample()\n        action = torch.clamp(action, -1.0, 1.0)\n        return action, probs.log_prob(action).sum(1), probs.entropy().sum(1), self.critic(x)\n\n\ndef linear_schedule(start_e, end_e, duration, t):\n    return start_e + (end_e - start_e) * min(t / duration, 1)\n\ndef main():\n    fig, ax = plt.subplots(1, 1)\n    ax.axhline(y=1.0, color='r', linestyle='--', alpha=0.5)\n    ax.set_xlabel(\"Time (s)\")\n    ax.set_ylabel(\"Ny\")\n\n    random.seed(0)\n    np.random.seed(0)\n    torch.manual_seed(0)\n    torch.backends.cudnn.deterministic = True\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n\n    object_dict = {\n        \"name\": \"test\",\n        \"integrator\": \"rk45\",\n        \"S\": 3603.0,\n        \"c\": 80.0,\n        \"m\": 9375.0,\n\n        \"pos\": [0.0, 33528.0, 0.0],\n        \"vel\": [4590.29, 0.0, 0.0],\n        \"ang_vel\": [0.0, 0.0, 0.0],\n        \"J\": [1.0, 7*10**6, 7*10**6],\n        \"theta\": 0.00/180*pi,\n        \"phi\": 0.0,\n        \"gamma\": 0.0,   \n        \"theta_v\": 0.0,\n        \"phi_v\": 0.0,\n        \"gamma_v\": 0.0,\n        \"alpha\": 0.00/180*pi,\n        \"beta\": 0.0,\n\n        \"Kiz\": 0.2597,\n        \"Kwz\": 1.6,\n        \"Kaz\": 13/2,\n        \"Kpz\": 0.14,\n        \"Kp_V\": 5.0,\n        \"Ki_V\": 1.0,\n        \"Kd_V\": 0.3\n    }\n\n    env = aerodrome.make(\"wingedcone-v0\")\n    object = WingedCone2D_RL(object_dict)\n    env.add_object(object)\n\n    agent = Agent().to(device)\n    agent.load_state_dict(torch.load(\"wingedcone_ppo.pth\"))\n    agent.eval()\n\n    states = []\n    rewards = []\n    next_obs, info = env.reset()\n    next_obs = torch.Tensor(next_obs).reshape((1, -1)).to(device)\n    step = 0\n    while True:\n        step += 1\n        states.append(env.get_state())\n        with torch.no_grad():\n            action, logprob, _, value = agent.get_action_and_value(next_obs, evaluate=True)\n\n        step_action = {\n            \"test\": {\"Nyc\":1.0, \"Vc\":4590.29, \"nn_control\":action.item()},\n        }\n        next_obs, reward, terminations, truncations, infos = env.step(step_action)\n        next_done = np.logical_or(terminations, truncations)\n        next_obs = torch.Tensor(next_obs).reshape((1, -1)).to(device)\n        rewards.append(reward)\n        if next_done or step &gt;= 1000:\n            break\n\n    x = np.arange(1000) * 0.01\n    y = np.array([states[i][\"Ny\"] for i in range(len(states))])\n    ax.plot(x, y, label=\"RL\")\n\n    # Classical control\n    env = Space3D(0.01, 0.001, 5)\n    object = WingedCone2D_Classic(object_dict)\n    env.add_object(object)\n\n    cnt = 1000\n    y = np.zeros(cnt)\n\n    for i in range(cnt):\n        action = {\"test\": {\"Nyc\":1.0, \"Vc\":4590.29}}\n        result = env.step(action)\n        y[i] = result[\"test\"][\"Ny\"]\n\n    ax.plot(x, y, label=\"Classic\")\n    ax.legend()\n    plt.show()\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> \u9636\u8dc3\u54cd\u5e94\u6027\u80fd\u6bd4\u8f83"},{"location":"minimal_example/","title":"\u6700\u7b80\u73af\u5883","text":"<p>\u4e3a\u4e86\u65b9\u4fbf\u7528\u6237\u7406\u89e3 Aerodrome \u7684\u8fd0\u884c\u903b\u8f91\uff0c\u8fd9\u91cc\u63d0\u4f9b\u4e00\u4e2a\u6700\u7b80\u7684\u4f8b\u5b50\u3002</p> <p>\u4f7f\u7528\u5230\u7684\u4ee3\u7801\uff1a</p> <ul> <li>C++ \u73af\u5883\uff1a <code>src/simulator/MinimalExample/envs/MinimalEnv.h</code></li> <li>Pybind11 \u7ed1\u5b9a\uff1a <code>src/simulator/MinimalExample/envs/MinimalEnv.cpp</code></li> <li>Python \u73af\u5883\uff1a <code>python/aerodrome/envs/Minimal.py</code></li> <li>\u4ea4\u4e92\u4ee3\u7801\uff1a <code>examples/MinimalExample/MinimalExample.py</code></li> </ul>"},{"location":"minimal_example/#c","title":"C++ \u73af\u5883","text":"MinimalEnv.h<pre><code>class MinimalEnv : public BaseEnv { // \u7ee7\u627f\u81ea BaseEnv\npublic:\n    MinimalEnv() : cpp_state(0) {} // \u521d\u59cb\u5316 cpp_state \u4e3a 0\n\n    ~MinimalEnv() {} // \u6790\u6784\u51fd\u6570\n\n    py::object reset() override // \u91cd\u5199 BaseEnv \u4e2d\u5b9a\u4e49\u7684 reset \u65b9\u6cd5\n    {\n        py::dict result; // \u521b\u5efa\u4e00\u4e2a\u5b57\u5178\u6765\u5b58\u50a8\u8981\u8fd4\u56de\u7684\u7ed3\u679c\n        cpp_state = 0; // \u5c06 cpp_state \u91cd\u7f6e\u4e3a 0\n        result[\"cpp_state\"] = cpp_state;\n        result[\"info\"] = \"\";\n        return result;\n    }\n\n    py::object step(const py::object&amp; action) override // step \u65b9\u6cd5\u4ece Python \u7aef\u63a5\u6536\u52a8\u4f5c\n    {\n        // \u5728\u6bcf\u4e00\u6b65\u4e2d\uff0c\u73af\u5883\u5c06 action[\"value\"] \u7684\u503c\u52a0\u5230\u5176 cpp_state \u4e0a\n        py::dict result;\n        if (action.contains(\"value\"))\n        {\n            try {\n                int value = action[\"value\"].cast&lt;int&gt;(); // \u5c06 action[\"value\"] \u7684\u503c\u8f6c\u6362\u4e3a\u6574\u6570\n                cpp_state += value; // \u5c06\u8be5\u503c\u52a0\u5230 cpp_state \u4e0a\n            } catch (const std::exception &amp;e) {\n                result[\"info\"] = std::string(\"failed to convert value to int: \") + e.what(); // \u5982\u679c\u8be5\u503c\u4e0d\u662f\u6574\u6570\uff0c\u5728\u7ed3\u679c\u4e2d\u6dfb\u52a0\u9519\u8bef\u4fe1\u606f\n            }\n        }\n        else\n        {\n            result[\"info\"] = \"error: action must contain 'value'\";\n        }\n\n        result[\"cpp_state\"] = cpp_state;\n        if (!result.contains(\"info\"))\n        {\n            // \u5982\u679c\u7ed3\u679c\u4e2d\u6ca1\u6709 info \u952e\uff0c\u6dfb\u52a0\u4e00\u4e2a\u7a7a\u5b57\u7b26\u4e32\uff0c\u4ee5\u907f\u514d key error\n            result[\"info\"] = \"\";\n        }\n        return result;\n    }\n\nprivate:\n    int cpp_state = 0; // \u79c1\u6709\u6210\u5458\u53d8\u91cf\uff0c\u7528\u4e8e\u5b58\u50a8\u73af\u5883\u7684\u72b6\u6001\n};\n</code></pre>"},{"location":"minimal_example/#python","title":"Python \u73af\u5883","text":"Minimal.py<pre><code>class Minimal(Env):\n    def __init__(self):\n        self.env = MinimalEnv() # \u521d\u59cb\u5316 C++ \u73af\u5883\n        self.state = 0 # \u521d\u59cb\u5316 Python \u73af\u5883\u5185\u90e8\u72b6\u6001\n        print(\"Initialize MinimalEnv\")\n\n    def step(self, action):\n        self.state += 1 # \u5728\u6bcf\u4e00\u6b65\u4e2d\uff0cPython \u73af\u5883\u5185\u90e8\u72b6\u6001\u52a0 1\n        try:\n            input_dict = {\n                \"value\": action, # \u5c06 Python \u73af\u5883\u63a5\u6536\u5230\u7684\u6574\u6570\u8f6c\u6362\u4e3a\u52a8\u4f5c\u5b57\u5178\n            }\n            result = self.env.step(input_dict) # \u8c03\u7528 C++ \u73af\u5883\u7684 step \u65b9\u6cd5\uff0c\u5e76\u63a5\u6536\u8fd4\u56de\u7ed3\u679c\n            result[\"py_state\"] = self.state # \u5c06 Python \u73af\u5883\u5185\u90e8\u72b6\u6001\u6dfb\u52a0\u5230\u8fd4\u56de\u7ed3\u679c\u4e2d\n            return result\n        except ValueError:\n            print(\"input a valid integer\")\n        except KeyboardInterrupt:\n            print(\"\\nquit\")\n\n    def reset(self):\n        self.state = 0 # \u91cd\u7f6e Python \u73af\u5883\u5185\u90e8\u72b6\u6001\n        print(\"Reset MinimalEnv\")\n        result = self.env.reset() # \u8c03\u7528 C++ \u73af\u5883\u7684 reset \u65b9\u6cd5\uff0c\u5e76\u63a5\u6536\u8fd4\u56de\u7ed3\u679c\n        result[\"py_state\"] = self.state # \u5c06 Python \u73af\u5883\u5185\u90e8\u72b6\u6001\u6dfb\u52a0\u5230\u8fd4\u56de\u7ed3\u679c\u4e2d\n        return result\n\n    def close(self):\n        print(\"Close MinimalEnv\") # \u5728\u6709\u4e9b\u60c5\u51b5\u4e0b\uff0c\u53ef\u80fd\u9700\u8981\u5728\u5173\u95ed\u73af\u5883\u65f6\u8fdb\u884c\u4e00\u4e9b\u6e05\u7406\u5de5\u4f5c\n</code></pre>"},{"location":"minimal_example/#_2","title":"\u4ea4\u4e92\u4ee3\u7801","text":"MinimalExample.py<pre><code>if __name__ == \"__main__\":\n    env = aerodrome.make(\"minimal-v0\") # \u521b\u5efa Python \u73af\u5883\n    result = env.reset() # \u91cd\u7f6e\u73af\u5883\n    print(result) # \u6253\u5370\u91cd\u7f6e\u540e\u8fd4\u56de\u7684\u7ed3\u679c\n\n    while True:\n        try:\n            action = input(\"Enter an action value: \") # \u4ece\u7528\u6237\u8f93\u5165\u83b7\u53d6\u52a8\u4f5c\uff08\u4e00\u4e2a\u6574\u6570\uff09\n        except KeyboardInterrupt:\n            env.close()\n            break\n\n        try:\n            action = int(action) # \u5c06\u7528\u6237\u8f93\u5165\u7684\u52a8\u4f5c\u8f6c\u6362\u4e3a\u6574\u6570\n        except ValueError:\n            print(\"Invalid action value\")\n            continue\n        result = env.step(action) # \u8c03\u7528\u73af\u5883 step \u65b9\u6cd5\uff0c\u5e76\u63a5\u6536\u8fd4\u56de\u7ed3\u679c\n        print(result) # \u6253\u5370\u8fd4\u56de\u7ed3\u679c\n\n        if result[\"py_state\"] &gt; 10: # \u5982\u679c Python \u73af\u5883\u5185\u90e8\u72b6\u6001\u5927\u4e8e 10\uff08\u5927\u4e8e 10 \u6b65\uff09\uff0c\u5219\u91cd\u7f6e\u73af\u5883\n            result = env.reset()\n            print(result)\n</code></pre>"},{"location":"minimal_example/#_3","title":"\u8fd0\u884c\u7ed3\u679c","text":"<pre><code>$ python examples/MinimalExample/MinimalExample.py\nInitialize MinimalEnv\nReset MinimalEnv\n{'cpp_state': 0, 'info': '', 'py_state': 0}\nEnter an action value: 2\n{'cpp_state': 2, 'info': '', 'py_state': 1}\nEnter an action value: 12\n{'cpp_state': 14, 'info': '', 'py_state': 2}\nEnter an action value: 18\n{'cpp_state': 32, 'info': '', 'py_state': 3}\nEnter an action value: Close MinimalEnv\n</code></pre>"},{"location":"minimal_example/#pybind11","title":"Pybind11 \u7ed1\u5b9a","text":"<p>\u5982\u679c\u4f60\u9700\u8981\u81ea\u5df1\u5b9e\u73b0\u73af\u5883\uff0c\u5e94\u5f53\u6309\u7167\u5982\u4e0b\u683c\u5f0f\u5199\u597d\u7ed1\u5b9a\u4ee3\u7801\uff0c\u6216\u53c2\u8003 <code>pybind11</code> \u7684 \u5b98\u65b9\u6587\u6863\u3002 <pre><code>PYBIND11_MODULE(MinimalEnv, m) {\n    py::class_&lt;MinimalEnv, BaseEnv&gt;(m, \"MinimalEnv\")\n        .def(py::init&lt;&gt;())\n        .def(\"reset\", &amp;MinimalEnv::reset)\n        .def(\"step\", &amp;MinimalEnv::step);\n}\n</code></pre></p>"},{"location":"project_structure/","title":"\u9879\u76ee\u7ed3\u6784","text":"<p>Aerodrome \u7531 C++ \u548c Python \u4e24\u90e8\u5206\u7ec4\u6210\uff1b\u5176\u4e2d C++ \u51fd\u6570/\u7c7b\u9700\u8981\u5148\u901a\u8fc7 <code>pybind11</code> \u7f16\u8bd1\u4e3a <code>.pyd</code> \u6216 <code>.so</code> \u6587\u4ef6\uff0c\u518d\u88ab Python \u4ee3\u7801\u8c03\u7528\u3002</p> <pre><code>./Aerodrome\n\u251c\u2500docs                              # \u9879\u76ee\u6587\u6863\n\u251c\u2500examples                          # \u793a\u4f8b\n\u2502  \u251c\u2500AircraftControl       \n\u2502  \u2502  \u251c\u2500 StepResponse.py            # \u4f20\u7edf\u63a7\u5236\u548c\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u7684\u9636\u8dc3\u54cd\u5e94\u6bd4\u8f83\n\u2502  |  \u251c\u2500 WingedCone_Classic.py      # \u4f20\u7edf\u63a7\u5236\u65b9\u6cd5(\u76f4\u63a5\u8c03\u7528 C++ \u4ee3\u7801)\n\u2502  |  \u251c\u2500 WingedCone_PPO.py          # \u5f3a\u5316\u5b66\u4e60\u63a7\u5236(C++ \u4eff\u771f/ Python \u4ea4\u4e92\u73af\u5883)\n\u2502  |  \u2514\u2500 WingedCone_TimeCompare.py  # C++ \u548c Python \u4eff\u771f\u8fd0\u884c\u901f\u5ea6\u6bd4\u8f83\n\u2502  \u251c\u2500CartPole                       # DQN \u5b9e\u73b0\u7684 CartPole \u63a7\u5236\n\u2502  \u2514\u2500MinimalExample                 # \u6700\u7b80\u793a\u4f8b\u73af\u5883\n\u251c\u2500include\n\u2502  \u2514\u2500pybind11\n\u251c\u2500models                            # \u9884\u8bad\u7ec3\u6a21\u578b\n\u251c\u2500python                            # Python \u6e90\u7801\n\u2502  \u251c\u2500aerodrome \n\u2502  \u2502  \u251c\u2500envs                        # \u4ea4\u4e92\u73af\u5883\uff0c\u5904\u7406\u7528\u6237\u548cC++\u4eff\u771f\u4e4b\u95f4\u7684\u4fe1\u606f\u4ea4\u4e92\n\u2502  \u2502  \u2514\u2500simulator                   # \u7f16\u8bd1\u597d\u7684 C++ \u4ee3\u7801\u4f1a\u81ea\u52a8\u5b58\u653e\u5230\u6b64\u5904\n\u2502  \u2502      \u251c\u2500CanonicalAircraftEnv \n\u2502  \u2502      \u2502  \u251c\u2500envs                 # \u73af\u5883\u7c7b(\u901a\u5e38\u60c5\u51b5\u4e0b\u73af\u5883\u548c\u5b9e\u4f53\u662f\u4f5c\u4e3a\u4e0d\u540c\u7c7b\u7f16\u5199\u7684)\n\u2502  \u2502      \u2502  \u2514\u2500objects              # \u5b9e\u4f53\u7c7b\n\u2502  \u2502      \u251c\u2500CartPole\n\u2502  \u2502      \u2502  \u2514\u2500envs\n\u2502  \u2502      \u251c\u2500Core\n\u2502  \u2502      \u2502  \u251c\u2500envs\n\u2502  \u2502      \u2502  \u2514\u2500objects\n\u2502  \u2502      \u2514\u2500MinimalExample\n\u2502  \u2502          \u2514\u2500envs\n\u2502  \u2514\u2500aerodrome.egg-info\n\u2514\u2500src                              # C++ \u6e90\u7801\n   \u2514\u2500simulator\n       \u251c\u2500CanonicalAircraftEnv\n       \u2502  \u251c\u2500envs\n       \u2502  \u2514\u2500objects\n       \u251c\u2500CartPole\n       \u2502  \u251c\u2500envs\n       \u2502  \u2514\u2500objects\n       \u251c\u2500Core\n       \u2502  \u251c\u2500envs\n       \u2502  \u2514\u2500objects\n       \u2514\u2500MinimalExample\n           \u251c\u2500envs\n           \u2514\u2500objects\n</code></pre>"},{"location":"en/","title":"Aerodrome - Overview","text":"<p>Aerodrome is a lightweight library based on the joint programming of C++ and Python, focusing on providing high-performance dynamics simulation, Python interaction interfaces, and code examples for reinforcement learning and traditional control. It primarily targets two types of users: beginners in reinforcement learning research, or researchers who wish to apply reinforcement learning to specific fields (such as flight control) and need custom simulation environments. To ensure good modifiability and readability, every part of Aerodrome avoids the use of complex generic programming or advanced language features, and includes detailed comments in the code.</p> <p>The main contents and features of Aerodrome include:</p> <ul> <li> <p>Mimicking the code and interface style of Gym</p> </li> <li> <p>An example environment and a migrated version of Gym-CartPole for testing the correctness of reinforcement learning algorithms</p> </li> <li> <p>Highly customizable fixed-wing aircraft simulation example code</p> </li> <li> <p>A nonlinear aerodynamic model of the Winged-Cone based on publicly available data, along with its dynamics simulation (available in both C++ and Python, including performance comparisons!)</p> </li> <li> <p>Traditional three-loop autopilot implementation and Proximal Policy Optimization (PPO) implementation for longitudinal load control of the Winged-Cone</p> </li> </ul> <p>Note Aerodrome is not a modular library, therefore it is not suitable for import and use. Aerodrome sacrifices some code duplication to ensure that all code is concise, easy to understand, and convenient to extend. Aerodrome also has its limitations, such as the lack of visualization and experimental result saving functions; if you need specific reinforcement learning algorithm examples, you can refer to the CleanRL library; if you need to implement other aircraft models (or even environments in other fields), you can modify the Aerodrome code or rewrite it entirely!</p>"},{"location":"en/basics/","title":"Basics and Classes","text":"<p>Page Under Construction</p>"},{"location":"en/cartpole_dqn/","title":"CartPole and DQN","text":"<p>Page Under Construction</p>"},{"location":"en/fixed_wing_template/","title":"Fixed Wing Template","text":"<p>Page Under Construction</p>"},{"location":"en/get_started/","title":"Install Aerodrome","text":"<p>1.Create and activate conda environment</p> <pre><code>$ conda create -n aerodrome python==3.9\n$ conda activate aerodrome\n</code></pre> <p>Compile Environment</p> <p>Aerodrome has been tested on <code>python&gt;=3.9.0,&lt;3.12</code>, but the binary files included in the source code (C++ compiled files under <code>python/simulator</code>) were generated in a <code>python==3.9</code> environment. If you intend to use a different Python version or your own custom environment, you will need to recompile the binaries and ensure that the Python versions used for compilation and runtime are consistent.</p> <p>2.Install Pytorch</p> <p>Running reinforcement learning code requires the use of the <code>torch</code> library; the source code has been tested on <code>torch==2.6.0</code>, but theoretically, it can run on any <code>torch&gt;1.0.0</code> and compatible CUDA versions. For example, <code>PyTorch 2.6.0</code> with <code>CUDA 11.8</code>:</p> <pre><code>$ pip install torch==2.6.0 --index-url https://download.pytorch.org/whl/cu118\n</code></pre> <p>3.Install Aerodrome from source</p> <pre><code>$ git clone https://github.com/CH4ACKO3/Aerodrome.git --recursive\n$ cd Aerodrome\n$ pip install .\n</code></pre> <p>4.Compiling the C++ Code (Optional)</p> <p>If you intend to use a custom environment or a Python version that differs from the one used to generate the binary files in the source code (<code>python==3.9</code>), you will need to recompile and install the code:</p> <pre><code>$ cmake -B build\n$ cmake --build build\n$ pip install .\n</code></pre> <p>The platform and Python version used during compilation will be reflected in the binary file names. For example, a file named <code>*.cp39-win_amd64.pyd</code> indicates that it was compiled on a Windows platform with a 64-bit architecture and in a <code>python==3.9</code> environment.</p>"},{"location":"en/longitudinal_control_classic/","title":"Longitudinal Control - Classic","text":"<p>Page Under Construction</p>"},{"location":"en/longitudinal_control_classic_python/","title":"Longitudinal Control - Classic (Pure Python Implementation)","text":"<p>Page Under Construction</p>"},{"location":"en/longitudinal_control_rl/","title":"Longitudinal Control - Reinforcement Learning","text":"<p>Page Under Construction</p>"},{"location":"en/minimal_example/","title":"Minimal Example","text":"<p>Page Under Construction</p>"},{"location":"en/project_structure/","title":"Project Structure","text":"<p>Aerodrome consists of both C++ and Python components. The C++ functions/classes need to be compiled into <code>.pyd</code> files using <code>pybind11</code> first, after which they can be called by the Python code.</p> <pre><code>./Aerodrome\n\u251c\u2500docs                              # Project Documentation\n\u251c\u2500examples                          # Examples\n\u2502  \u251c\u2500AircraftControl       \n\u2502  \u2502  \u251c\u2500 StepResponse.py            # Comparison of Step Response Between Traditional Control and Reinforcement Learning Control\n\u2502  |  \u251c\u2500 WingedCone_Classic.py      # Traditional Control Method (Directly Calling C++ Code)\n\u2502  |  \u251c\u2500 WingedCone_PPO.py          # Reinforcement Learning Control (C++ Simulation / Python Interaction Environment)\n\u2502  |  \u2514\u2500 WingedCone_TimeCompare.py  # Comparison of Simulation Execution Speed Between C++ and Python\n\u2502  \u251c\u2500CartPole                       # DQN Implementation for CartPole Control\n\u2502  \u2514\u2500MinimalExample                 # Minimal Example Environment\n\u251c\u2500include\n\u2502  \u2514\u2500pybind11\n\u251c\u2500models                            # Pre-trained Models\n\u251c\u2500python                            # Python Source Code\n\u2502  \u251c\u2500aerodrome \n\u2502  \u2502  \u251c\u2500envs                        # Interaction Environment, Handling Information Exchange Between User and C++ Simulation\n\u2502  \u2502  \u2514\u2500simulator                   # Compiled C++ Code Will Be Automatically Stored Here\n\u2502  \u2502      \u251c\u2500CanonicalAircraftEnv \n\u2502  \u2502      \u2502  \u251c\u2500envs                 # Environment Class (Typically, Environment and Entity Are Written as Separate Classes)\n\u2502  \u2502      \u2502  \u2514\u2500objects              # Entity Class\n\u2502  \u2502      \u251c\u2500CartPole\n\u2502  \u2502      \u2502  \u2514\u2500envs\n\u2502  \u2502      \u251c\u2500Core\n\u2502  \u2502      \u2502  \u251c\u2500envs\n\u2502  \u2502      \u2502  \u2514\u2500objects\n\u2502  \u2502      \u2514\u2500MinimalExample\n\u2502  \u2502          \u2514\u2500envs\n\u2502  \u2514\u2500aerodrome.egg-info\n\u2514\u2500src                              # C++ Source Code\n   \u2514\u2500simulator\n       \u251c\u2500CanonicalAircraftEnv\n       \u2502  \u251c\u2500envs\n       \u2502  \u2514\u2500objects\n       \u251c\u2500CartPole\n       \u2502  \u251c\u2500envs\n       \u2502  \u2514\u2500objects\n       \u251c\u2500Core\n       \u2502  \u251c\u2500envs\n       \u2502  \u2514\u2500objects\n       \u2514\u2500MinimalExample\n           \u251c\u2500envs\n           \u2514\u2500objects\n</code></pre>"}]}