{"expires":1743603345.412,"value":{"highlighted":"<!-- Syntax highlighted by torchlight.dev --><div class='line'>&nbsp;</div><div class='line'><span style=\"color: #A6ACCD;\">```py</span></div><div class='line'><span style=\"color: #A6ACCD;\">def layer_init(layer, std=np.sqrt(2), bias_const=0.0):</span></div><div class='line'><span style=\"color: #A6ACCD;\">    torch.nn.init.orthogonal_(layer.weight, std)</span></div><div class='line'><span style=\"color: #A6ACCD;\">    torch.nn.init.constant_(layer.bias, bias_const)</span></div><div class='line'><span style=\"color: #A6ACCD;\">    return layer</span></div><div class='line'>&nbsp;</div><div class='line'><span style=\"color: #A6ACCD;\">class Agent(nn.Module):</span></div><div class='line'><span style=\"color: #A6ACCD;\">    def __init__(self):</span></div><div class='line'><span style=\"color: #A6ACCD;\">        super().__init__()</span></div><div class='line'><span style=\"color: #A6ACCD;\">        self.critic = nn.Sequential(</span></div><div class='line'><span style=\"color: #A6ACCD;\">            layer_init(nn.Linear(3, 256)),</span></div><div class='line'><span style=\"color: #A6ACCD;\">            nn.ReLU(),</span></div><div class='line'><span style=\"color: #A6ACCD;\">            layer_init(nn.Linear(256, 256)),</span></div><div class='line'><span style=\"color: #A6ACCD;\">            nn.ReLU(),</span></div><div class='line'><span style=\"color: #A6ACCD;\">            layer_init(nn.Linear(256, 256)),</span></div><div class='line'><span style=\"color: #A6ACCD;\">            nn.ReLU(),</span></div><div class='line'><span style=\"color: #A6ACCD;\">            layer_init(nn.Linear(256, 1), std=1.0),</span></div><div class='line'><span style=\"color: #A6ACCD;\">        )</span></div><div class='line'><span style=\"color: #A6ACCD;\">        self.actor_mean = nn.Sequential(</span></div><div class='line'><span style=\"color: #A6ACCD;\">            layer_init(nn.Linear(3, 128)),</span></div><div class='line'><span style=\"color: #A6ACCD;\">            nn.ReLU(),</span></div><div class='line'><span style=\"color: #A6ACCD;\">            layer_init(nn.Linear(128, 128)),</span></div><div class='line'><span style=\"color: #A6ACCD;\">            nn.ReLU(),</span></div><div class='line'><span style=\"color: #A6ACCD;\">            layer_init(nn.Linear(128, 128)),</span></div><div class='line'><span style=\"color: #A6ACCD;\">            nn.ReLU(),</span></div><div class='line'><span style=\"color: #A6ACCD;\">            layer_init(nn.Linear(128, 1), std=0.01),</span></div><div class='line'><span style=\"color: #A6ACCD;\">            nn.Tanh(),</span></div><div class='line'><span style=\"color: #A6ACCD;\">        )</span></div><div class='line'><span style=\"color: #A6ACCD;\">        self.actor_logstd = nn.Parameter(torch.zeros(1, 1))</span></div><div class='line'>&nbsp;</div><div class='line'><span style=\"color: #A6ACCD;\">    def get_value(self, x):</span></div><div class='line'><span style=\"color: #A6ACCD;\">        return self.critic(x)</span></div><div class='line'>&nbsp;</div><div class='line'><span style=\"color: #A6ACCD;\">    def get_action_and_value(self, x, action=None, evaluate=False):</span></div><div class='line'><span style=\"color: #A6ACCD;\">        action_mean = self.actor_mean(x)</span></div><div class='line'><span style=\"color: #A6ACCD;\">        action_logstd = self.actor_logstd.expand_as(action_mean)</span></div><div class='line'><span style=\"color: #A6ACCD;\">        action_std = torch.exp(action_logstd)</span></div><div class='line'><span style=\"color: #A6ACCD;\">        if evaluate:</span></div><div class='line'><span style=\"color: #A6ACCD;\">            probs = Normal(action_mean, action_std*1e-6)</span></div><div class='line'><span style=\"color: #A6ACCD;\">        else:</span></div><div class='line'><span style=\"color: #A6ACCD;\">            probs = Normal(action_mean, action_std)</span></div><div class='line'><span style=\"color: #A6ACCD;\">        if action is None:</span></div><div class='line'><span style=\"color: #A6ACCD;\">            action = probs.sample()</span></div><div class='line'><span style=\"color: #A6ACCD;\">        action = torch.clamp(action, -1.0, 1.0)</span></div><div class='line'><span style=\"color: #A6ACCD;\">        return action, probs.log_prob(action).sum(1), probs.entropy().sum(1), self.critic(x)</span></div><div class='line'>&nbsp;</div><div class='line'>&nbsp;</div><div class='line'><span style=\"color: #A6ACCD;\">def linear_schedule(start_e, end_e, duration, t):</span></div><div class='line'><span style=\"color: #A6ACCD;\">    return start_e + (end_e - start_e) * min(t / duration, 1)</span></div>","classes":"torchlight","styles":"background-color: #292D3E; --theme-selection-background: #00000080;"}}
